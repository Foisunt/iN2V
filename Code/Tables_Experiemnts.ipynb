{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34c2399-99d5-418f-bb34-49cd20ee13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "#from utils import collect_res_dat\n",
    "import copy\n",
    "\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed733f3-c394-4176-a4fa-5dc05c0a68ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = baselines vs best in2v variant\n",
    "\n",
    "def get_table_x(df):\n",
    "    params = []\n",
    "    for c in df.drop([\"val_acc\", \"test_acc\", \"statrep\", \"trained_epochs\"], axis=1).columns:\n",
    "        if len(df[c].unique())>1:\n",
    "            params.append(c)\n",
    "    tmp = df.groupby(params)\n",
    "    mean = tmp.mean(numeric_only = True)\n",
    "    std = tmp.std(numeric_only = True)\n",
    "    \n",
    "    ix = mean.val_acc.idxmax()\n",
    "    num_occ = mean.val_acc.value_counts()[mean.loc[ix].val_acc]\n",
    "    \n",
    "    #check wether max is unique, if not use lowest sd one\n",
    "    if num_occ > 1:\n",
    "        max_df = mean[mean.val_acc.eq(mean.loc[ix].val_acc)]\n",
    "        for index, row in max_df.iterrows():\n",
    "            if std.loc[index].val_acc < std.loc[ix].val_acc:\n",
    "                ix = index\n",
    "    return (mean.loc[ix].test_acc*100, std.loc[ix].test_acc*100)\n",
    "    \n",
    "prbest = lambda x: \"$\\\\mathbf{{{:.2f}}}_{{{:.2f}}}$\".format(x[0], x[1])\n",
    "prother = lambda x: \"${:.2f}_{{{:.2f}}}$\".format(x[0], x[1])\n",
    "\n",
    "def print_res_x(dss, splits = [\"145\", \"24\", \"43\", \"81\"], model = \"Sage\", datamode = \"emb\"):\n",
    "    for ds in dss:\n",
    "        ls_orig, ls_trans, ls_fp, ls_train, ls_best = [\"\\\\textcolor{gray}{Original features\"], [\"\\\\textcolor{gray}{N2V (transductive)\"], [\"Feature Propagation\"], [\"N2V (inductive)\"], [\"\\\\textbf{iN2V} (own)\"]\n",
    "        for split in splits:\n",
    "            tmp = \"../results_comb/F_\"+ds+\"_\"+split+\"_\"+model\n",
    "            ls = [pd.read_pickle(tmp+\".pkl\")]\n",
    "            if Path(tmp+\"_e.pkl\").exists():\n",
    "                ls.append(pd.read_pickle(tmp+\"_e.pkl\"))\n",
    "            if Path(tmp+\"_jk.pkl\").exists():\n",
    "                ls.append(pd.read_pickle(tmp+\"_jk.pkl\"))\n",
    "            if Path(tmp+\"_fp.pkl\").exists():\n",
    "                ls.append(pd.read_pickle(tmp+\"_fp.pkl\"))\n",
    "            if Path(tmp+\"_tr.pkl\").exists():\n",
    "                ls.append(pd.read_pickle(tmp+\"_tr.pkl\"))\n",
    "\n",
    "            \n",
    "            \n",
    "            df = pd.concat(ls, ignore_index=True).drop([\n",
    "                \"val_loss\", \"test_loss\", \"loss_hist\", \"valtest_time\", \"train_time\", \"record_train\", \"save_models\", \"batch_size\", \"batch_size_test\", \"batch_size_val\", \"alpha\", \"delay\", \"save_embeds\",\n",
    "                \"context_size\", \"num_negative_samples\", \"max_iter\", \"patience\"], axis=1, errors=\"ignore\")\n",
    "\n",
    "            \n",
    "            ls_orig.append(prother(get_table_x(df[df.datamode.eq(\"gra\")])))\n",
    "            ls_trans.append(prother(get_table_x(df[df.datamode.eq(datamode+\"_transd\")])))\n",
    "            \n",
    "            res_ls = [get_table_x(df[df.datamode.eq(datamode+\"_fpbase\")]), get_table_x(df[df.datamode.eq(datamode+\"_tr\")]), get_table_x(df[df.datamode.eq(datamode+\"_po\") | df.datamode.eq(datamode+\"_lo\") | df.datamode.eq(datamode+\"_re\") | df.datamode.eq(datamode+\"_ba\")])]\n",
    "            mx = max(res_ls)[0]\n",
    "            res_ls=[prbest(x) if x[0]==mx else prother(x) for x in res_ls]\n",
    "\n",
    "            ls_fp.append(res_ls[0])\n",
    "            ls_train.append(res_ls[1])\n",
    "            ls_best.append(res_ls[2])\n",
    "            \n",
    "        ds_n = {\"Cora\":\"Cora\", \"Cite\":\"Citeseer\", \"PM\":\"Pubmed\", \"Com\":\"Computers\", \"Pho\":\"Photo\", \"Act\":\"Actor\", \"Ar\":\"Amazon-ratings\", \"Re\":\"Roman-empire\", \"WCS\":\"WikiCS\"}[ds]\n",
    "\n",
    "        print(r\"\\multicolumn{\"+str(len(ls_orig))+\"}{l}{\"+ds_n+\"} \\\\\\\\ \\\\hline\")\n",
    "        print(\" & \".join(ls_train)+\" \\\\\\\\\")\n",
    "        print(\" & \".join(ls_fp)+\" \\\\\\\\\")\n",
    "        print(\" & \".join(ls_best)+\" \\\\\\\\ \\\\hline\")\n",
    "        print(\"} & \\\\textcolor{gray}{\".join(ls_orig)+\"} \\\\\\\\\")\n",
    "        print(\"} & \\\\textcolor{gray}{\".join(ls_trans)+\"} \\\\\\\\ \\\\midrule\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371dcf63-c057-497c-a112-aded90420cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate over all datasets\n",
    "def aggregate_res():\n",
    "    res_ls = []\n",
    "    for model in [\"MLP\", \"Sage\"]:\n",
    "        for ds in [\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"WCS\", \"Act\", \"Ar\", \"Re\"]:\n",
    "            for split in [\"145\", \"24\", \"43\",\"62\", \"81\"]:\n",
    "                tmp = \"../results_comb/F_\"+ds+\"_\"+split+\"_\"+model\n",
    "                ls = [pd.read_pickle(tmp+\".pkl\")]\n",
    "                if Path(tmp+\"_e.pkl\").exists():\n",
    "                    ls.append(pd.read_pickle(tmp+\"_e.pkl\"))\n",
    "                if Path(tmp+\"_jk.pkl\").exists():\n",
    "                    ls.append(pd.read_pickle(tmp+\"_jk.pkl\"))\n",
    "                if Path(tmp+\"_fp.pkl\").exists():\n",
    "                    ls.append(pd.read_pickle(tmp+\"_fp.pkl\"))\n",
    "                if Path(tmp+\"_tr.pkl\").exists():\n",
    "                    ls.append(pd.read_pickle(tmp+\"_tr.pkl\"))\n",
    "                df = pd.concat(ls, ignore_index=True).drop([\n",
    "                    \"val_loss\", \"test_loss\", \"loss_hist\", \"valtest_time\", \"train_time\", \"record_train\", \"save_models\", \"batch_size\", \"batch_size_test\", \"batch_size_val\", \"alpha\", \"delay\", \"save_embeds\",\n",
    "                    \"context_size\", \"num_negative_samples\", \"max_iter\", \"patience\"], axis=1, errors=\"ignore\")\n",
    "                \n",
    "\n",
    "                for cat in [\"emb\", \"cat\"]:\n",
    "                    tmp = get_table_x(df[df.datamode.eq(\"gra\")])\n",
    "                    res_ls.append((ds, split, model, cat, \"gra\", tmp[0], tmp[1]))\n",
    "                    for datamode in [\"transd\", \"fpbase\", \"fploss\", \"fpprob\", \"tr\", \"ba\", \"po\", \"lo\", \"re\"]:\n",
    "                        tmp = get_table_x(df[df.datamode.eq(cat+\"_\"+datamode)])\n",
    "                        res_ls.append((ds, split, model, cat, datamode, tmp[0], tmp[1]))\n",
    "    return pd.DataFrame(res_ls, columns =['dataset', 'split', 'model', \"cat\", \"datamode\", \"test_acc\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f7943bf-8e70-45d6-be2a-81e2f448620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = aggregate_res()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75f0d079-e2d3-4d2e-891c-f3dbf9182562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_93552/1099724808.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.split = df.split.replace({\"145\":10, \"24\":20, \"43\":40, \"62\":60, \"81\":80, })\n"
     ]
    }
   ],
   "source": [
    "df = copy.copy(res_df)\n",
    "df.datamode = df.datamode.replace({\"tr\":\"N2V (in.)\", \"fpbase\":\"FP\", \"ba\":\"frozen ($\\\\lambda=1$)\",\"po\":\"post-hoc\", \"lo\":\"p-h w losses\", \"re\":\"p-h w sampling\", \"gra\":\"features only\", \"transd\":\"N2V (tr.)\"})\n",
    "df.model = df.model.replace({\"Sage\":\"GraphSAGE\"})\n",
    "df.split = df.split.replace({\"145\":10, \"24\":20, \"43\":40, \"62\":60, \"81\":80, })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "abc91dbc-3bc3-4ed3-9a24-4b25e4ed0213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "cat & \\multicolumn{2}{r}{cat} & \\multicolumn{2}{r}{emb} \\\\\n",
      "model & GraphSAGE & MLP & GraphSAGE & MLP \\\\\n",
      "datamode &  &  &  &  \\\\\n",
      "\\midrule\n",
      "FP & 74.09 & 73.17 & 63.20 & 62.97 \\\\\n",
      "N2V (in.) & 73.51 & 68.72 & 59.45 & 27.91 \\\\\n",
      "N2V (tr.) & 75.57 & 74.15 & 65.07 & 63.89 \\\\\n",
      "features only & 74.73 & 71.01 & 74.73 & 71.01 \\\\\n",
      "frozen ($\\lambda=1$) & 73.46 & 72.40 & 62.88 & 61.74 \\\\\n",
      "p-h w losses & 74.32 & 74.04 & 63.95 & 64.57 \\\\\n",
      "p-h w sampling & 74.02 & 73.95 & 63.83 & 64.42 \\\\\n",
      "post-hoc & 74.24 & 73.99 & 63.75 & 64.38 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sage vs mlp\n",
    "#cat vs emb\n",
    "tmp = df[df.datamode.ne(\"fploss\")&df.datamode.ne(\"fpprob\")].groupby([\"cat\", \"model\", \"datamode\"]).mean(numeric_only=True).reset_index()\n",
    "print(tmp.pivot(index='datamode', columns=[\"cat\", \"model\"], values='test_acc').to_latex(float_format=\"{:.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e57db63b-288a-4dc4-a24f-95b80aa6b7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>model</th>\n",
       "      <th>cat</th>\n",
       "      <th>datamode</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cora</td>\n",
       "      <td>10</td>\n",
       "      <td>MLP</td>\n",
       "      <td>emb</td>\n",
       "      <td>FP</td>\n",
       "      <td>78.539786</td>\n",
       "      <td>1.423613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cora</td>\n",
       "      <td>10</td>\n",
       "      <td>MLP</td>\n",
       "      <td>emb</td>\n",
       "      <td>fploss</td>\n",
       "      <td>79.269893</td>\n",
       "      <td>1.275014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cora</td>\n",
       "      <td>10</td>\n",
       "      <td>MLP</td>\n",
       "      <td>emb</td>\n",
       "      <td>fpprob</td>\n",
       "      <td>79.204266</td>\n",
       "      <td>1.550839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cora</td>\n",
       "      <td>20</td>\n",
       "      <td>MLP</td>\n",
       "      <td>emb</td>\n",
       "      <td>FP</td>\n",
       "      <td>81.108032</td>\n",
       "      <td>1.170562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cora</td>\n",
       "      <td>20</td>\n",
       "      <td>MLP</td>\n",
       "      <td>emb</td>\n",
       "      <td>fploss</td>\n",
       "      <td>80.443212</td>\n",
       "      <td>1.371501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>Re</td>\n",
       "      <td>60</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>emb</td>\n",
       "      <td>fploss</td>\n",
       "      <td>16.045896</td>\n",
       "      <td>1.300203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>Re</td>\n",
       "      <td>60</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>emb</td>\n",
       "      <td>fpprob</td>\n",
       "      <td>15.584731</td>\n",
       "      <td>1.790754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>Re</td>\n",
       "      <td>80</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>emb</td>\n",
       "      <td>FP</td>\n",
       "      <td>21.968226</td>\n",
       "      <td>1.251630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>Re</td>\n",
       "      <td>80</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>emb</td>\n",
       "      <td>fploss</td>\n",
       "      <td>21.959400</td>\n",
       "      <td>1.801289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>Re</td>\n",
       "      <td>80</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>emb</td>\n",
       "      <td>fpprob</td>\n",
       "      <td>19.783760</td>\n",
       "      <td>1.574480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset  split      model  cat datamode   test_acc       std\n",
       "2       Cora     10        MLP  emb       FP  78.539786  1.423613\n",
       "3       Cora     10        MLP  emb   fploss  79.269893  1.275014\n",
       "4       Cora     10        MLP  emb   fpprob  79.204266  1.550839\n",
       "22      Cora     20        MLP  emb       FP  81.108032  1.170562\n",
       "23      Cora     20        MLP  emb   fploss  80.443212  1.371501\n",
       "...      ...    ...        ...  ...      ...        ...       ...\n",
       "1763      Re     60  GraphSAGE  emb   fploss  16.045896  1.300203\n",
       "1764      Re     60  GraphSAGE  emb   fpprob  15.584731  1.790754\n",
       "1782      Re     80  GraphSAGE  emb       FP  21.968226  1.251630\n",
       "1783      Re     80  GraphSAGE  emb   fploss  21.959400  1.801289\n",
       "1784      Re     80  GraphSAGE  emb   fpprob  19.783760  1.574480\n",
       "\n",
       "[270 rows x 7 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[df.cat.eq(\"emb\")]\n",
    "df=df[df.datamode.eq(\"fploss\")|df.datamode.eq(\"fpprob\")|df.datamode.eq(\"FP\")]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f83bba9a-ac66-45b5-aa81-05c598003f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "model & GraphSAGE & MLP \\\\\n",
      "datamode &  &  \\\\\n",
      "\\midrule\n",
      "FP & 63.20 & 62.97 \\\\\n",
      "fploss & 63.22 & 63.04 \\\\\n",
      "fpprob & 62.98 & 62.98 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby([\"model\", \"datamode\"]).mean(numeric_only=True).reset_index().pivot(index='datamode', columns=[\"model\"], values='test_acc').to_latex(float_format=\"{:.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d3de539-ba60-4b21-9228-0676b566de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ac4f5e9-2371-440b-8f79-cc62ba6d1114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1240.62x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hom_df = df[df.dataset.ne(\"Actor\") & df.dataset.ne(\"Amazon-rating\") & df.dataset.ne(\"Roman-empire\")]\n",
    "ta = \"test accuracy\"\n",
    "n_sp = \"training data percentage\"\n",
    "\n",
    "tmp_df = df[df.cat.eq(\"emb\") & df.datamode.ne(\"features only\")& df.datamode.ne(\"fpprob\")& df.datamode.ne(\"fploss\")].rename(columns={\"test_acc\":ta, \"datamode\":\"setup\"})\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fg = sns.relplot(tmp_df.rename(columns={\"setup\":\" \", \"split\":n_sp}), x=n_sp, y=ta, hue=\" \", kind=\"line\",col=\"model\", errorbar=None, facet_kws={'sharey': True, 'sharex': True})\n",
    "sns.move_legend(fg, \"lower center\", bbox_to_anchor=(.43, 1), ncol=4)\n",
    "\n",
    "plt.ylim(55,69)\n",
    "plt.savefig(\"imgs/split_effect.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8242cccc-245f-4fc5-a32d-fe20be2bd959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1626ad49-0407-4a57-a26e-cb8a0d26d9b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn{5}{l}{Cora} \\\\ \\hline\n",
      "N2V (inductive) & $42.18_{3.52}$ & $59.91_{4.15}$ & $75.07_{1.92}$ & $\\mathbf{84.50}_{1.44}$ \\\\\n",
      "Feature Propagation & $77.91_{2.62}$ & $79.48_{2.19}$ & $81.03_{1.85}$ & $84.13_{2.35}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{78.88}_{1.45}$ & $\\mathbf{80.94}_{1.58}$ & $\\mathbf{83.30}_{1.09}$ & $84.46_{2.08}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$75.27_{2.63}$} & \\textcolor{gray}{$83.37_{1.17}$} & \\textcolor{gray}{$86.23_{1.77}$} & \\textcolor{gray}{$87.05_{1.20}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$79.25_{1.45}$} & \\textcolor{gray}{$81.66_{1.29}$} & \\textcolor{gray}{$83.81_{0.95}$} & \\textcolor{gray}{$86.01_{1.99}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{Citeseer} \\\\ \\hline\n",
      "N2V (inductive) & $34.17_{3.43}$ & $42.76_{2.15}$ & $56.12_{3.24}$ & $68.89_{2.61}$ \\\\\n",
      "Feature Propagation & $56.85_{1.84}$ & $60.53_{2.03}$ & $\\mathbf{63.03}_{2.21}$ & $\\mathbf{69.76}_{1.82}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{57.88}_{0.91}$ & $\\mathbf{60.78}_{1.78}$ & $63.02_{1.88}$ & $68.92_{2.07}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$69.85_{1.42}$} & \\textcolor{gray}{$72.86_{0.98}$} & \\textcolor{gray}{$74.93_{1.56}$} & \\textcolor{gray}{$76.82_{1.77}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$57.14_{1.51}$} & \\textcolor{gray}{$61.33_{1.09}$} & \\textcolor{gray}{$66.45_{1.60}$} & \\textcolor{gray}{$72.76_{2.54}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{Pubmed} \\\\ \\hline\n",
      "N2V (inductive) & $66.02_{5.57}$ & $74.73_{2.36}$ & $79.84_{1.78}$ & $\\mathbf{82.61}_{0.52}$ \\\\\n",
      "Feature Propagation & $76.37_{0.62}$ & $77.72_{0.50}$ & $80.74_{0.72}$ & $82.43_{0.86}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{79.93}_{0.50}$ & $\\mathbf{80.80}_{0.46}$ & $\\mathbf{82.14}_{0.43}$ & $82.59_{0.63}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$85.95_{0.47}$} & \\textcolor{gray}{$86.99_{0.28}$} & \\textcolor{gray}{$88.32_{0.48}$} & \\textcolor{gray}{$89.85_{0.56}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$81.36_{0.49}$} & \\textcolor{gray}{$82.20_{0.50}$} & \\textcolor{gray}{$83.22_{0.34}$} & \\textcolor{gray}{$83.66_{0.65}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{Computers} \\\\ \\hline\n",
      "N2V (inductive) & $77.64_{2.81}$ & $84.44_{0.84}$ & $87.18_{0.77}$ & $89.35_{0.70}$ \\\\\n",
      "Feature Propagation & $82.79_{0.64}$ & $86.43_{0.63}$ & $89.40_{0.45}$ & $90.87_{0.64}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{88.36}_{0.58}$ & $\\mathbf{89.67}_{0.40}$ & $\\mathbf{90.84}_{0.37}$ & $\\mathbf{91.38}_{0.51}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$87.52_{0.48}$} & \\textcolor{gray}{$89.76_{0.40}$} & \\textcolor{gray}{$91.12_{0.20}$} & \\textcolor{gray}{$91.50_{0.48}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$89.18_{0.38}$} & \\textcolor{gray}{$90.16_{0.44}$} & \\textcolor{gray}{$90.77_{0.39}$} & \\textcolor{gray}{$91.16_{0.56}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{Photo} \\\\ \\hline\n",
      "N2V (inductive) & $85.48_{1.28}$ & $87.73_{1.40}$ & $90.98_{0.71}$ & $92.21_{0.96}$ \\\\\n",
      "Feature Propagation & $87.43_{1.09}$ & $90.14_{0.34}$ & $91.57_{0.42}$ & $92.95_{0.79}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{90.51}_{0.72}$ & $\\mathbf{91.70}_{0.44}$ & $\\mathbf{92.37}_{0.46}$ & $\\mathbf{93.08}_{0.77}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$93.74_{0.42}$} & \\textcolor{gray}{$94.59_{0.37}$} & \\textcolor{gray}{$95.27_{0.38}$} & \\textcolor{gray}{$95.59_{0.77}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$91.29_{0.41}$} & \\textcolor{gray}{$92.29_{0.30}$} & \\textcolor{gray}{$92.90_{0.45}$} & \\textcolor{gray}{$93.33_{0.71}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{WikiCS} \\\\ \\hline\n",
      "N2V (inductive) & $67.78_{2.68}$ & $74.22_{1.65}$ & $78.21_{0.69}$ & $81.62_{0.86}$ \\\\\n",
      "Feature Propagation & $74.77_{2.27}$ & $78.04_{1.00}$ & $80.17_{0.68}$ & $81.93_{1.08}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{78.91}_{0.61}$ & $\\mathbf{80.19}_{0.70}$ & $\\mathbf{81.28}_{0.61}$ & $\\mathbf{82.37}_{1.01}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$80.75_{0.64}$} & \\textcolor{gray}{$82.56_{0.81}$} & \\textcolor{gray}{$84.28_{0.55}$} & \\textcolor{gray}{$85.88_{0.70}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$79.75_{0.41}$} & \\textcolor{gray}{$80.93_{0.64}$} & \\textcolor{gray}{$81.88_{0.55}$} & \\textcolor{gray}{$82.81_{0.68}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{Actor} \\\\ \\hline\n",
      "N2V (inductive) & $25.14_{1.09}$ & $\\mathbf{25.56}_{0.90}$ & $\\mathbf{25.54}_{1.15}$ & $25.68_{1.42}$ \\\\\n",
      "Feature Propagation & $\\mathbf{25.22}_{1.29}$ & $25.39_{1.06}$ & $25.14_{0.59}$ & $25.05_{1.34}$ \\\\\n",
      "\\textbf{iN2V} (own) & $25.18_{0.97}$ & $25.50_{0.70}$ & $25.40_{0.99}$ & $\\mathbf{25.79}_{2.27}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$31.77_{0.71}$} & \\textcolor{gray}{$33.84_{0.91}$} & \\textcolor{gray}{$36.48_{0.54}$} & \\textcolor{gray}{$36.71_{1.23}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$25.50_{0.76}$} & \\textcolor{gray}{$25.56_{0.95}$} & \\textcolor{gray}{$25.41_{0.74}$} & \\textcolor{gray}{$24.55_{1.70}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{Amazon-ratings} \\\\ \\hline\n",
      "N2V (inductive) & $37.47_{0.47}$ & $40.69_{0.63}$ & $44.71_{0.85}$ & $49.47_{1.07}$ \\\\\n",
      "Feature Propagation & $38.97_{0.76}$ & $41.68_{0.76}$ & $\\mathbf{45.72}_{0.75}$ & $50.04_{1.42}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{40.02}_{0.79}$ & $\\mathbf{42.01}_{0.48}$ & $45.48_{0.57}$ & $\\mathbf{50.38}_{2.22}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$39.20_{1.06}$} & \\textcolor{gray}{$41.66_{0.70}$} & \\textcolor{gray}{$48.07_{0.58}$} & \\textcolor{gray}{$57.34_{0.97}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$41.82_{0.66}$} & \\textcolor{gray}{$43.69_{0.52}$} & \\textcolor{gray}{$46.31_{0.78}$} & \\textcolor{gray}{$49.80_{0.94}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{Roman-empire} \\\\ \\hline\n",
      "N2V (inductive) & $\\mathbf{13.96}_{0.35}$ & $\\mathbf{14.10}_{0.32}$ & $\\mathbf{15.77}_{0.76}$ & $16.81_{2.94}$ \\\\\n",
      "Feature Propagation & $13.23_{1.44}$ & $13.89_{0.44}$ & $15.49_{0.67}$ & $\\mathbf{21.97}_{1.25}$ \\\\\n",
      "\\textbf{iN2V} (own) & $13.79_{0.39}$ & $13.86_{0.29}$ & $14.48_{0.63}$ & $18.55_{1.23}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$66.09_{0.75}$} & \\textcolor{gray}{$70.28_{0.63}$} & \\textcolor{gray}{$74.41_{0.47}$} & \\textcolor{gray}{$82.90_{1.09}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$13.82_{0.22}$} & \\textcolor{gray}{$13.86_{0.37}$} & \\textcolor{gray}{$15.35_{1.53}$} & \\textcolor{gray}{$27.46_{1.36}$} \\\\ \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_res_x([\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"WCS\", \"Act\", \"Ar\", \"Re\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661b16a8-619b-4b09-8d66-6502e3e7b6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn{6}{l}{Cora} \\\\ \\hline\n",
      "N2V (inductive) & $30.04_{1.06}$ & $30.07_{1.15}$ & $30.12_{1.05}$ & $29.67_{1.04}$ & $30.70_{2.14}$ \\\\\n",
      "Feature Propagation & $78.54_{1.42}$ & $81.11_{1.17}$ & $82.38_{1.01}$ & $83.76_{1.00}$ & $85.13_{2.27}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{79.84}_{1.27}$ & $\\mathbf{81.70}_{1.19}$ & $\\mathbf{83.93}_{1.16}$ & $\\mathbf{84.69}_{0.95}$ & $\\mathbf{85.57}_{2.22}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$66.98_{1.70}$} & \\textcolor{gray}{$71.34_{1.79}$} & \\textcolor{gray}{$75.94_{1.38}$} & \\textcolor{gray}{$78.78_{1.11}$} & \\textcolor{gray}{$79.23_{1.95}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$78.44_{1.15}$} & \\textcolor{gray}{$80.84_{1.49}$} & \\textcolor{gray}{$82.82_{1.10}$} & \\textcolor{gray}{$83.75_{1.20}$} & \\textcolor{gray}{$83.10_{1.86}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Citeseer} \\\\ \\hline\n",
      "N2V (inductive) & $19.81_{1.75}$ & $21.43_{1.00}$ & $21.11_{1.27}$ & $21.10_{1.46}$ & $19.82_{3.05}$ \\\\\n",
      "Feature Propagation & $56.76_{2.21}$ & $60.14_{1.58}$ & $65.73_{1.37}$ & $68.54_{1.53}$ & $72.16_{2.65}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{57.88}_{1.35}$ & $\\mathbf{61.67}_{1.69}$ & $\\mathbf{66.47}_{1.91}$ & $\\mathbf{70.62}_{1.37}$ & $\\mathbf{73.27}_{1.73}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$66.60_{1.56}$} & \\textcolor{gray}{$70.53_{1.04}$} & \\textcolor{gray}{$73.23_{1.17}$} & \\textcolor{gray}{$74.56_{1.04}$} & \\textcolor{gray}{$75.20_{2.10}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$56.43_{2.01}$} & \\textcolor{gray}{$60.65_{1.81}$} & \\textcolor{gray}{$64.77_{1.77}$} & \\textcolor{gray}{$68.80_{1.69}$} & \\textcolor{gray}{$70.09_{1.32}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Pubmed} \\\\ \\hline\n",
      "N2V (inductive) & $39.45_{0.69}$ & $39.69_{0.77}$ & $40.15_{0.42}$ & $40.01_{0.71}$ & $39.30_{1.06}$ \\\\\n",
      "Feature Propagation & $78.44_{0.44}$ & $78.99_{0.49}$ & $81.02_{0.73}$ & $81.91_{0.64}$ & $82.56_{0.95}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{80.42}_{0.44}$ & $\\mathbf{81.77}_{0.40}$ & $\\mathbf{82.78}_{0.58}$ & $\\mathbf{83.19}_{0.44}$ & $\\mathbf{83.26}_{0.87}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$84.11_{0.21}$} & \\textcolor{gray}{$86.05_{0.40}$} & \\textcolor{gray}{$87.72_{0.40}$} & \\textcolor{gray}{$88.63_{0.60}$} & \\textcolor{gray}{$89.10_{0.63}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$81.03_{0.51}$} & \\textcolor{gray}{$81.76_{0.52}$} & \\textcolor{gray}{$82.72_{0.39}$} & \\textcolor{gray}{$82.96_{0.51}$} & \\textcolor{gray}{$83.17_{0.76}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Computers} \\\\ \\hline\n",
      "N2V (inductive) & $37.39_{0.32}$ & $37.33_{0.28}$ & $37.31_{0.66}$ & $37.51_{0.75}$ & $37.72_{0.87}$ \\\\\n",
      "Feature Propagation & $81.90_{0.93}$ & $86.16_{0.66}$ & $89.20_{0.35}$ & $90.27_{0.60}$ & $90.71_{0.61}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{88.70}_{0.47}$ & $\\mathbf{90.04}_{0.51}$ & $\\mathbf{91.10}_{0.47}$ & $\\mathbf{91.51}_{0.48}$ & $\\mathbf{91.55}_{0.52}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$82.15_{0.63}$} & \\textcolor{gray}{$84.08_{0.65}$} & \\textcolor{gray}{$85.57_{0.53}$} & \\textcolor{gray}{$86.00_{0.77}$} & \\textcolor{gray}{$86.56_{0.58}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$88.58_{0.54}$} & \\textcolor{gray}{$89.63_{0.39}$} & \\textcolor{gray}{$90.18_{0.41}$} & \\textcolor{gray}{$90.51_{0.35}$} & \\textcolor{gray}{$90.39_{0.57}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Photo} \\\\ \\hline\n",
      "N2V (inductive) & $25.51_{0.46}$ & $24.86_{1.30}$ & $23.66_{1.99}$ & $22.96_{1.95}$ & $23.15_{2.24}$ \\\\\n",
      "Feature Propagation & $87.37_{0.85}$ & $89.38_{0.58}$ & $91.49_{0.51}$ & $92.25_{0.53}$ & $92.64_{0.77}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{90.70}_{0.50}$ & $\\mathbf{91.74}_{0.36}$ & $\\mathbf{92.60}_{0.55}$ & $\\mathbf{92.86}_{0.72}$ & $\\mathbf{93.07}_{0.68}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$89.32_{0.59}$} & \\textcolor{gray}{$90.85_{0.55}$} & \\textcolor{gray}{$91.96_{0.55}$} & \\textcolor{gray}{$92.41_{0.60}$} & \\textcolor{gray}{$92.92_{0.87}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$91.23_{0.44}$} & \\textcolor{gray}{$91.88_{0.47}$} & \\textcolor{gray}{$92.67_{0.50}$} & \\textcolor{gray}{$92.73_{0.61}$} & \\textcolor{gray}{$92.44_{0.67}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{WikiCS} \\\\ \\hline\n",
      "N2V (inductive) & $22.99_{0.41}$ & $22.96_{0.49}$ & $23.05_{0.51}$ & $23.12_{0.76}$ & $22.82_{1.26}$ \\\\\n",
      "Feature Propagation & $73.59_{1.36}$ & $75.83_{1.53}$ & $78.83_{0.82}$ & $80.58_{0.57}$ & $80.97_{0.87}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{79.21}_{0.59}$ & $\\mathbf{80.37}_{0.80}$ & $\\mathbf{81.47}_{0.52}$ & $\\mathbf{82.12}_{0.68}$ & $\\mathbf{82.76}_{0.83}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$76.85_{0.64}$} & \\textcolor{gray}{$78.76_{0.66}$} & \\textcolor{gray}{$80.43_{0.64}$} & \\textcolor{gray}{$81.56_{0.78}$} & \\textcolor{gray}{$82.38_{1.06}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$79.23_{0.68}$} & \\textcolor{gray}{$80.51_{0.59}$} & \\textcolor{gray}{$81.47_{0.56}$} & \\textcolor{gray}{$81.86_{0.53}$} & \\textcolor{gray}{$81.92_{0.66}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Actor} \\\\ \\hline\n",
      "N2V (inductive) & $25.41_{1.39}$ & $\\mathbf{25.55}_{1.16}$ & $25.69_{1.08}$ & $\\mathbf{26.05}_{0.51}$ & $\\mathbf{26.57}_{0.79}$ \\\\\n",
      "Feature Propagation & $25.56_{1.04}$ & $25.15_{0.94}$ & $\\mathbf{25.83}_{0.65}$ & $25.18_{0.53}$ & $25.00_{1.05}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{25.78}_{0.76}$ & $25.45_{0.87}$ & $25.00_{1.35}$ & $25.14_{0.76}$ & $25.51_{2.00}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$35.13_{0.51}$} & \\textcolor{gray}{$36.20_{0.67}$} & \\textcolor{gray}{$37.79_{0.62}$} & \\textcolor{gray}{$38.75_{0.86}$} & \\textcolor{gray}{$37.87_{1.53}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$25.08_{1.04}$} & \\textcolor{gray}{$25.34_{0.99}$} & \\textcolor{gray}{$25.51_{1.01}$} & \\textcolor{gray}{$25.12_{0.89}$} & \\textcolor{gray}{$23.92_{1.12}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Amazon-ratings} \\\\ \\hline\n",
      "N2V (inductive) & $36.91_{0.30}$ & $36.93_{0.35}$ & $36.74_{0.37}$ & $36.78_{0.52}$ & $36.54_{0.89}$ \\\\\n",
      "Feature Propagation & $39.70_{0.60}$ & $42.18_{0.81}$ & $44.90_{0.62}$ & $46.24_{0.76}$ & $46.32_{0.96}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{41.41}_{0.87}$ & $\\mathbf{43.75}_{0.54}$ & $\\mathbf{46.52}_{0.77}$ & $\\mathbf{51.66}_{0.31}$ & $\\mathbf{51.93}_{0.78}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$37.80_{0.51}$} & \\textcolor{gray}{$41.77_{0.61}$} & \\textcolor{gray}{$47.20_{0.56}$} & \\textcolor{gray}{$50.82_{0.77}$} & \\textcolor{gray}{$54.00_{0.69}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$41.97_{0.50}$} & \\textcolor{gray}{$42.71_{0.48}$} & \\textcolor{gray}{$45.57_{0.47}$} & \\textcolor{gray}{$46.58_{0.60}$} & \\textcolor{gray}{$47.97_{0.89}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Roman-empire} \\\\ \\hline\n",
      "N2V (inductive) & $13.34_{1.25}$ & $13.55_{0.97}$ & $\\mathbf{14.00}_{0.28}$ & $13.99_{0.40}$ & $13.27_{1.67}$ \\\\\n",
      "Feature Propagation & $13.83_{0.25}$ & $\\mathbf{13.93}_{0.26}$ & $13.90_{0.29}$ & $13.88_{0.52}$ & $13.53_{0.78}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{13.89}_{0.26}$ & $13.90_{0.27}$ & $13.79_{0.24}$ & $\\mathbf{14.23}_{0.69}$ & $\\mathbf{14.27}_{0.94}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$63.46_{0.43}$} & \\textcolor{gray}{$65.05_{0.31}$} & \\textcolor{gray}{$66.47_{0.41}$} & \\textcolor{gray}{$66.83_{0.71}$} & \\textcolor{gray}{$66.55_{1.02}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$13.80_{0.26}$} & \\textcolor{gray}{$13.74_{0.39}$} & \\textcolor{gray}{$13.95_{0.25}$} & \\textcolor{gray}{$13.98_{0.49}$} & \\textcolor{gray}{$13.27_{0.90}$} \\\\ \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_res_x([\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"WCS\", \"Act\", \"Ar\", \"Re\"], splits = [\"145\", \"24\", \"43\",\"62\", \"81\"], model = \"MLP\", datamode = \"emb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1e9b30d-fdda-4912-af5b-5ee452fd96fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn{6}{l}{Cora} \\\\ \\hline\n",
      "N2V (inductive) & $42.18_{3.52}$ & $59.91_{4.15}$ & $75.07_{1.92}$ & $81.31_{1.56}$ & $\\mathbf{84.50}_{1.44}$ \\\\\n",
      "Feature Propagation & $77.91_{2.62}$ & $79.48_{2.19}$ & $81.03_{1.85}$ & $\\mathbf{84.00}_{1.00}$ & $84.13_{2.35}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{78.88}_{1.45}$ & $\\mathbf{80.94}_{1.58}$ & $\\mathbf{83.30}_{1.09}$ & $83.73_{1.13}$ & $84.46_{2.08}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$75.27_{2.63}$} & \\textcolor{gray}{$83.37_{1.17}$} & \\textcolor{gray}{$86.23_{1.77}$} & \\textcolor{gray}{$86.99_{0.86}$} & \\textcolor{gray}{$87.05_{1.20}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$79.25_{1.45}$} & \\textcolor{gray}{$81.66_{1.29}$} & \\textcolor{gray}{$83.81_{0.95}$} & \\textcolor{gray}{$85.24_{0.83}$} & \\textcolor{gray}{$86.01_{1.99}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Citeseer} \\\\ \\hline\n",
      "N2V (inductive) & $34.17_{3.43}$ & $42.76_{2.15}$ & $56.12_{3.24}$ & $63.61_{2.57}$ & $68.89_{2.61}$ \\\\\n",
      "Feature Propagation & $56.85_{1.84}$ & $60.53_{2.03}$ & $\\mathbf{63.03}_{2.21}$ & $66.51_{2.18}$ & $\\mathbf{69.76}_{1.82}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{57.88}_{0.91}$ & $\\mathbf{60.78}_{1.78}$ & $63.02_{1.88}$ & $\\mathbf{66.81}_{1.42}$ & $68.92_{2.07}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$69.85_{1.42}$} & \\textcolor{gray}{$72.86_{0.98}$} & \\textcolor{gray}{$74.93_{1.56}$} & \\textcolor{gray}{$76.39_{1.05}$} & \\textcolor{gray}{$76.82_{1.77}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$57.14_{1.51}$} & \\textcolor{gray}{$61.33_{1.09}$} & \\textcolor{gray}{$66.45_{1.60}$} & \\textcolor{gray}{$70.14_{1.26}$} & \\textcolor{gray}{$72.76_{2.54}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Pubmed} \\\\ \\hline\n",
      "N2V (inductive) & $66.02_{5.57}$ & $74.73_{2.36}$ & $79.84_{1.78}$ & $81.85_{0.61}$ & $\\mathbf{82.61}_{0.52}$ \\\\\n",
      "Feature Propagation & $76.37_{0.62}$ & $77.72_{0.50}$ & $80.74_{0.72}$ & $82.00_{0.54}$ & $82.43_{0.86}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{79.93}_{0.50}$ & $\\mathbf{80.80}_{0.46}$ & $\\mathbf{82.14}_{0.43}$ & $\\mathbf{82.81}_{0.46}$ & $82.59_{0.63}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$85.95_{0.47}$} & \\textcolor{gray}{$86.99_{0.28}$} & \\textcolor{gray}{$88.32_{0.48}$} & \\textcolor{gray}{$89.25_{0.44}$} & \\textcolor{gray}{$89.85_{0.56}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$81.36_{0.49}$} & \\textcolor{gray}{$82.20_{0.50}$} & \\textcolor{gray}{$83.22_{0.34}$} & \\textcolor{gray}{$83.57_{0.50}$} & \\textcolor{gray}{$83.66_{0.65}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Computers} \\\\ \\hline\n",
      "N2V (inductive) & $77.64_{2.81}$ & $84.44_{0.84}$ & $87.18_{0.77}$ & $89.21_{0.42}$ & $89.35_{0.70}$ \\\\\n",
      "Feature Propagation & $82.79_{0.64}$ & $86.43_{0.63}$ & $89.40_{0.45}$ & $90.43_{0.40}$ & $90.87_{0.64}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{88.36}_{0.58}$ & $\\mathbf{89.67}_{0.40}$ & $\\mathbf{90.84}_{0.37}$ & $\\mathbf{91.08}_{0.36}$ & $\\mathbf{91.38}_{0.51}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$87.52_{0.48}$} & \\textcolor{gray}{$89.76_{0.40}$} & \\textcolor{gray}{$91.12_{0.20}$} & \\textcolor{gray}{$91.49_{0.58}$} & \\textcolor{gray}{$91.50_{0.48}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$89.18_{0.38}$} & \\textcolor{gray}{$90.16_{0.44}$} & \\textcolor{gray}{$90.77_{0.39}$} & \\textcolor{gray}{$91.19_{0.39}$} & \\textcolor{gray}{$91.16_{0.56}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Photo} \\\\ \\hline\n",
      "N2V (inductive) & $85.48_{1.28}$ & $87.73_{1.40}$ & $90.98_{0.71}$ & $91.92_{0.63}$ & $92.21_{0.96}$ \\\\\n",
      "Feature Propagation & $87.43_{1.09}$ & $90.14_{0.34}$ & $91.57_{0.42}$ & $92.48_{0.51}$ & $92.95_{0.79}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{90.51}_{0.72}$ & $\\mathbf{91.70}_{0.44}$ & $\\mathbf{92.37}_{0.46}$ & $\\mathbf{92.82}_{0.63}$ & $\\mathbf{93.08}_{0.77}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$93.74_{0.42}$} & \\textcolor{gray}{$94.59_{0.37}$} & \\textcolor{gray}{$95.27_{0.38}$} & \\textcolor{gray}{$95.52_{0.52}$} & \\textcolor{gray}{$95.59_{0.77}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$91.29_{0.41}$} & \\textcolor{gray}{$92.29_{0.30}$} & \\textcolor{gray}{$92.90_{0.45}$} & \\textcolor{gray}{$93.01_{0.67}$} & \\textcolor{gray}{$93.33_{0.71}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{WikiCS} \\\\ \\hline\n",
      "N2V (inductive) & $67.78_{2.68}$ & $74.22_{1.65}$ & $78.21_{0.69}$ & $80.40_{0.45}$ & $81.62_{0.86}$ \\\\\n",
      "Feature Propagation & $74.77_{2.27}$ & $78.04_{1.00}$ & $80.17_{0.68}$ & $81.03_{0.68}$ & $81.93_{1.08}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{78.91}_{0.61}$ & $\\mathbf{80.19}_{0.70}$ & $\\mathbf{81.28}_{0.61}$ & $\\mathbf{81.73}_{0.76}$ & $\\mathbf{82.37}_{1.01}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$80.75_{0.64}$} & \\textcolor{gray}{$82.56_{0.81}$} & \\textcolor{gray}{$84.28_{0.55}$} & \\textcolor{gray}{$85.21_{0.63}$} & \\textcolor{gray}{$85.88_{0.70}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$79.75_{0.41}$} & \\textcolor{gray}{$80.93_{0.64}$} & \\textcolor{gray}{$81.88_{0.55}$} & \\textcolor{gray}{$82.30_{0.65}$} & \\textcolor{gray}{$82.81_{0.68}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Actor} \\\\ \\hline\n",
      "N2V (inductive) & $25.14_{1.09}$ & $\\mathbf{25.56}_{0.90}$ & $\\mathbf{25.54}_{1.15}$ & $\\mathbf{25.42}_{1.03}$ & $25.68_{1.42}$ \\\\\n",
      "Feature Propagation & $\\mathbf{25.22}_{1.29}$ & $25.39_{1.06}$ & $25.14_{0.59}$ & $25.09_{1.42}$ & $25.05_{1.34}$ \\\\\n",
      "\\textbf{iN2V} (own) & $25.18_{0.97}$ & $25.50_{0.70}$ & $25.40_{0.99}$ & $25.16_{0.92}$ & $\\mathbf{25.79}_{2.27}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$31.77_{0.71}$} & \\textcolor{gray}{$33.84_{0.91}$} & \\textcolor{gray}{$36.48_{0.54}$} & \\textcolor{gray}{$37.38_{0.73}$} & \\textcolor{gray}{$36.71_{1.23}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$25.50_{0.76}$} & \\textcolor{gray}{$25.56_{0.95}$} & \\textcolor{gray}{$25.41_{0.74}$} & \\textcolor{gray}{$24.26_{1.18}$} & \\textcolor{gray}{$24.55_{1.70}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Amazon-ratings} \\\\ \\hline\n",
      "N2V (inductive) & $37.47_{0.47}$ & $40.69_{0.63}$ & $44.71_{0.85}$ & $46.98_{0.68}$ & $49.47_{1.07}$ \\\\\n",
      "Feature Propagation & $38.97_{0.76}$ & $41.68_{0.76}$ & $\\mathbf{45.72}_{0.75}$ & $48.03_{0.67}$ & $50.04_{1.42}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{40.02}_{0.79}$ & $\\mathbf{42.01}_{0.48}$ & $45.48_{0.57}$ & $\\mathbf{50.39}_{0.48}$ & $\\mathbf{50.38}_{2.22}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$39.20_{1.06}$} & \\textcolor{gray}{$41.66_{0.70}$} & \\textcolor{gray}{$48.07_{0.58}$} & \\textcolor{gray}{$53.09_{0.69}$} & \\textcolor{gray}{$57.34_{0.97}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$41.82_{0.66}$} & \\textcolor{gray}{$43.69_{0.52}$} & \\textcolor{gray}{$46.31_{0.78}$} & \\textcolor{gray}{$48.40_{0.55}$} & \\textcolor{gray}{$49.80_{0.94}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Roman-empire} \\\\ \\hline\n",
      "N2V (inductive) & $\\mathbf{13.96}_{0.35}$ & $\\mathbf{14.10}_{0.32}$ & $\\mathbf{15.77}_{0.76}$ & $15.98_{1.55}$ & $16.81_{2.94}$ \\\\\n",
      "Feature Propagation & $13.23_{1.44}$ & $13.89_{0.44}$ & $15.49_{0.67}$ & $\\mathbf{16.13}_{1.04}$ & $\\mathbf{21.97}_{1.25}$ \\\\\n",
      "\\textbf{iN2V} (own) & $13.79_{0.39}$ & $13.86_{0.29}$ & $14.48_{0.63}$ & $15.33_{1.12}$ & $18.55_{1.23}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$66.09_{0.75}$} & \\textcolor{gray}{$70.28_{0.63}$} & \\textcolor{gray}{$74.41_{0.47}$} & \\textcolor{gray}{$78.56_{0.50}$} & \\textcolor{gray}{$82.90_{1.09}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$13.82_{0.22}$} & \\textcolor{gray}{$13.86_{0.37}$} & \\textcolor{gray}{$15.35_{1.53}$} & \\textcolor{gray}{$21.46_{0.46}$} & \\textcolor{gray}{$27.46_{1.36}$} \\\\ \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_res_x([\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"WCS\", \"Act\", \"Ar\", \"Re\"], splits = [\"145\", \"24\", \"43\",\"62\", \"81\"], model = \"Sage\", datamode = \"emb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1d6aac6-c4d7-46cb-99f4-0fe6a405f4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn{6}{l}{Cora} \\\\ \\hline\n",
      "N2V (inductive) & $66.48_{1.68}$ & $70.54_{1.20}$ & $75.47_{1.91}$ & $76.09_{2.08}$ & $76.27_{1.68}$ \\\\\n",
      "Feature Propagation & $\\mathbf{82.24}_{1.06}$ & $83.49_{1.26}$ & $83.83_{1.49}$ & $85.59_{1.24}$ & $85.54_{1.48}$ \\\\\n",
      "\\textbf{iN2V} (own) & $82.01_{1.38}$ & $\\mathbf{83.97}_{1.35}$ & $\\mathbf{85.83}_{1.45}$ & $\\mathbf{85.81}_{1.77}$ & $\\mathbf{86.49}_{1.62}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$66.98_{1.70}$} & \\textcolor{gray}{$71.34_{1.79}$} & \\textcolor{gray}{$75.94_{1.38}$} & \\textcolor{gray}{$78.78_{1.11}$} & \\textcolor{gray}{$79.23_{1.95}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$81.94_{1.39}$} & \\textcolor{gray}{$83.52_{1.13}$} & \\textcolor{gray}{$85.99_{1.10}$} & \\textcolor{gray}{$86.99_{1.44}$} & \\textcolor{gray}{$86.13_{1.69}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Citeseer} \\\\ \\hline\n",
      "N2V (inductive) & $66.06_{1.31}$ & $70.04_{1.29}$ & $72.33_{1.07}$ & $73.58_{1.14}$ & $74.68_{2.12}$ \\\\\n",
      "Feature Propagation & $\\mathbf{68.48}_{1.20}$ & $\\mathbf{72.13}_{1.08}$ & $\\mathbf{74.37}_{1.26}$ & $75.29_{0.97}$ & $76.34_{1.66}$ \\\\\n",
      "\\textbf{iN2V} (own) & $66.98_{1.14}$ & $71.35_{0.83}$ & $74.13_{1.23}$ & $\\mathbf{75.85}_{0.87}$ & $\\mathbf{77.09}_{2.79}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$66.60_{1.56}$} & \\textcolor{gray}{$70.53_{1.04}$} & \\textcolor{gray}{$73.23_{1.17}$} & \\textcolor{gray}{$74.56_{1.04}$} & \\textcolor{gray}{$75.20_{2.10}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$69.40_{0.88}$} & \\textcolor{gray}{$72.58_{1.28}$} & \\textcolor{gray}{$74.78_{0.93}$} & \\textcolor{gray}{$75.94_{1.03}$} & \\textcolor{gray}{$77.27_{2.34}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Pubmed} \\\\ \\hline\n",
      "N2V (inductive) & $83.94_{0.42}$ & $85.55_{0.42}$ & $86.73_{0.46}$ & $87.21_{0.58}$ & $87.40_{0.92}$ \\\\\n",
      "Feature Propagation & $\\mathbf{85.59}_{0.26}$ & $87.06_{0.41}$ & $\\mathbf{88.71}_{0.49}$ & $89.33_{0.39}$ & $\\mathbf{89.95}_{0.60}$ \\\\\n",
      "\\textbf{iN2V} (own) & $85.38_{0.39}$ & $\\mathbf{87.07}_{0.39}$ & $88.69_{0.60}$ & $\\mathbf{89.46}_{0.51}$ & $89.90_{0.51}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$84.11_{0.21}$} & \\textcolor{gray}{$86.05_{0.40}$} & \\textcolor{gray}{$87.72_{0.40}$} & \\textcolor{gray}{$88.63_{0.60}$} & \\textcolor{gray}{$89.10_{0.63}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$86.16_{0.28}$} & \\textcolor{gray}{$87.95_{0.47}$} & \\textcolor{gray}{$88.73_{0.37}$} & \\textcolor{gray}{$89.42_{0.47}$} & \\textcolor{gray}{$89.89_{0.59}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Computers} \\\\ \\hline\n",
      "N2V (inductive) & $80.41_{0.60}$ & $82.98_{0.65}$ & $84.08_{0.76}$ & $84.34_{0.97}$ & $84.72_{0.87}$ \\\\\n",
      "Feature Propagation & $85.39_{0.67}$ & $87.03_{0.33}$ & $89.14_{0.40}$ & $89.91_{0.70}$ & $90.15_{0.78}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{88.63}_{0.22}$ & $\\mathbf{89.75}_{0.22}$ & $\\mathbf{90.67}_{0.24}$ & $\\mathbf{90.99}_{0.52}$ & $\\mathbf{90.95}_{0.59}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$82.15_{0.63}$} & \\textcolor{gray}{$84.08_{0.65}$} & \\textcolor{gray}{$85.57_{0.53}$} & \\textcolor{gray}{$86.00_{0.77}$} & \\textcolor{gray}{$86.56_{0.58}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$89.36_{0.39}$} & \\textcolor{gray}{$90.61_{0.23}$} & \\textcolor{gray}{$91.19_{0.39}$} & \\textcolor{gray}{$91.47_{0.40}$} & \\textcolor{gray}{$91.30_{0.47}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Photo} \\\\ \\hline\n",
      "N2V (inductive) & $85.73_{2.20}$ & $86.22_{1.22}$ & $90.71_{0.59}$ & $90.90_{0.65}$ & $91.76_{0.70}$ \\\\\n",
      "Feature Propagation & $92.75_{0.44}$ & $93.93_{0.28}$ & $94.73_{0.40}$ & $94.75_{0.51}$ & $95.31_{0.62}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{93.99}_{0.36}$ & $\\mathbf{94.55}_{0.29}$ & $\\mathbf{95.33}_{0.32}$ & $\\mathbf{95.42}_{0.45}$ & $\\mathbf{95.70}_{0.74}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$89.32_{0.59}$} & \\textcolor{gray}{$90.85_{0.55}$} & \\textcolor{gray}{$91.96_{0.55}$} & \\textcolor{gray}{$92.41_{0.60}$} & \\textcolor{gray}{$92.92_{0.87}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$94.07_{0.46}$} & \\textcolor{gray}{$94.93_{0.29}$} & \\textcolor{gray}{$95.36_{0.28}$} & \\textcolor{gray}{$95.73_{0.51}$} & \\textcolor{gray}{$95.63_{0.53}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{WikiCS} \\\\ \\hline\n",
      "N2V (inductive) & $73.16_{1.17}$ & $75.60_{0.78}$ & $76.79_{0.51}$ & $77.30_{0.73}$ & $76.71_{0.97}$ \\\\\n",
      "Feature Propagation & $78.14_{1.23}$ & $80.58_{0.70}$ & $82.91_{0.53}$ & $83.98_{1.01}$ & $84.78_{1.15}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{81.78}_{0.50}$ & $\\mathbf{83.47}_{0.47}$ & $\\mathbf{84.77}_{0.55}$ & $\\mathbf{85.41}_{0.76}$ & $\\mathbf{86.26}_{0.87}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$76.85_{0.64}$} & \\textcolor{gray}{$78.76_{0.66}$} & \\textcolor{gray}{$80.43_{0.64}$} & \\textcolor{gray}{$81.56_{0.78}$} & \\textcolor{gray}{$82.38_{1.06}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$82.26_{0.55}$} & \\textcolor{gray}{$83.73_{0.65}$} & \\textcolor{gray}{$84.70_{0.41}$} & \\textcolor{gray}{$85.44_{0.49}$} & \\textcolor{gray}{$85.50_{0.77}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Actor} \\\\ \\hline\n",
      "N2V (inductive) & $33.99_{0.93}$ & $35.54_{1.01}$ & $36.64_{0.85}$ & $38.22_{0.70}$ & $\\mathbf{38.08}_{1.62}$ \\\\\n",
      "Feature Propagation & $33.91_{0.72}$ & $\\mathbf{35.94}_{0.44}$ & $36.63_{0.76}$ & $\\mathbf{38.22}_{0.72}$ & $37.43_{1.16}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{35.15}_{1.06}$ & $35.92_{0.56}$ & $\\mathbf{37.66}_{0.96}$ & $37.72_{0.89}$ & $38.07_{1.12}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$35.13_{0.51}$} & \\textcolor{gray}{$36.20_{0.67}$} & \\textcolor{gray}{$37.79_{0.62}$} & \\textcolor{gray}{$38.75_{0.86}$} & \\textcolor{gray}{$37.87_{1.53}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$32.35_{0.94}$} & \\textcolor{gray}{$34.75_{0.83}$} & \\textcolor{gray}{$36.35_{1.01}$} & \\textcolor{gray}{$37.30_{1.52}$} & \\textcolor{gray}{$37.83_{1.43}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Amazon-ratings} \\\\ \\hline\n",
      "N2V (inductive) & $37.36_{0.39}$ & $37.93_{0.59}$ & $38.30_{0.50}$ & $38.51_{0.69}$ & $38.57_{1.67}$ \\\\\n",
      "Feature Propagation & $39.86_{0.72}$ & $42.92_{1.07}$ & $47.89_{0.95}$ & $50.90_{0.70}$ & $53.07_{1.18}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{41.24}_{0.74}$ & $\\mathbf{45.64}_{0.67}$ & $\\mathbf{51.91}_{0.40}$ & $\\mathbf{55.96}_{0.81}$ & $\\mathbf{58.44}_{0.67}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$37.80_{0.51}$} & \\textcolor{gray}{$41.77_{0.61}$} & \\textcolor{gray}{$47.20_{0.56}$} & \\textcolor{gray}{$50.82_{0.77}$} & \\textcolor{gray}{$54.00_{0.69}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$41.73_{0.66}$} & \\textcolor{gray}{$45.42_{0.53}$} & \\textcolor{gray}{$50.92_{0.58}$} & \\textcolor{gray}{$53.93_{0.52}$} & \\textcolor{gray}{$56.78_{1.45}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Roman-empire} \\\\ \\hline\n",
      "N2V (inductive) & $\\mathbf{62.37}_{0.51}$ & $\\mathbf{64.35}_{0.38}$ & $65.67_{0.18}$ & $\\mathbf{66.48}_{0.70}$ & $\\mathbf{66.54}_{1.07}$ \\\\\n",
      "Feature Propagation & $62.02_{0.41}$ & $64.16_{0.39}$ & $\\mathbf{65.81}_{0.33}$ & $65.96_{0.51}$ & $66.34_{1.11}$ \\\\\n",
      "\\textbf{iN2V} (own) & $60.57_{0.39}$ & $63.57_{0.30}$ & $65.36_{0.35}$ & $65.83_{0.80}$ & $65.99_{1.12}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$63.46_{0.43}$} & \\textcolor{gray}{$65.05_{0.31}$} & \\textcolor{gray}{$66.47_{0.41}$} & \\textcolor{gray}{$66.83_{0.71}$} & \\textcolor{gray}{$66.55_{1.02}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$60.28_{0.27}$} & \\textcolor{gray}{$63.54_{0.28}$} & \\textcolor{gray}{$65.09_{0.37}$} & \\textcolor{gray}{$65.99_{0.62}$} & \\textcolor{gray}{$66.32_{1.23}$} \\\\ \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_res_x([\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"WCS\", \"Act\", \"Ar\", \"Re\"], splits = [\"145\", \"24\", \"43\",\"62\", \"81\"], model = \"MLP\", datamode = \"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c05f210-1560-425b-91d6-c8832cb59b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn{6}{l}{Cora} \\\\ \\hline\n",
      "N2V (inductive) & $73.97_{3.35}$ & $81.92_{1.84}$ & $\\mathbf{85.97}_{1.67}$ & $86.97_{0.96}$ & $87.38_{0.79}$ \\\\\n",
      "Feature Propagation & $80.92_{1.29}$ & $\\mathbf{83.49}_{1.54}$ & $85.33_{1.44}$ & $\\mathbf{87.32}_{1.07}$ & $\\mathbf{87.75}_{1.12}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{81.01}_{1.42}$ & $83.28_{1.41}$ & $85.92_{1.17}$ & $86.77_{1.42}$ & $87.60_{1.81}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$75.27_{2.63}$} & \\textcolor{gray}{$83.37_{1.17}$} & \\textcolor{gray}{$86.23_{1.77}$} & \\textcolor{gray}{$86.99_{0.86}$} & \\textcolor{gray}{$87.05_{1.20}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$82.43_{0.77}$} & \\textcolor{gray}{$84.45_{1.23}$} & \\textcolor{gray}{$86.50_{1.04}$} & \\textcolor{gray}{$86.85_{1.16}$} & \\textcolor{gray}{$88.30_{1.47}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Citeseer} \\\\ \\hline\n",
      "N2V (inductive) & $\\mathbf{68.52}_{2.47}$ & $\\mathbf{72.49}_{1.14}$ & $74.53_{1.28}$ & $75.85_{1.40}$ & $\\mathbf{76.76}_{1.85}$ \\\\\n",
      "Feature Propagation & $68.00_{1.58}$ & $71.72_{1.15}$ & $\\mathbf{74.77}_{0.97}$ & $\\mathbf{76.39}_{0.99}$ & $76.46_{1.73}$ \\\\\n",
      "\\textbf{iN2V} (own) & $67.11_{1.47}$ & $71.14_{0.60}$ & $73.99_{1.47}$ & $75.77_{1.29}$ & $75.50_{1.63}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$69.85_{1.42}$} & \\textcolor{gray}{$72.86_{0.98}$} & \\textcolor{gray}{$74.93_{1.56}$} & \\textcolor{gray}{$76.39_{1.05}$} & \\textcolor{gray}{$76.82_{1.77}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$71.08_{1.04}$} & \\textcolor{gray}{$73.21_{1.12}$} & \\textcolor{gray}{$74.76_{0.81}$} & \\textcolor{gray}{$76.14_{1.43}$} & \\textcolor{gray}{$76.82_{1.77}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Pubmed} \\\\ \\hline\n",
      "N2V (inductive) & $\\mathbf{84.33}_{0.46}$ & $\\mathbf{86.06}_{0.59}$ & $87.32_{0.38}$ & $87.32_{0.39}$ & $88.01_{0.78}$ \\\\\n",
      "Feature Propagation & $82.99_{0.64}$ & $85.46_{0.46}$ & $86.74_{0.55}$ & $87.97_{0.40}$ & $88.96_{0.63}$ \\\\\n",
      "\\textbf{iN2V} (own) & $83.02_{0.72}$ & $85.09_{0.37}$ & $\\mathbf{87.51}_{0.51}$ & $\\mathbf{88.59}_{0.35}$ & $\\mathbf{89.39}_{0.72}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$85.95_{0.47}$} & \\textcolor{gray}{$86.99_{0.28}$} & \\textcolor{gray}{$88.32_{0.48}$} & \\textcolor{gray}{$89.25_{0.44}$} & \\textcolor{gray}{$89.85_{0.56}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$85.36_{0.45}$} & \\textcolor{gray}{$87.28_{0.46}$} & \\textcolor{gray}{$87.12_{0.44}$} & \\textcolor{gray}{$88.42_{0.36}$} & \\textcolor{gray}{$89.02_{0.57}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Computers} \\\\ \\hline\n",
      "N2V (inductive) & $86.64_{1.11}$ & $89.05_{0.63}$ & $90.72_{0.36}$ & $91.33_{0.56}$ & $91.70_{0.55}$ \\\\\n",
      "Feature Propagation & $87.77_{0.57}$ & $89.93_{0.39}$ & $91.30_{0.34}$ & $91.85_{0.52}$ & $\\mathbf{92.13}_{0.45}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{88.90}_{0.36}$ & $\\mathbf{90.50}_{0.22}$ & $\\mathbf{91.43}_{0.36}$ & $\\mathbf{91.91}_{0.49}$ & $91.72_{0.37}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$87.52_{0.48}$} & \\textcolor{gray}{$89.76_{0.40}$} & \\textcolor{gray}{$91.12_{0.20}$} & \\textcolor{gray}{$91.49_{0.58}$} & \\textcolor{gray}{$91.50_{0.48}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$90.48_{0.37}$} & \\textcolor{gray}{$91.59_{0.36}$} & \\textcolor{gray}{$92.09_{0.36}$} & \\textcolor{gray}{$92.35_{0.36}$} & \\textcolor{gray}{$92.20_{0.37}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Photo} \\\\ \\hline\n",
      "N2V (inductive) & $91.97_{1.73}$ & $93.87_{0.70}$ & $94.94_{0.44}$ & $95.37_{0.60}$ & $95.56_{0.81}$ \\\\\n",
      "Feature Propagation & $93.25_{0.54}$ & $94.40_{0.41}$ & $95.11_{0.41}$ & $95.54_{0.54}$ & $\\mathbf{95.73}_{0.77}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{93.87}_{0.52}$ & $\\mathbf{94.68}_{0.33}$ & $\\mathbf{95.26}_{0.28}$ & $\\mathbf{95.59}_{0.42}$ & $95.63_{0.74}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$93.74_{0.42}$} & \\textcolor{gray}{$94.59_{0.37}$} & \\textcolor{gray}{$95.27_{0.38}$} & \\textcolor{gray}{$95.52_{0.52}$} & \\textcolor{gray}{$95.59_{0.77}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$94.49_{0.46}$} & \\textcolor{gray}{$94.97_{0.28}$} & \\textcolor{gray}{$95.50_{0.22}$} & \\textcolor{gray}{$95.69_{0.32}$} & \\textcolor{gray}{$95.79_{1.00}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{WikiCS} \\\\ \\hline\n",
      "N2V (inductive) & $76.50_{1.34}$ & $79.99_{0.65}$ & $82.23_{0.75}$ & $83.76_{0.63}$ & $84.79_{0.87}$ \\\\\n",
      "Feature Propagation & $79.58_{0.88}$ & $82.09_{0.86}$ & $84.10_{0.63}$ & $84.95_{0.77}$ & $\\mathbf{85.77}_{0.76}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{81.50}_{0.64}$ & $\\mathbf{83.38}_{0.58}$ & $\\mathbf{84.62}_{0.47}$ & $\\mathbf{85.25}_{0.47}$ & $85.73_{0.70}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$80.75_{0.64}$} & \\textcolor{gray}{$82.56_{0.81}$} & \\textcolor{gray}{$84.28_{0.55}$} & \\textcolor{gray}{$85.21_{0.63}$} & \\textcolor{gray}{$85.88_{0.70}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$81.91_{0.52}$} & \\textcolor{gray}{$83.37_{0.67}$} & \\textcolor{gray}{$84.66_{0.64}$} & \\textcolor{gray}{$85.56_{0.61}$} & \\textcolor{gray}{$86.10_{0.70}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Actor} \\\\ \\hline\n",
      "N2V (inductive) & $32.04_{0.94}$ & $33.44_{0.73}$ & $35.14_{0.93}$ & $36.13_{1.52}$ & $36.05_{2.46}$ \\\\\n",
      "Feature Propagation & $\\mathbf{32.51}_{0.51}$ & $33.08_{0.73}$ & $34.89_{1.40}$ & $\\mathbf{36.19}_{0.88}$ & $36.25_{1.13}$ \\\\\n",
      "\\textbf{iN2V} (own) & $32.12_{0.73}$ & $\\mathbf{33.53}_{0.63}$ & $\\mathbf{35.38}_{1.24}$ & $36.03_{0.64}$ & $\\mathbf{36.66}_{2.24}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$31.77_{0.71}$} & \\textcolor{gray}{$33.84_{0.91}$} & \\textcolor{gray}{$36.48_{0.54}$} & \\textcolor{gray}{$37.38_{0.73}$} & \\textcolor{gray}{$36.71_{1.23}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$30.82_{1.12}$} & \\textcolor{gray}{$32.52_{0.71}$} & \\textcolor{gray}{$34.46_{0.75}$} & \\textcolor{gray}{$35.45_{1.18}$} & \\textcolor{gray}{$36.54_{2.27}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Amazon-ratings} \\\\ \\hline\n",
      "N2V (inductive) & $39.14_{0.57}$ & $41.43_{0.65}$ & $44.99_{1.04}$ & $48.97_{1.16}$ & $50.98_{1.35}$ \\\\\n",
      "Feature Propagation & $39.50_{0.98}$ & $42.93_{0.82}$ & $48.31_{0.67}$ & $51.28_{0.63}$ & $53.90_{1.14}$ \\\\\n",
      "\\textbf{iN2V} (own) & $\\mathbf{40.29}_{0.67}$ & $\\mathbf{43.72}_{0.70}$ & $\\mathbf{50.99}_{0.84}$ & $\\mathbf{55.42}_{0.83}$ & $\\mathbf{58.70}_{0.84}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$39.20_{1.06}$} & \\textcolor{gray}{$41.66_{0.70}$} & \\textcolor{gray}{$48.07_{0.58}$} & \\textcolor{gray}{$53.09_{0.69}$} & \\textcolor{gray}{$57.34_{0.97}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$42.38_{0.53}$} & \\textcolor{gray}{$46.31_{0.72}$} & \\textcolor{gray}{$51.60_{0.76}$} & \\textcolor{gray}{$54.84_{1.11}$} & \\textcolor{gray}{$57.05_{1.31}$} \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Roman-empire} \\\\ \\hline\n",
      "N2V (inductive) & $\\mathbf{64.71}_{0.66}$ & $\\mathbf{68.52}_{0.65}$ & $\\mathbf{72.78}_{0.31}$ & $\\mathbf{76.68}_{0.64}$ & $\\mathbf{81.16}_{1.65}$ \\\\\n",
      "Feature Propagation & $62.25_{0.46}$ & $67.03_{0.44}$ & $71.74_{0.25}$ & $76.02_{0.75}$ & $80.31_{0.97}$ \\\\\n",
      "\\textbf{iN2V} (own) & $59.29_{0.87}$ & $66.19_{0.59}$ & $71.50_{0.43}$ & $76.07_{0.49}$ & $80.48_{0.75}$ \\\\ \\hline\n",
      "\\textcolor{gray}{Original features} & \\textcolor{gray}{$66.09_{0.75}$} & \\textcolor{gray}{$70.28_{0.63}$} & \\textcolor{gray}{$74.41_{0.47}$} & \\textcolor{gray}{$78.56_{0.50}$} & \\textcolor{gray}{$82.90_{1.09}$} \\\\\n",
      "\\textcolor{gray}{N2V (transductive)} & \\textcolor{gray}{$66.95_{0.77}$} & \\textcolor{gray}{$71.66_{0.47}$} & \\textcolor{gray}{$78.39_{0.46}$} & \\textcolor{gray}{$82.41_{0.48}$} & \\textcolor{gray}{$84.67_{0.95}$} \\\\ \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_res_x([\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"WCS\", \"Act\", \"Ar\", \"Re\"], splits = [\"145\", \"24\", \"43\",\"62\", \"81\"], model = \"Sage\", datamode = \"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e842021-f254-4cca-ab45-779671db3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare in2v variants \n",
    "def print_res_y(dss, splits = [\"145\", \"24\", \"43\", \"81\"], model = \"MLP\", datamode = \"emb\"):\n",
    "    for ds in dss:\n",
    "        ls_train, ls_naive, ls_post, ls_loss, ls_sampling = [\"N2V (inductive)\"], [\"frozen ($\\\\lambda = 1$)\"], [\"post-hoc\"], [\"p-h w losses\"], [\"p-h w sampling\"]\n",
    "        for split in splits:\n",
    "            tmp = \"../results_comb/F_\"+ds+\"_\"+split+\"_\"+model\n",
    "            ls = [pd.read_pickle(tmp+\".pkl\")]\n",
    "            if Path(tmp+\"_e.pkl\").exists():\n",
    "                ls.append(pd.read_pickle(tmp+\"_e.pkl\"))\n",
    "            if Path(tmp+\"_jk.pkl\").exists():\n",
    "                ls.append(pd.read_pickle(tmp+\"_jk.pkl\"))\n",
    "\n",
    "            \n",
    "            \n",
    "            df = pd.concat(ls, ignore_index=True).drop([\n",
    "                \"val_loss\", \"test_loss\", \"loss_hist\", \"valtest_time\", \"train_time\", \"record_train\", \"save_models\", \"batch_size\", \"batch_size_test\", \"batch_size_val\", \"alpha\", \"delay\", \"save_embeds\",\n",
    "                \"context_size\", \"num_negative_samples\", \"max_iter\", \"patience\"], axis=1, errors=\"ignore\")\n",
    "            \n",
    "            res_ls = [get_table_x(df[df.datamode.eq(datamode+\"_tr\")]), get_table_x(df[df.datamode.eq(datamode+\"_ba\")]), get_table_x(df[df.datamode.eq(datamode+\"_po\")]), get_table_x(df[df.datamode.eq(datamode+\"_lo\")]),  get_table_x(df[df.datamode.eq(datamode+\"_re\")])]\n",
    "            mx = max(res_ls)[0]\n",
    "            res_ls=[prbest(x) if x[0]==mx else prother(x) for x in res_ls]\n",
    "\n",
    "            ls_train.append(res_ls[0])\n",
    "            ls_naive.append(res_ls[1])\n",
    "            ls_post.append(res_ls[2])\n",
    "            ls_loss.append(res_ls[3])\n",
    "            ls_sampling.append(res_ls[4])\n",
    "\n",
    "            \n",
    "        ds_n = {\"Cora\":\"Cora\", \"Cite\":\"Citeseer\", \"PM\":\"Pubmed\", \"Com\":\"Computers\", \"Pho\":\"Photo\", \"Act\":\"Actor\", \"Ar\":\"Amazon-ratings\", \"Re\":\"Roman-empire\", \"WCS\":\"WikiCS\"}[ds]\n",
    "\n",
    "        print(r\"\\multicolumn{\"+str(len(ls_train))+\"}{l}{\"+ds_n+\"} \\\\\\\\ \\\\hline\")\n",
    "        print(\" & \".join(ls_train)+\" \\\\\\\\\")\n",
    "        print(\" & \".join(ls_naive)+\" \\\\\\\\\")\n",
    "        print(\" & \".join(ls_post)+\" \\\\\\\\\")\n",
    "        print(\" & \".join(ls_loss)+\" \\\\\\\\\")\n",
    "        print(\" & \".join(ls_sampling)+\" \\\\\\\\ \\\\midrule\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48de1bf2-f844-42e3-932f-514e154ddf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn{5}{l}{Cora} \\\\ \\hline\n",
      "N2V (inductive) & $42.18_{3.52}$ & $59.91_{4.15}$ & $75.07_{1.92}$ & $84.50_{1.44}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $74.76_{2.08}$ & $76.86_{1.66}$ & $80.75_{1.17}$ & $84.13_{1.99}$ \\\\\n",
      "post-hoc & $\\mathbf{79.20}_{1.80}$ & $79.44_{1.55}$ & $\\mathbf{83.45}_{1.08}$ & $84.46_{2.08}$ \\\\\n",
      "p-h w losses & $78.88_{1.45}$ & $80.50_{1.26}$ & $83.30_{1.09}$ & $\\mathbf{84.69}_{1.65}$ \\\\\n",
      "p-h w sampling & $79.11_{1.77}$ & $\\mathbf{80.94}_{1.58}$ & $82.02_{1.34}$ & $84.02_{1.88}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{Citeseer} \\\\ \\hline\n",
      "N2V (inductive) & $34.17_{3.43}$ & $42.76_{2.15}$ & $56.12_{3.24}$ & $68.89_{2.61}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $56.22_{1.72}$ & $59.00_{2.16}$ & $\\mathbf{63.63}_{1.47}$ & $68.92_{2.26}$ \\\\\n",
      "post-hoc & $57.25_{1.27}$ & $60.59_{1.52}$ & $62.88_{1.80}$ & $\\mathbf{69.13}_{2.33}$ \\\\\n",
      "p-h w losses & $57.25_{1.55}$ & $\\mathbf{60.78}_{1.78}$ & $62.76_{1.90}$ & $68.92_{2.07}$ \\\\\n",
      "p-h w sampling & $\\mathbf{57.88}_{0.91}$ & $57.92_{3.47}$ & $63.02_{1.88}$ & $68.83_{2.37}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{Pubmed} \\\\ \\hline\n",
      "N2V (inductive) & $66.02_{5.57}$ & $74.73_{2.36}$ & $79.84_{1.78}$ & $82.61_{0.52}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $75.99_{0.52}$ & $78.37_{1.02}$ & $81.31_{0.55}$ & $82.88_{0.72}$ \\\\\n",
      "post-hoc & $\\mathbf{79.93}_{0.50}$ & $\\mathbf{80.80}_{0.46}$ & $81.80_{0.49}$ & $82.90_{0.73}$ \\\\\n",
      "p-h w losses & $79.75_{0.61}$ & $80.75_{0.61}$ & $81.91_{0.54}$ & $82.59_{0.63}$ \\\\\n",
      "p-h w sampling & $79.68_{0.55}$ & $80.59_{0.54}$ & $\\mathbf{82.14}_{0.43}$ & $\\mathbf{82.94}_{0.60}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{Computers} \\\\ \\hline\n",
      "N2V (inductive) & $77.64_{2.81}$ & $84.44_{0.84}$ & $87.18_{0.77}$ & $89.35_{0.70}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $85.40_{0.54}$ & $87.45_{0.42}$ & $89.05_{0.56}$ & $90.24_{0.59}$ \\\\\n",
      "post-hoc & $87.94_{0.43}$ & $89.62_{0.43}$ & $90.66_{0.38}$ & $91.07_{0.64}$ \\\\\n",
      "p-h w losses & $87.84_{0.32}$ & $\\mathbf{89.67}_{0.40}$ & $\\mathbf{90.84}_{0.37}$ & $91.24_{0.52}$ \\\\\n",
      "p-h w sampling & $\\mathbf{88.36}_{0.58}$ & $89.26_{0.50}$ & $90.53_{0.62}$ & $\\mathbf{91.38}_{0.51}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{Photo} \\\\ \\hline\n",
      "N2V (inductive) & $85.48_{1.28}$ & $87.73_{1.40}$ & $90.98_{0.71}$ & $92.21_{0.96}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $88.64_{0.95}$ & $90.31_{0.50}$ & $91.78_{0.47}$ & $92.76_{0.78}$ \\\\\n",
      "post-hoc & $90.49_{0.67}$ & $91.62_{0.35}$ & $92.40_{0.53}$ & $\\mathbf{93.08}_{0.77}$ \\\\\n",
      "p-h w losses & $\\mathbf{90.51}_{0.72}$ & $91.67_{0.30}$ & $92.37_{0.46}$ & $92.95_{1.00}$ \\\\\n",
      "p-h w sampling & $90.42_{0.54}$ & $\\mathbf{91.70}_{0.44}$ & $\\mathbf{92.50}_{0.50}$ & $92.88_{0.81}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{WikiCS} \\\\ \\hline\n",
      "N2V (inductive) & $67.78_{2.68}$ & $74.22_{1.65}$ & $78.21_{0.69}$ & $81.62_{0.86}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $75.62_{0.63}$ & $77.96_{0.56}$ & $79.83_{0.60}$ & $81.55_{0.58}$ \\\\\n",
      "post-hoc & $78.78_{0.74}$ & $80.07_{0.88}$ & $81.01_{0.63}$ & $\\mathbf{82.55}_{0.72}$ \\\\\n",
      "p-h w losses & $78.72_{0.55}$ & $80.06_{0.71}$ & $81.20_{0.48}$ & $82.43_{0.69}$ \\\\\n",
      "p-h w sampling & $\\mathbf{78.91}_{0.61}$ & $\\mathbf{80.19}_{0.70}$ & $\\mathbf{81.28}_{0.61}$ & $82.37_{1.01}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{Actor} \\\\ \\hline\n",
      "N2V (inductive) & $25.14_{1.09}$ & $25.56_{0.90}$ & $25.54_{1.15}$ & $25.68_{1.42}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $25.18_{0.97}$ & $22.94_{0.83}$ & $25.40_{0.99}$ & $24.97_{1.10}$ \\\\\n",
      "post-hoc & $\\mathbf{25.40}_{1.08}$ & $\\mathbf{25.82}_{0.99}$ & $25.34_{0.85}$ & $25.39_{1.18}$ \\\\\n",
      "p-h w losses & $25.06_{1.06}$ & $24.95_{0.78}$ & $\\mathbf{25.85}_{0.79}$ & $\\mathbf{25.79}_{2.27}$ \\\\\n",
      "p-h w sampling & $25.39_{1.14}$ & $25.50_{0.70}$ & $25.71_{0.93}$ & $24.17_{1.69}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{Amazon-ratings} \\\\ \\hline\n",
      "N2V (inductive) & $37.47_{0.47}$ & $40.69_{0.63}$ & $44.71_{0.85}$ & $49.47_{1.07}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $36.70_{1.51}$ & $41.76_{0.91}$ & $\\mathbf{45.48}_{0.57}$ & $50.19_{1.10}$ \\\\\n",
      "post-hoc & $38.68_{1.00}$ & $\\mathbf{42.12}_{0.66}$ & $45.20_{0.70}$ & $48.40_{1.23}$ \\\\\n",
      "p-h w losses & $40.02_{0.79}$ & $42.01_{0.48}$ & $45.46_{0.82}$ & $\\mathbf{50.38}_{2.22}$ \\\\\n",
      "p-h w sampling & $\\mathbf{40.10}_{0.68}$ & $41.92_{0.85}$ & $45.31_{0.74}$ & $48.40_{1.30}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{5}{l}{Roman-empire} \\\\ \\hline\n",
      "N2V (inductive) & $\\mathbf{13.96}_{0.35}$ & $\\mathbf{14.10}_{0.32}$ & $\\mathbf{15.77}_{0.76}$ & $16.81_{2.94}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $13.64_{0.85}$ & $13.88_{0.29}$ & $14.48_{0.63}$ & $17.59_{4.35}$ \\\\\n",
      "post-hoc & $13.31_{1.26}$ & $13.86_{0.29}$ & $13.86_{0.17}$ & $14.89_{1.70}$ \\\\\n",
      "p-h w losses & $13.17_{1.43}$ & $13.84_{0.27}$ & $13.90_{0.26}$ & $16.93_{1.31}$ \\\\\n",
      "p-h w sampling & $13.79_{0.39}$ & $13.59_{0.75}$ & $14.02_{0.41}$ & $\\mathbf{18.55}_{1.23}$ \\\\ \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_res_y([\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"WCS\", \"Act\", \"Ar\", \"Re\"], model = \"Sage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6476fd68-7c20-4948-b833-9e7893ff1f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn{6}{l}{Cora} \\\\ \\hline\n",
      "N2V (inductive) & $30.04_{1.06}$ & $30.07_{1.15}$ & $30.12_{1.05}$ & $29.67_{1.04}$ & $30.70_{2.14}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $74.64_{1.75}$ & $76.71_{1.60}$ & $79.57_{1.24}$ & $81.75_{1.63}$ & $83.51_{1.79}$ \\\\\n",
      "post-hoc & $\\mathbf{79.84}_{1.27}$ & $80.28_{1.80}$ & $83.93_{1.16}$ & $84.00_{1.03}$ & $\\mathbf{85.57}_{2.46}$ \\\\\n",
      "p-h w losses & $79.38_{1.42}$ & $81.07_{1.58}$ & $\\mathbf{83.99}_{1.06}$ & $83.75_{1.51}$ & $85.24_{2.33}$ \\\\\n",
      "p-h w sampling & $79.57_{1.34}$ & $\\mathbf{81.70}_{1.19}$ & $82.71_{0.84}$ & $\\mathbf{84.69}_{0.95}$ & $\\mathbf{85.57}_{2.22}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Citeseer} \\\\ \\hline\n",
      "N2V (inductive) & $19.81_{1.75}$ & $21.43_{1.00}$ & $21.11_{1.27}$ & $21.10_{1.46}$ & $19.82_{3.05}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $54.19_{2.79}$ & $59.75_{1.63}$ & $65.06_{1.69}$ & $68.95_{1.27}$ & $71.59_{1.90}$ \\\\\n",
      "post-hoc & $55.91_{2.26}$ & $61.51_{1.37}$ & $66.47_{1.91}$ & $70.62_{1.37}$ & $72.55_{1.77}$ \\\\\n",
      "p-h w losses & $\\mathbf{58.02}_{1.29}$ & $\\mathbf{61.67}_{1.69}$ & $66.56_{1.90}$ & $\\mathbf{70.69}_{1.30}$ & $73.09_{2.32}$ \\\\\n",
      "p-h w sampling & $57.88_{1.35}$ & $61.40_{1.21}$ & $\\mathbf{66.62}_{1.78}$ & $70.21_{1.59}$ & $\\mathbf{73.27}_{1.73}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Pubmed} \\\\ \\hline\n",
      "N2V (inductive) & $39.45_{0.69}$ & $39.69_{0.77}$ & $40.15_{0.42}$ & $40.01_{0.71}$ & $39.30_{1.06}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $76.61_{0.74}$ & $78.43_{0.75}$ & $80.49_{0.68}$ & $81.45_{0.69}$ & $82.08_{0.79}$ \\\\\n",
      "post-hoc & $\\mathbf{80.47}_{0.35}$ & $\\mathbf{81.77}_{0.40}$ & $82.69_{0.45}$ & $83.42_{0.56}$ & $83.30_{0.60}$ \\\\\n",
      "p-h w losses & $80.42_{0.44}$ & $81.68_{0.39}$ & $82.74_{0.47}$ & $\\mathbf{83.45}_{0.49}$ & $83.26_{0.87}$ \\\\\n",
      "p-h w sampling & $80.42_{0.46}$ & $81.57_{0.38}$ & $\\mathbf{82.78}_{0.58}$ & $83.19_{0.44}$ & $\\mathbf{83.35}_{0.59}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Computers} \\\\ \\hline\n",
      "N2V (inductive) & $37.39_{0.32}$ & $37.33_{0.28}$ & $37.31_{0.66}$ & $37.51_{0.75}$ & $37.72_{0.87}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $82.25_{0.73}$ & $84.66_{0.50}$ & $87.12_{0.53}$ & $88.13_{0.70}$ & $88.81_{0.97}$ \\\\\n",
      "post-hoc & $88.06_{0.46}$ & $89.87_{0.39}$ & $90.95_{0.40}$ & $90.90_{0.56}$ & $91.32_{0.53}$ \\\\\n",
      "p-h w losses & $88.19_{0.42}$ & $\\mathbf{90.04}_{0.51}$ & $\\mathbf{91.10}_{0.47}$ & $\\mathbf{91.55}_{0.38}$ & $91.35_{0.60}$ \\\\\n",
      "p-h w sampling & $\\mathbf{88.70}_{0.47}$ & $89.69_{0.50}$ & $90.75_{0.57}$ & $91.51_{0.48}$ & $\\mathbf{91.55}_{0.52}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Photo} \\\\ \\hline\n",
      "N2V (inductive) & $25.51_{0.46}$ & $24.86_{1.30}$ & $23.66_{1.99}$ & $22.96_{1.95}$ & $23.15_{2.24}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $86.08_{0.97}$ & $87.72_{0.68}$ & $90.01_{0.78}$ & $90.95_{0.56}$ & $91.56_{0.88}$ \\\\\n",
      "post-hoc & $90.42_{0.57}$ & $91.71_{0.36}$ & $92.47_{0.50}$ & $\\mathbf{93.08}_{0.73}$ & $93.07_{0.68}$ \\\\\n",
      "p-h w losses & $\\mathbf{90.70}_{0.50}$ & $91.74_{0.36}$ & $\\mathbf{92.60}_{0.55}$ & $92.86_{0.72}$ & $\\mathbf{93.12}_{0.87}$ \\\\\n",
      "p-h w sampling & $90.38_{0.54}$ & $\\mathbf{91.90}_{0.44}$ & $92.47_{0.64}$ & $92.70_{0.79}$ & $93.11_{1.02}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{WikiCS} \\\\ \\hline\n",
      "N2V (inductive) & $22.99_{0.41}$ & $22.96_{0.49}$ & $23.05_{0.51}$ & $23.12_{0.76}$ & $22.82_{1.26}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $70.64_{2.01}$ & $71.89_{1.30}$ & $75.48_{0.98}$ & $77.27_{0.54}$ & $78.62_{1.65}$ \\\\\n",
      "post-hoc & $78.92_{0.69}$ & $80.16_{0.78}$ & $81.36_{0.63}$ & $82.03_{0.57}$ & $82.56_{0.79}$ \\\\\n",
      "p-h w losses & $78.98_{0.64}$ & $80.22_{0.81}$ & $81.47_{0.52}$ & $82.12_{0.68}$ & $\\mathbf{82.76}_{0.83}$ \\\\\n",
      "p-h w sampling & $\\mathbf{79.21}_{0.59}$ & $\\mathbf{80.37}_{0.80}$ & $\\mathbf{81.48}_{0.66}$ & $\\mathbf{82.18}_{0.77}$ & $82.60_{0.83}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Actor} \\\\ \\hline\n",
      "N2V (inductive) & $25.41_{1.39}$ & $25.55_{1.16}$ & $\\mathbf{25.69}_{1.08}$ & $\\mathbf{26.05}_{0.51}$ & $\\mathbf{26.57}_{0.79}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $\\mathbf{25.78}_{0.76}$ & $25.45_{0.87}$ & $25.00_{1.35}$ & $24.62_{0.94}$ & $25.03_{0.99}$ \\\\\n",
      "post-hoc & $25.43_{1.35}$ & $25.78_{0.78}$ & $24.84_{0.97}$ & $24.93_{1.07}$ & $25.83_{1.50}$ \\\\\n",
      "p-h w losses & $25.42_{1.11}$ & $25.76_{0.92}$ & $24.75_{0.87}$ & $25.45_{0.40}$ & $25.51_{2.00}$ \\\\\n",
      "p-h w sampling & $24.96_{1.25}$ & $\\mathbf{25.82}_{0.83}$ & $25.62_{0.80}$ & $25.14_{0.76}$ & $24.43_{1.97}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Amazon-ratings} \\\\ \\hline\n",
      "N2V (inductive) & $36.91_{0.30}$ & $36.93_{0.35}$ & $36.74_{0.37}$ & $36.78_{0.52}$ & $36.54_{0.89}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $39.04_{0.65}$ & $41.31_{1.01}$ & $44.44_{1.62}$ & $45.77_{0.44}$ & $46.74_{0.81}$ \\\\\n",
      "post-hoc & $41.33_{0.66}$ & $\\mathbf{43.89}_{0.50}$ & $46.52_{0.77}$ & $49.44_{0.78}$ & $49.78_{1.70}$ \\\\\n",
      "p-h w losses & $\\mathbf{41.43}_{0.79}$ & $43.69_{0.57}$ & $\\mathbf{46.68}_{0.94}$ & $\\mathbf{51.66}_{0.31}$ & $\\mathbf{51.93}_{0.78}$ \\\\\n",
      "p-h w sampling & $41.41_{0.87}$ & $43.75_{0.54}$ & $46.58_{1.02}$ & $49.28_{0.64}$ & $49.06_{0.67}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Roman-empire} \\\\ \\hline\n",
      "N2V (inductive) & $13.34_{1.25}$ & $13.55_{0.97}$ & $14.00_{0.28}$ & $13.99_{0.40}$ & $13.27_{1.67}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $13.89_{0.26}$ & $\\mathbf{13.90}_{0.27}$ & $13.90_{0.19}$ & $13.74_{0.62}$ & $13.64_{0.76}$ \\\\\n",
      "post-hoc & $\\mathbf{13.90}_{0.26}$ & $13.85_{0.30}$ & $\\mathbf{14.01}_{0.24}$ & $\\mathbf{14.23}_{0.69}$ & $\\mathbf{14.27}_{0.94}$ \\\\\n",
      "p-h w losses & $13.81_{0.36}$ & $13.68_{0.33}$ & $13.79_{0.24}$ & $13.97_{0.40}$ & $14.16_{0.80}$ \\\\\n",
      "p-h w sampling & $13.85_{0.29}$ & $13.84_{0.28}$ & $13.88_{0.18}$ & $13.96_{0.55}$ & $13.61_{0.81}$ \\\\ \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_res_y([\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"WCS\", \"Act\", \"Ar\", \"Re\"], splits = [\"145\", \"24\", \"43\",\"62\", \"81\"], model = \"MLP\", datamode = \"emb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e134337-552e-4781-b9ba-c5ecd82166da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn{6}{l}{Cora} \\\\ \\hline\n",
      "N2V (inductive) & $42.18_{3.52}$ & $59.91_{4.15}$ & $75.07_{1.92}$ & $81.31_{1.56}$ & $84.50_{1.44}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $74.76_{2.08}$ & $76.86_{1.66}$ & $80.75_{1.17}$ & $82.45_{2.14}$ & $84.13_{1.99}$ \\\\\n",
      "post-hoc & $\\mathbf{79.20}_{1.80}$ & $79.44_{1.55}$ & $\\mathbf{83.45}_{1.08}$ & $\\mathbf{83.73}_{1.13}$ & $84.46_{2.08}$ \\\\\n",
      "p-h w losses & $78.88_{1.45}$ & $80.50_{1.26}$ & $83.30_{1.09}$ & $83.39_{1.74}$ & $\\mathbf{84.69}_{1.65}$ \\\\\n",
      "p-h w sampling & $79.11_{1.77}$ & $\\mathbf{80.94}_{1.58}$ & $82.02_{1.34}$ & $83.43_{1.50}$ & $84.02_{1.88}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Citeseer} \\\\ \\hline\n",
      "N2V (inductive) & $34.17_{3.43}$ & $42.76_{2.15}$ & $56.12_{3.24}$ & $63.61_{2.57}$ & $68.89_{2.61}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $56.22_{1.72}$ & $59.00_{2.16}$ & $\\mathbf{63.63}_{1.47}$ & $\\mathbf{67.73}_{1.63}$ & $68.92_{2.26}$ \\\\\n",
      "post-hoc & $57.25_{1.27}$ & $60.59_{1.52}$ & $62.88_{1.80}$ & $66.81_{1.42}$ & $\\mathbf{69.13}_{2.33}$ \\\\\n",
      "p-h w losses & $57.25_{1.55}$ & $\\mathbf{60.78}_{1.78}$ & $62.76_{1.90}$ & $67.23_{2.14}$ & $68.92_{2.07}$ \\\\\n",
      "p-h w sampling & $\\mathbf{57.88}_{0.91}$ & $57.92_{3.47}$ & $63.02_{1.88}$ & $67.23_{1.81}$ & $68.83_{2.37}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Pubmed} \\\\ \\hline\n",
      "N2V (inductive) & $66.02_{5.57}$ & $74.73_{2.36}$ & $79.84_{1.78}$ & $81.85_{0.61}$ & $82.61_{0.52}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $75.99_{0.52}$ & $78.37_{1.02}$ & $81.31_{0.55}$ & $82.30_{0.81}$ & $82.88_{0.72}$ \\\\\n",
      "post-hoc & $\\mathbf{79.93}_{0.50}$ & $\\mathbf{80.80}_{0.46}$ & $81.80_{0.49}$ & $82.74_{0.29}$ & $82.90_{0.73}$ \\\\\n",
      "p-h w losses & $79.75_{0.61}$ & $80.75_{0.61}$ & $81.91_{0.54}$ & $82.71_{0.34}$ & $82.59_{0.63}$ \\\\\n",
      "p-h w sampling & $79.68_{0.55}$ & $80.59_{0.54}$ & $\\mathbf{82.14}_{0.43}$ & $\\mathbf{82.81}_{0.46}$ & $\\mathbf{82.94}_{0.60}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Computers} \\\\ \\hline\n",
      "N2V (inductive) & $77.64_{2.81}$ & $84.44_{0.84}$ & $87.18_{0.77}$ & $89.21_{0.42}$ & $89.35_{0.70}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $85.40_{0.54}$ & $87.45_{0.42}$ & $89.05_{0.56}$ & $90.09_{0.44}$ & $90.24_{0.59}$ \\\\\n",
      "post-hoc & $87.94_{0.43}$ & $89.62_{0.43}$ & $90.66_{0.38}$ & $90.71_{0.52}$ & $91.07_{0.64}$ \\\\\n",
      "p-h w losses & $87.84_{0.32}$ & $\\mathbf{89.67}_{0.40}$ & $\\mathbf{90.84}_{0.37}$ & $91.08_{0.36}$ & $91.24_{0.52}$ \\\\\n",
      "p-h w sampling & $\\mathbf{88.36}_{0.58}$ & $89.26_{0.50}$ & $90.53_{0.62}$ & $\\mathbf{91.16}_{0.47}$ & $\\mathbf{91.38}_{0.51}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Photo} \\\\ \\hline\n",
      "N2V (inductive) & $85.48_{1.28}$ & $87.73_{1.40}$ & $90.98_{0.71}$ & $91.92_{0.63}$ & $92.21_{0.96}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $88.64_{0.95}$ & $90.31_{0.50}$ & $91.78_{0.47}$ & $92.48_{0.59}$ & $92.76_{0.78}$ \\\\\n",
      "post-hoc & $90.49_{0.67}$ & $91.62_{0.35}$ & $92.40_{0.53}$ & $\\mathbf{92.93}_{0.74}$ & $\\mathbf{93.08}_{0.77}$ \\\\\n",
      "p-h w losses & $\\mathbf{90.51}_{0.72}$ & $91.67_{0.30}$ & $92.37_{0.46}$ & $92.74_{0.61}$ & $92.95_{1.00}$ \\\\\n",
      "p-h w sampling & $90.42_{0.54}$ & $\\mathbf{91.70}_{0.44}$ & $\\mathbf{92.50}_{0.50}$ & $92.82_{0.63}$ & $92.88_{0.81}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{WikiCS} \\\\ \\hline\n",
      "N2V (inductive) & $67.78_{2.68}$ & $74.22_{1.65}$ & $78.21_{0.69}$ & $80.40_{0.45}$ & $81.62_{0.86}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $75.62_{0.63}$ & $77.96_{0.56}$ & $79.83_{0.60}$ & $80.85_{0.63}$ & $81.55_{0.58}$ \\\\\n",
      "post-hoc & $78.78_{0.74}$ & $80.07_{0.88}$ & $81.01_{0.63}$ & $\\mathbf{81.84}_{0.39}$ & $\\mathbf{82.55}_{0.72}$ \\\\\n",
      "p-h w losses & $78.72_{0.55}$ & $80.06_{0.71}$ & $81.20_{0.48}$ & $81.73_{0.76}$ & $82.43_{0.69}$ \\\\\n",
      "p-h w sampling & $\\mathbf{78.91}_{0.61}$ & $\\mathbf{80.19}_{0.70}$ & $\\mathbf{81.28}_{0.61}$ & $81.82_{0.54}$ & $82.37_{1.01}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Actor} \\\\ \\hline\n",
      "N2V (inductive) & $25.14_{1.09}$ & $25.56_{0.90}$ & $25.54_{1.15}$ & $\\mathbf{25.42}_{1.03}$ & $25.68_{1.42}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $25.18_{0.97}$ & $22.94_{0.83}$ & $25.40_{0.99}$ & $24.93_{0.89}$ & $24.97_{1.10}$ \\\\\n",
      "post-hoc & $\\mathbf{25.40}_{1.08}$ & $\\mathbf{25.82}_{0.99}$ & $25.34_{0.85}$ & $24.89_{0.75}$ & $25.39_{1.18}$ \\\\\n",
      "p-h w losses & $25.06_{1.06}$ & $24.95_{0.78}$ & $\\mathbf{25.85}_{0.79}$ & $24.41_{1.27}$ & $\\mathbf{25.79}_{2.27}$ \\\\\n",
      "p-h w sampling & $25.39_{1.14}$ & $25.50_{0.70}$ & $25.71_{0.93}$ & $25.16_{0.92}$ & $24.17_{1.69}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Amazon-ratings} \\\\ \\hline\n",
      "N2V (inductive) & $37.47_{0.47}$ & $40.69_{0.63}$ & $44.71_{0.85}$ & $46.98_{0.68}$ & $49.47_{1.07}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $36.70_{1.51}$ & $41.76_{0.91}$ & $\\mathbf{45.48}_{0.57}$ & $48.10_{0.58}$ & $50.19_{1.10}$ \\\\\n",
      "post-hoc & $38.68_{1.00}$ & $\\mathbf{42.12}_{0.66}$ & $45.20_{0.70}$ & $47.93_{0.29}$ & $48.40_{1.23}$ \\\\\n",
      "p-h w losses & $40.02_{0.79}$ & $42.01_{0.48}$ & $45.46_{0.82}$ & $\\mathbf{50.39}_{0.48}$ & $\\mathbf{50.38}_{2.22}$ \\\\\n",
      "p-h w sampling & $\\mathbf{40.10}_{0.68}$ & $41.92_{0.85}$ & $45.31_{0.74}$ & $47.44_{0.46}$ & $48.40_{1.30}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Roman-empire} \\\\ \\hline\n",
      "N2V (inductive) & $\\mathbf{13.96}_{0.35}$ & $\\mathbf{14.10}_{0.32}$ & $\\mathbf{15.77}_{0.76}$ & $\\mathbf{15.98}_{1.55}$ & $16.81_{2.94}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $13.64_{0.85}$ & $13.88_{0.29}$ & $14.48_{0.63}$ & $14.82_{1.04}$ & $17.59_{4.35}$ \\\\\n",
      "post-hoc & $13.31_{1.26}$ & $13.86_{0.29}$ & $13.86_{0.17}$ & $13.86_{0.64}$ & $14.89_{1.70}$ \\\\\n",
      "p-h w losses & $13.17_{1.43}$ & $13.84_{0.27}$ & $13.90_{0.26}$ & $15.05_{1.07}$ & $16.93_{1.31}$ \\\\\n",
      "p-h w sampling & $13.79_{0.39}$ & $13.59_{0.75}$ & $14.02_{0.41}$ & $15.33_{1.12}$ & $\\mathbf{18.55}_{1.23}$ \\\\ \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_res_y([\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"WCS\", \"Act\", \"Ar\", \"Re\"], splits = [\"145\", \"24\", \"43\",\"62\", \"81\"], model = \"Sage\", datamode = \"emb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2055269e-4fec-417c-adb5-65d60060b3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn{6}{l}{Cora} \\\\ \\hline\n",
      "N2V (inductive) & $66.48_{1.68}$ & $70.54_{1.20}$ & $75.47_{1.91}$ & $76.09_{2.08}$ & $76.27_{1.68}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $76.83_{1.66}$ & $79.70_{1.44}$ & $82.76_{1.87}$ & $85.31_{1.85}$ & $85.06_{2.20}$ \\\\\n",
      "post-hoc & $\\mathbf{82.01}_{1.38}$ & $82.53_{1.58}$ & $85.81_{1.38}$ & $85.63_{1.73}$ & $\\mathbf{87.12}_{2.08}$ \\\\\n",
      "p-h w losses & $81.85_{1.42}$ & $83.27_{1.21}$ & $\\mathbf{85.83}_{1.45}$ & $\\mathbf{86.27}_{1.97}$ & $86.68_{1.66}$ \\\\\n",
      "p-h w sampling & $81.72_{1.26}$ & $\\mathbf{83.97}_{1.35}$ & $85.37_{1.35}$ & $85.81_{1.77}$ & $86.49_{1.62}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Citeseer} \\\\ \\hline\n",
      "N2V (inductive) & $66.06_{1.31}$ & $70.04_{1.29}$ & $72.33_{1.07}$ & $73.58_{1.14}$ & $74.68_{2.12}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $65.59_{1.52}$ & $70.19_{0.97}$ & $73.53_{1.23}$ & $74.35_{0.96}$ & $76.49_{1.76}$ \\\\\n",
      "post-hoc & $66.75_{1.01}$ & $71.24_{1.00}$ & $74.13_{1.23}$ & $75.85_{0.87}$ & $76.40_{2.23}$ \\\\\n",
      "p-h w losses & $66.98_{1.14}$ & $\\mathbf{71.35}_{0.83}$ & $\\mathbf{74.37}_{1.05}$ & $75.70_{1.53}$ & $76.49_{2.44}$ \\\\\n",
      "p-h w sampling & $\\mathbf{67.33}_{1.33}$ & $70.35_{1.11}$ & $74.30_{1.03}$ & $\\mathbf{75.92}_{1.10}$ & $\\mathbf{77.09}_{2.79}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Pubmed} \\\\ \\hline\n",
      "N2V (inductive) & $83.94_{0.42}$ & $85.55_{0.42}$ & $86.73_{0.46}$ & $87.21_{0.58}$ & $87.40_{0.92}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $83.40_{0.62}$ & $86.17_{0.42}$ & $88.08_{0.52}$ & $88.86_{0.63}$ & $88.97_{0.79}$ \\\\\n",
      "post-hoc & $85.34_{0.40}$ & $87.05_{0.45}$ & $88.01_{0.45}$ & $89.44_{0.51}$ & $\\mathbf{90.01}_{0.71}$ \\\\\n",
      "p-h w losses & $85.37_{0.40}$ & $\\mathbf{87.07}_{0.39}$ & $88.15_{0.49}$ & $89.29_{0.44}$ & $89.62_{0.68}$ \\\\\n",
      "p-h w sampling & $\\mathbf{85.38}_{0.39}$ & $86.85_{0.51}$ & $\\mathbf{88.69}_{0.60}$ & $\\mathbf{89.46}_{0.51}$ & $89.90_{0.51}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Computers} \\\\ \\hline\n",
      "N2V (inductive) & $80.41_{0.60}$ & $82.98_{0.65}$ & $84.08_{0.76}$ & $84.34_{0.97}$ & $84.72_{0.87}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $86.09_{0.53}$ & $87.99_{0.36}$ & $89.47_{0.38}$ & $90.21_{0.43}$ & $90.19_{0.64}$ \\\\\n",
      "post-hoc & $88.32_{0.29}$ & $89.57_{0.36}$ & $90.46_{0.44}$ & $90.37_{0.54}$ & $90.64_{0.82}$ \\\\\n",
      "p-h w losses & $88.34_{0.16}$ & $89.63_{0.34}$ & $90.40_{0.39}$ & $90.68_{0.53}$ & $90.89_{0.74}$ \\\\\n",
      "p-h w sampling & $\\mathbf{88.63}_{0.22}$ & $\\mathbf{89.75}_{0.22}$ & $\\mathbf{90.67}_{0.24}$ & $\\mathbf{90.99}_{0.52}$ & $\\mathbf{90.95}_{0.59}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Photo} \\\\ \\hline\n",
      "N2V (inductive) & $85.73_{2.20}$ & $86.22_{1.22}$ & $90.71_{0.59}$ & $90.90_{0.65}$ & $91.76_{0.70}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $92.13_{0.39}$ & $93.66_{0.64}$ & $94.59_{0.37}$ & $95.10_{0.49}$ & $95.32_{0.74}$ \\\\\n",
      "post-hoc & $93.86_{0.39}$ & $94.54_{0.37}$ & $95.24_{0.40}$ & $95.31_{0.45}$ & $95.48_{0.69}$ \\\\\n",
      "p-h w losses & $93.85_{0.46}$ & $\\mathbf{94.59}_{0.30}$ & $95.21_{0.38}$ & $95.28_{0.38}$ & $95.69_{0.64}$ \\\\\n",
      "p-h w sampling & $\\mathbf{93.99}_{0.36}$ & $94.55_{0.29}$ & $\\mathbf{95.33}_{0.32}$ & $\\mathbf{95.42}_{0.45}$ & $\\mathbf{95.70}_{0.74}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{WikiCS} \\\\ \\hline\n",
      "N2V (inductive) & $73.16_{1.17}$ & $75.60_{0.78}$ & $76.79_{0.51}$ & $77.30_{0.73}$ & $76.71_{0.97}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $77.52_{0.81}$ & $79.41_{0.76}$ & $81.46_{0.82}$ & $82.94_{0.67}$ & $83.87_{1.02}$ \\\\\n",
      "post-hoc & $81.82_{0.69}$ & $83.34_{0.63}$ & $84.37_{0.56}$ & $85.27_{0.49}$ & $85.62_{0.69}$ \\\\\n",
      "p-h w losses & $\\mathbf{81.88}_{0.50}$ & $83.37_{0.59}$ & $\\mathbf{84.77}_{0.55}$ & $85.41_{0.76}$ & $86.05_{0.93}$ \\\\\n",
      "p-h w sampling & $81.78_{0.50}$ & $\\mathbf{83.47}_{0.47}$ & $84.54_{0.48}$ & $\\mathbf{85.45}_{0.54}$ & $\\mathbf{86.26}_{0.87}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Actor} \\\\ \\hline\n",
      "N2V (inductive) & $33.99_{0.93}$ & $35.54_{1.01}$ & $36.64_{0.85}$ & $\\mathbf{38.22}_{0.70}$ & $38.08_{1.62}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $33.07_{1.00}$ & $34.32_{0.97}$ & $36.57_{1.18}$ & $37.91_{0.76}$ & $37.80_{1.56}$ \\\\\n",
      "post-hoc & $34.96_{0.78}$ & $\\mathbf{36.16}_{0.53}$ & $37.13_{1.08}$ & $37.75_{1.10}$ & $\\mathbf{38.11}_{1.18}$ \\\\\n",
      "p-h w losses & $34.97_{0.54}$ & $35.95_{0.39}$ & $37.40_{1.19}$ & $37.53_{1.02}$ & $37.32_{1.22}$ \\\\\n",
      "p-h w sampling & $\\mathbf{35.15}_{1.06}$ & $35.92_{0.56}$ & $\\mathbf{37.66}_{0.96}$ & $37.72_{0.89}$ & $38.07_{1.12}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Amazon-ratings} \\\\ \\hline\n",
      "N2V (inductive) & $37.36_{0.39}$ & $37.93_{0.59}$ & $38.30_{0.50}$ & $38.51_{0.69}$ & $38.57_{1.67}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $39.49_{0.78}$ & $41.98_{1.16}$ & $48.63_{2.84}$ & $49.49_{0.80}$ & $51.99_{1.25}$ \\\\\n",
      "post-hoc & $41.24_{0.74}$ & $45.64_{0.67}$ & $51.89_{0.53}$ & $55.90_{0.77}$ & $\\mathbf{58.69}_{0.44}$ \\\\\n",
      "p-h w losses & $41.11_{0.66}$ & $45.56_{0.96}$ & $\\mathbf{52.08}_{0.49}$ & $\\mathbf{55.96}_{0.81}$ & $58.44_{0.67}$ \\\\\n",
      "p-h w sampling & $\\mathbf{41.26}_{0.69}$ & $\\mathbf{45.73}_{0.67}$ & $51.91_{0.40}$ & $55.93_{0.68}$ & $51.69_{1.60}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Roman-empire} \\\\ \\hline\n",
      "N2V (inductive) & $\\mathbf{62.37}_{0.51}$ & $\\mathbf{64.35}_{0.38}$ & $\\mathbf{65.67}_{0.18}$ & $\\mathbf{66.48}_{0.70}$ & $\\mathbf{66.54}_{1.07}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $60.57_{0.41}$ & $63.64_{0.31}$ & $65.36_{0.35}$ & $65.98_{0.67}$ & $66.11_{1.17}$ \\\\\n",
      "post-hoc & $60.33_{0.33}$ & $63.49_{0.33}$ & $65.07_{0.39}$ & $65.83_{0.80}$ & $65.97_{1.23}$ \\\\\n",
      "p-h w losses & $60.57_{0.39}$ & $63.59_{0.32}$ & $65.28_{0.34}$ & $65.81_{0.56}$ & $65.97_{1.32}$ \\\\\n",
      "p-h w sampling & $60.04_{0.37}$ & $63.57_{0.30}$ & $65.16_{0.36}$ & $65.86_{0.59}$ & $65.99_{1.12}$ \\\\ \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_res_y([\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"WCS\", \"Act\", \"Ar\", \"Re\"], splits = [\"145\", \"24\", \"43\",\"62\", \"81\"], model = \"MLP\", datamode = \"cat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ea11511-2e28-4294-8cde-cbe314f9ef4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn{6}{l}{Cora} \\\\ \\hline\n",
      "N2V (inductive) & $73.97_{3.35}$ & $81.92_{1.84}$ & $85.97_{1.67}$ & $\\mathbf{86.97}_{0.96}$ & $87.38_{0.79}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $76.56_{1.72}$ & $81.51_{1.77}$ & $85.12_{1.38}$ & $86.62_{1.87}$ & $87.60_{1.81}$ \\\\\n",
      "post-hoc & $81.01_{1.42}$ & $81.98_{1.75}$ & $\\mathbf{86.13}_{1.08}$ & $86.55_{1.35}$ & $86.64_{1.26}$ \\\\\n",
      "p-h w losses & $\\mathbf{81.45}_{1.39}$ & $82.82_{1.20}$ & $85.92_{1.17}$ & $86.35_{1.56}$ & $87.45_{1.39}$ \\\\\n",
      "p-h w sampling & $80.97_{1.47}$ & $\\mathbf{83.28}_{1.41}$ & $85.71_{1.44}$ & $86.77_{1.42}$ & $\\mathbf{87.64}_{1.27}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Citeseer} \\\\ \\hline\n",
      "N2V (inductive) & $\\mathbf{68.52}_{2.47}$ & $\\mathbf{72.49}_{1.14}$ & $\\mathbf{74.53}_{1.28}$ & $75.85_{1.40}$ & $76.76_{1.85}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $65.62_{1.85}$ & $70.69_{1.10}$ & $73.99_{1.47}$ & $75.77_{1.29}$ & $\\mathbf{77.09}_{1.77}$ \\\\\n",
      "post-hoc & $66.79_{1.51}$ & $71.14_{0.60}$ & $73.91_{1.38}$ & $\\mathbf{76.35}_{1.42}$ & $75.50_{1.63}$ \\\\\n",
      "p-h w losses & $67.11_{1.47}$ & $71.14_{0.98}$ & $73.51_{1.81}$ & $75.94_{1.41}$ & $76.55_{2.79}$ \\\\\n",
      "p-h w sampling & $66.69_{1.34}$ & $69.10_{1.60}$ & $73.47_{1.54}$ & $75.73_{1.27}$ & $76.13_{2.14}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Pubmed} \\\\ \\hline\n",
      "N2V (inductive) & $\\mathbf{84.33}_{0.46}$ & $\\mathbf{86.06}_{0.59}$ & $87.32_{0.38}$ & $87.32_{0.39}$ & $88.01_{0.78}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $81.23_{0.69}$ & $84.86_{0.58}$ & $86.74_{0.60}$ & $87.92_{0.47}$ & $88.38_{0.88}$ \\\\\n",
      "post-hoc & $82.83_{0.77}$ & $84.76_{0.53}$ & $86.78_{0.56}$ & $\\mathbf{88.69}_{0.49}$ & $89.23_{0.69}$ \\\\\n",
      "p-h w losses & $82.75_{0.71}$ & $85.09_{0.37}$ & $86.68_{0.48}$ & $88.36_{0.47}$ & $89.07_{0.69}$ \\\\\n",
      "p-h w sampling & $83.02_{0.72}$ & $84.82_{0.46}$ & $\\mathbf{87.51}_{0.51}$ & $88.59_{0.35}$ & $\\mathbf{89.39}_{0.72}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Computers} \\\\ \\hline\n",
      "N2V (inductive) & $86.64_{1.11}$ & $89.05_{0.63}$ & $90.72_{0.36}$ & $91.33_{0.56}$ & $91.70_{0.55}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $88.52_{0.51}$ & $90.17_{0.31}$ & $91.16_{0.35}$ & $91.63_{0.30}$ & $91.60_{0.52}$ \\\\\n",
      "post-hoc & $88.83_{0.51}$ & $\\mathbf{90.50}_{0.24}$ & $91.47_{0.39}$ & $91.80_{0.59}$ & $\\mathbf{92.01}_{0.35}$ \\\\\n",
      "p-h w losses & $88.83_{0.34}$ & $90.46_{0.19}$ & $91.43_{0.36}$ & $91.90_{0.38}$ & $91.85_{0.61}$ \\\\\n",
      "p-h w sampling & $\\mathbf{88.90}_{0.36}$ & $90.50_{0.22}$ & $\\mathbf{91.47}_{0.30}$ & $\\mathbf{91.91}_{0.49}$ & $91.72_{0.37}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Photo} \\\\ \\hline\n",
      "N2V (inductive) & $91.97_{1.73}$ & $93.87_{0.70}$ & $94.94_{0.44}$ & $95.37_{0.60}$ & $95.56_{0.81}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $93.04_{0.51}$ & $94.29_{0.47}$ & $95.25_{0.30}$ & $95.54_{0.50}$ & $95.63_{0.75}$ \\\\\n",
      "post-hoc & $93.74_{0.41}$ & $94.53_{0.45}$ & $95.23_{0.31}$ & $95.52_{0.39}$ & $95.73_{0.61}$ \\\\\n",
      "p-h w losses & $93.54_{0.49}$ & $94.56_{0.33}$ & $95.14_{0.42}$ & $95.44_{0.49}$ & $\\mathbf{95.74}_{0.85}$ \\\\\n",
      "p-h w sampling & $\\mathbf{93.87}_{0.52}$ & $\\mathbf{94.68}_{0.33}$ & $\\mathbf{95.26}_{0.28}$ & $\\mathbf{95.59}_{0.42}$ & $95.63_{0.74}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{WikiCS} \\\\ \\hline\n",
      "N2V (inductive) & $76.50_{1.34}$ & $79.99_{0.65}$ & $82.23_{0.75}$ & $83.76_{0.63}$ & $84.79_{0.87}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $79.29_{0.98}$ & $81.62_{0.51}$ & $83.29_{0.71}$ & $84.44_{0.65}$ & $85.38_{0.45}$ \\\\\n",
      "post-hoc & $81.50_{0.64}$ & $83.30_{0.62}$ & $84.41_{0.51}$ & $\\mathbf{85.43}_{0.48}$ & $85.97_{0.78}$ \\\\\n",
      "p-h w losses & $\\mathbf{81.54}_{0.68}$ & $83.30_{0.59}$ & $84.47_{0.64}$ & $85.25_{0.47}$ & $\\mathbf{86.00}_{0.90}$ \\\\\n",
      "p-h w sampling & $81.36_{0.52}$ & $\\mathbf{83.38}_{0.58}$ & $\\mathbf{84.62}_{0.47}$ & $85.29_{0.66}$ & $85.73_{0.70}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Actor} \\\\ \\hline\n",
      "N2V (inductive) & $32.04_{0.94}$ & $33.44_{0.73}$ & $35.14_{0.93}$ & $36.13_{1.52}$ & $36.05_{2.46}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $31.29_{0.58}$ & $32.75_{0.46}$ & $34.78_{0.77}$ & $\\mathbf{36.23}_{1.14}$ & $36.46_{1.84}$ \\\\\n",
      "post-hoc & $32.12_{0.73}$ & $33.18_{0.45}$ & $34.89_{0.75}$ & $36.04_{1.06}$ & $36.66_{2.24}$ \\\\\n",
      "p-h w losses & $\\mathbf{32.82}_{0.74}$ & $\\mathbf{33.83}_{0.91}$ & $\\mathbf{35.82}_{0.86}$ & $35.21_{0.75}$ & $\\mathbf{36.76}_{2.21}$ \\\\\n",
      "p-h w sampling & $32.79_{1.03}$ & $33.53_{0.63}$ & $35.38_{1.24}$ & $36.03_{0.64}$ & $36.58_{1.50}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Amazon-ratings} \\\\ \\hline\n",
      "N2V (inductive) & $39.14_{0.57}$ & $41.43_{0.65}$ & $44.99_{1.04}$ & $48.97_{1.16}$ & $50.98_{1.35}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $38.76_{0.69}$ & $42.28_{0.54}$ & $48.16_{1.51}$ & $50.02_{0.59}$ & $54.05_{1.04}$ \\\\\n",
      "post-hoc & $39.93_{0.48}$ & $43.45_{0.94}$ & $50.70_{0.51}$ & $55.12_{0.80}$ & $58.70_{0.84}$ \\\\\n",
      "p-h w losses & $\\mathbf{40.29}_{0.67}$ & $43.72_{0.70}$ & $50.63_{0.90}$ & $55.29_{0.65}$ & $\\mathbf{58.94}_{0.89}$ \\\\\n",
      "p-h w sampling & $40.13_{0.60}$ & $\\mathbf{43.91}_{1.02}$ & $\\mathbf{50.99}_{0.84}$ & $\\mathbf{55.42}_{0.83}$ & $49.54_{1.30}$ \\\\ \\midrule\n",
      "\n",
      "\\multicolumn{6}{l}{Roman-empire} \\\\ \\hline\n",
      "N2V (inductive) & $\\mathbf{64.71}_{0.66}$ & $\\mathbf{68.52}_{0.65}$ & $\\mathbf{72.78}_{0.31}$ & $\\mathbf{76.68}_{0.64}$ & $\\mathbf{81.16}_{1.65}$ \\\\\n",
      "frozen ($\\lambda = 1$) & $57.86_{1.21}$ & $65.40_{0.54}$ & $70.93_{0.39}$ & $75.48_{0.57}$ & $80.58_{0.71}$ \\\\\n",
      "post-hoc & $57.94_{1.32}$ & $65.57_{0.44}$ & $71.50_{0.43}$ & $76.07_{0.49}$ & $80.48_{0.75}$ \\\\\n",
      "p-h w losses & $59.29_{0.87}$ & $66.10_{0.31}$ & $70.45_{0.38}$ & $75.62_{0.64}$ & $79.92_{0.96}$ \\\\\n",
      "p-h w sampling & $55.56_{1.30}$ & $66.19_{0.59}$ & $70.88_{0.38}$ & $75.15_{0.84}$ & $79.91_{0.71}$ \\\\ \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_res_y([\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"WCS\", \"Act\", \"Ar\", \"Re\"], splits = [\"145\", \"24\", \"43\",\"62\", \"81\"], model = \"Sage\", datamode = \"cat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e784f01-959c-482f-886c-876238118476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e281f5fd-0d96-456c-8678-d1c9743e4fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_final_exp(ds, split, model, ty):\n",
    "    ds_l = {\"Cora\":\"Cora\", \"Cite\":\"Citeseer\", \"PM\":\"Pubmed\", \"Com\":\"Computers\", \"Pho\":\"Photo\", \"Act\":\"Actor\", \"Ar\":\"Amazon-ratings\", \"Re\":\"Roman-empire\", \"WCS\":\"WikiCS\"}[ds]\n",
    "    mo = [\"_\".join((model, str(d), str(h))) for d in [5, 4, 3, 2, 1] for h in [512, 64]]\n",
    "\n",
    "    d = {\"dataset\":[ds_l],\n",
    "         \"datamode\": [\"gra\", \"emb_tr\", \"emb_ba\", \"emb_po\", \"emb_lo\", \"emb_re\", \"cat_tr\", \"cat_ba\", \"cat_po\", \"cat_lo\", \"cat_re\"],\n",
    "         \"drop_model\": [0.2, 0.5, 0.8],\n",
    "         \"lr\": [0.01, 0.001],\n",
    "         \"split\": [split],\n",
    "         \"statrep\": [10],\n",
    "         \"model\": mo,\n",
    "         \"model_type\":ty,\n",
    "         \"wd\": [0, 0.0001, 0.01]}\n",
    "    \n",
    "    p = \"../Experiments/F_\"+ds+\"_\"+str(split)+\"_\"+model+\".yml\"\n",
    "    yaml.dump(d, open(p, \"w\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c8f6849d-5a99-4b34-9861-aae6074bbe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_exf(ds, split, model, ty = [\"lin\", \"jkb\", \"jk\"]):\n",
    "    ds_l = {\"Cora\":\"Cora\", \"Cite\":\"Citeseer\", \"PM\":\"Pubmed\", \"Com\":\"Computers\", \"Pho\":\"Photo\", \"Act\":\"Actor\", \"Ar\":\"Amazon-ratings\", \"Re\":\"Roman-empire\", \"WCS\":\"WikiCS\"}[ds]\n",
    "    mo = [\"_\".join((model, str(d), str(h))) for d in [5, 4, 3, 2, 1] for h in [512, 64]]\n",
    "\n",
    "    d = {\"dataset\":[ds_l],\n",
    "         \"datamode\": [\"emb_exfbase\", \"emb_exffp\", \"emb_exfph\"],\n",
    "         \"drop_model\": [0.2, 0.5, 0.8],\n",
    "         \"lr\": [0.01, 0.001],\n",
    "         \"split\": [split],\n",
    "         \"statrep\": [10],\n",
    "         \"model\": mo,\n",
    "         \"model_type\":ty,\n",
    "         \"wd\": [0, 0.0001, 0.01]}\n",
    "    \n",
    "    p = \"../Experiments/F_\"+ds+\"_\"+str(split)+\"_\"+model+\"_exf.yml\"\n",
    "    yaml.dump(d, open(p, \"w\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f22a054-a575-42c5-94ff-323d518253b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_transductive_baseline(ds, split, model, ty):\n",
    "    ds_l = {\"Cora\":\"Cora\", \"Cite\":\"Citeseer\", \"PM\":\"Pubmed\", \"Com\":\"Computers\", \"Pho\":\"Photo\", \"Act\":\"Actor\", \"Ar\":\"Amazon-ratings\", \"Re\":\"Roman-empire\", \"WCS\":\"WikiCS\"}[ds]\n",
    "    mo = [\"_\".join((model, str(d), str(h))) for d in [5, 4, 3, 2, 1] for h in [512, 64]]\n",
    "\n",
    "    d = {\"dataset\":[ds_l],\n",
    "         \"datamode\": [\"emb_transd\", \"cat_transd\"],\n",
    "         \"drop_model\": [0.2, 0.5, 0.8],\n",
    "         \"lr\": [0.01, 0.001],\n",
    "         \"split\": [\"trans_\"+str(split)],\n",
    "         \"statrep\": [10],\n",
    "         \"model\": mo,\n",
    "         \"model_type\":ty,\n",
    "         \"wd\": [0, 0.0001, 0.01]}\n",
    "    \n",
    "    p = \"../Experiments/F_\"+ds+\"_\"+str(split)+\"_\"+model+\"_tr.yml\"\n",
    "    yaml.dump(d, open(p, \"w\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3004a344-2ecf-4425-83fe-ddb6988619ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fp_baseline(ds, split, model, ty):\n",
    "    ds_l = {\"Cora\":\"Cora\", \"Cite\":\"Citeseer\", \"PM\":\"Pubmed\", \"Com\":\"Computers\", \"Pho\":\"Photo\", \"Act\":\"Actor\", \"Ar\":\"Amazon-ratings\", \"Re\":\"Roman-empire\", \"WCS\":\"WikiCS\"}[ds]\n",
    "    mo = [\"_\".join((model, str(d), str(h))) for d in [5, 4, 3, 2, 1] for h in [512, 64]]\n",
    "\n",
    "    d = {\"dataset\":[ds_l],\n",
    "         \"datamode\": [\"emb_fpbase\", \"emb_fploss\", \"emb_fpprob\", \"cat_fpbase\", \"cat_fploss\", \"cat_fpprob\"],\n",
    "         \"drop_model\": [0.2, 0.5, 0.8],\n",
    "         \"lr\": [0.01, 0.001],\n",
    "         \"split\": [str(split)],\n",
    "         \"statrep\": [10],\n",
    "         \"model\": mo,\n",
    "         \"model_type\":ty,\n",
    "         \"wd\": [0, 0.0001, 0.01]}\n",
    "    \n",
    "    p = \"../Experiments/F_\"+ds+\"_\"+str(split)+\"_\"+model+\"_fp.yml\"\n",
    "    yaml.dump(d, open(p, \"w\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb013654-0dcc-4d40-add2-877be64c69ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = \"Sage\"\n",
    "for d in [\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"WCS\", \"Act\", \"Re\", \"Ar\"]:\n",
    "    for s in [81, 62, 43, 24, 145]:\n",
    "        #print_exf(d, s, m)\n",
    "        pass #print\")\n",
    "\n",
    "m = \"MLP\"\n",
    "for d in [\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"WCS\", \"Act\", \"Re\", \"Ar\"]:\n",
    "    for s in [81, 62, 43, 24, 145]:\n",
    "        #print_exf(d, s, m)\n",
    "        pass #print()\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850e6d58-187d-4aa7-bdf2-6b9999658094",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"WCS\"\n",
    "for s in [81, 62, 43, 24, 145]:\n",
    "    m = \"MLP\"\n",
    "    #print_transductive_baseline(d, s, m, [\"lin\", \"jkb\", \"jk\"])\n",
    "    pass #print\")\n",
    "for s in [81, 62, 43, 24, 145]:\n",
    "    m = \"Sage\"\n",
    "    #print_transductive_baseline(d, s, m, [\"lin\", \"jkb\", \"jk\"])\n",
    "    pass #print\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "021f0af0-c41c-40ff-bf66-447492144c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [\"PM\", \"Com\", \"Act\", \"Re\", \"Ar\", \"WCS\"]:\n",
    "    for s in [81, 62, 43, 24, 145]:\n",
    "        m = \"MLP\"\n",
    "        #print_fp_baseline(d, s, m, [\"lin\", \"jkb\", \"jk\"])\n",
    "        pass #print\")\n",
    "for d in [\"PM\", \"Com\", \"Act\", \"Re\", \"Ar\", \"WCS\"]:\n",
    "    for s in [81, 62, 43, 24, 145]:\n",
    "        m = \"Sage\"\n",
    "        #print_fp_baseline(d, s, m, [\"lin\", \"jkb\", \"jk\"])\n",
    "        pass #print\")\n",
    "        \n",
    "for d in [\"Cora\", \"Cite\", \"Pho\"]:\n",
    "    for s in [81, 62, 43, 24, 145]:\n",
    "        for m in [\"MLP\", \"Sage\"]:\n",
    "            #print_fp_baseline(d, s, m, [\"lin\", \"jkb\", \"jk\"])\n",
    "            pass #print\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bc30ea5-b201-4dfc-bf50-4089e11204aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"Act\", \"Re\", \"Ar\"]:\n",
    "    for s in [145, 24, 43, 62, 81]:\n",
    "        for m in [\"MLP\", \"Sage\"]:\n",
    "            #print_transductive_baseline(d, s, m, [\"lin\", \"jkb\", \"jk\"])\n",
    "            pass #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "943be214-b5ae-4f82-820f-62137a0bb5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [\"Cora\", \"Cite\", \"Pho\", \"Act\", \"PM\"]:\n",
    "    for s in [145, 24, 43, 62, 81]:\n",
    "        for m in [\"MLP\", \"Sage\"]:\n",
    "            #print_final_exp(d, s, m, [\"lin\", \"jkb\", \"jk\"])\n",
    "            pass #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "785d27ee-a3ae-4bb6-a27c-4d350c235f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [\"Com\", \"Ar\", \"Re\"]:\n",
    "    for s in [62, 81]:\n",
    "        for m in [\"Sage\", \"MLP\"]:\n",
    "            #print_final_exp(d, s, m, [\"lin\", \"jk\", \"jkb\"])\n",
    "            pass #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1212aa1a-1cf6-4679-8f49-5e0c6a8c162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2l(t):\n",
    "    r = str(t[0])\n",
    "    for e in t[1:]:\n",
    "        r += \" &    \"+str(e)\n",
    "    return r\n",
    "\n",
    "#create experiment that will save the final embeddings\n",
    "def print_gen_save(df, t):\n",
    "    params = []\n",
    "    for c in df.drop([\"val_acc\", \"statrep\", \"trained_epochs\"], axis=1).columns:\n",
    "        if len(df[c].unique())>1:\n",
    "            params.append(c)\n",
    "    tmp = df.groupby(params)\n",
    "    mean = tmp.mean(numeric_only = True)\n",
    "    std = tmp.std(numeric_only = True)\n",
    "    \n",
    "    ix = mean.val_acc.idxmax()\n",
    "    num_occ = mean.val_acc.value_counts()[mean.loc[ix].val_acc]\n",
    "    \n",
    "    #check wether max is unique, if not use lowest sd one\n",
    "    if num_occ > 1:\n",
    "        print()\n",
    "        print(\"more than 1 max acc:\")\n",
    "        max_df = mean[mean.val_acc.eq(mean.loc[ix].val_acc)]\n",
    "        #print(max_df)\n",
    "        #print()\n",
    "        for index, row in max_df.iterrows():\n",
    "            if std.loc[index].val_acc < std.loc[ix].val_acc:\n",
    "                ix = index\n",
    "    \n",
    "    print(params)\n",
    "    print(t2l(ix))\n",
    "    print(\"${:.2f}_{{{:.2f}}}$\".format(mean.loc[ix].val_acc*100, std.loc[ix].val_acc*100))\n",
    "    print(mean.loc[ix].val_acc*100)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    base_d = {\"batch_size\":[128], \"prob_replace\":[0], \"statrep\":[10], \"w_ms\": [0], \"w_ndiv\":[0], \"split\":[int(df[\"split\"].unique()[0])], \"dataset\":[df[\"dataset\"].unique()[0]], \"delay_alpha\":[\"0_1\"], \"save_embeds\":[True]}\n",
    "    #remove numpy datatypes (loaded by pandas) for saving\n",
    "    \n",
    "    d = {}\n",
    "    for i in range(len(ix)):\n",
    "        try:\n",
    "            d[params[i]] = [ix[i].item()]\n",
    "        except:\n",
    "            d[params[i]] = [ix[i]]\n",
    "    base_d.update(d)\n",
    "    \n",
    "    tmp = base_d[\"delay_alpha\"][0].split(\"_\")\n",
    "    if tmp[1] == \"fp\":\n",
    "        base_d[\"fp\"] = [[int(tmp[0])]]\n",
    "        base_d.pop(\"delay\", None)\n",
    "        base_d.pop(\"alpha\", None)\n",
    "    else:\n",
    "        base_d[\"delay\"] = [[int(tmp[0])]]\n",
    "        base_d[\"alpha\"] = [[float(tmp[1])]]\n",
    "    base_d.pop(\"delay_alpha\", None)\n",
    "    \n",
    "    yaml.dump(base_d, open(\"../Experiments/E_\"+base_d[\"dataset\"][0]+\"_\"+str(base_d[\"split\"][0])+\"_\"+t+\".yml\", \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61471aa0-d2a8-4a52-92ed-76d8b9c25437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_e(df):\n",
    "    params = []\n",
    "    for c in df.drop([\"val_acc\", \"statrep\", \"trained_epochs\"], axis=1).columns:\n",
    "        if len(df[c].unique())>1:\n",
    "            params.append(c)\n",
    "    tmp = df.groupby(params)\n",
    "    mean = tmp.mean(numeric_only = True)\n",
    "    std = tmp.std(numeric_only = True)\n",
    "    \n",
    "    ix = mean.val_acc.idxmax()\n",
    "    num_occ = mean.val_acc.value_counts()[mean.loc[ix].val_acc]\n",
    "    \n",
    "    #check wether max is unique, if not use lowest sd one\n",
    "    if num_occ > 1:\n",
    "        max_df = mean[mean.val_acc.eq(mean.loc[ix].val_acc)]\n",
    "        for index, row in max_df.iterrows():\n",
    "            if std.loc[index].val_acc < std.loc[ix].val_acc:\n",
    "                ix = index\n",
    "    \n",
    "    return (\"${:.2f}_{{{:.2f}}}$\".format(mean.loc[ix].val_acc*100, std.loc[ix].val_acc*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03870410-e2a3-409c-ba10-52f0aadc1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_table(dss, splits = [\"145\", \"24\", \"43\", \"62\", \"81\"]):\n",
    "    for ds in dss:\n",
    "        print()\n",
    "        ls1, ls2, ls3, ls4 = [ds, \" baseline \"], [\" \", \"best post-hoc\"], [\" \", \"    w losses \"], [\" \", \"  w sampling \"]\n",
    "        for split in splits:\n",
    "            df = pd.concat([pd.read_pickle(\"../results_comb/\"+ds+\"_\"+split+\".pkl\"), pd.read_pickle(\"../results_comb/\"+ds+\"_\"+split+\"r.pkl\")], ignore_index=True).drop([\n",
    "                \"val_loss\", \"loss_hist\", \"valtest_time\", \"train_time\", \"record_train\", \"save_models\", \"batch_size\", \"batch_size_test\", \"batch_size_val\", \"alpha\", \"delay\", \"save_embeds\",\n",
    "                \"context_size\", \"num_negative_samples\", \"max_iter\", \"patience\"], axis=1, errors=\"ignore\")\n",
    "            ls1.append(get_table_e(df[df.w_ms.eq(0) & df.w_ndiv.eq(0) & df.prob_replace.eq(0) & df.delay_alpha.eq(\"0_1\")]))\n",
    "            ls2.append(get_table_e(df[df.w_ms.eq(0) & df.w_ndiv.eq(0) & df.prob_replace.eq(0) & df.delay_alpha.ne(\"0_1\")]))\n",
    "            ls3.append(get_table_e(df[df.prob_replace.eq(0)]))\n",
    "            ls4.append(get_table_e(df[df.prob_replace.ne(0)]))\n",
    "        print(\" & \".join(ls1)+\" \\\\\\\\\")\n",
    "        print(\" & \".join(ls2)+\" \\\\\\\\\")\n",
    "        print(\" & \".join(ls3)+\" \\\\\\\\\")\n",
    "        print(\" & \".join(ls4)+\" \\\\\\\\ \\\\midrule\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ee983a5-73c1-41a5-b157-6122792f276c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Re &  baseline  & $13.13_{0.39}$ & $13.28_{0.47}$ & $13.46_{0.34}$ & $13.66_{0.29}$ \\\\\n",
      "  & best post-hoc & $13.22_{0.30}$ & $13.33_{0.25}$ & $13.37_{0.38}$ & $13.65_{0.23}$ \\\\\n",
      "  &     w losses  & $13.32_{0.36}$ & $13.55_{0.21}$ & $13.61_{0.11}$ & $14.13_{0.45}$ \\\\\n",
      "  &   w sampling  & $13.28_{0.47}$ & $13.40_{0.41}$ & $13.85_{0.16}$ & $14.07_{0.77}$ \\\\ \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#gen_table([\"PM\", \"Com\", \"Ar\", \"Re\"], [\"145\", \"24\", \"43\"])\n",
    "gen_table([\"Re\"], [\"145\", \"24\", \"43\", \"62\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ca7dd13-4d4a-4f0d-a89c-43b42edcc22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cora &  baseline  & $67.49_{1.86}$ & $72.24_{1.35}$ & $76.63_{1.23}$ & $79.61_{2.72}$ & $86.72_{0.37}$ \\\\\n",
      "  & best post-hoc & $68.34_{2.46}$ & $73.28_{1.35}$ & $79.70_{1.25}$ & $82.81_{3.60}$ & $89.30_{1.11}$ \\\\\n",
      "  &     w losses  & $68.42_{1.74}$ & $73.44_{1.76}$ & $79.83_{1.30}$ & $83.30_{2.83}$ & $89.54_{0.77}$ \\\\\n",
      "  &   w sampling  & $68.66_{2.22}$ & $73.62_{0.72}$ & $79.95_{1.19}$ & $83.67_{3.33}$ & $89.79_{0.93}$ \\\\ \\midrule\n",
      "\n",
      "\n",
      "Cite &  baseline  & $44.91_{3.16}$ & $51.97_{0.58}$ & $54.18_{1.86}$ & $58.36_{1.13}$ & $63.96_{1.52}$ \\\\\n",
      "  & best post-hoc & $47.12_{1.99}$ & $53.62_{0.68}$ & $61.69_{0.95}$ & $63.01_{0.74}$ & $68.57_{1.82}$ \\\\\n",
      "  &     w losses  & $47.21_{1.72}$ & $53.69_{0.93}$ & $61.79_{0.76}$ & $63.91_{1.50}$ & $69.48_{1.22}$ \\\\\n",
      "  &   w sampling  & $47.38_{1.47}$ & $53.62_{1.00}$ & $61.76_{1.00}$ & $64.81_{1.26}$ & $72.29_{3.42}$ \\\\ \\midrule\n",
      "\n",
      "\n",
      "Pho &  baseline  & $84.76_{0.12}$ & $87.54_{0.41}$ & $89.69_{0.83}$ & $91.61_{0.85}$ & $92.33_{0.42}$ \\\\\n",
      "  & best post-hoc & $89.13_{0.15}$ & $90.38_{0.18}$ & $91.46_{0.17}$ & $92.75_{0.34}$ & $93.42_{0.08}$ \\\\\n",
      "  &     w losses  & $89.23_{0.25}$ & $90.46_{0.20}$ & $91.62_{0.27}$ & $92.98_{0.33}$ & $93.90_{0.46}$ \\\\\n",
      "  &   w sampling  & $89.25_{0.05}$ & $90.38_{0.08}$ & $91.47_{0.15}$ & $92.79_{0.20}$ & $93.73_{0.39}$ \\\\ \\midrule\n",
      "\n",
      "\n",
      "Act &  baseline  & $25.16_{0.53}$ & $25.73_{0.27}$ & $26.04_{0.67}$ & $27.06_{0.74}$ & $27.72_{0.95}$ \\\\\n",
      "  & best post-hoc & $26.03_{0.29}$ & $26.33_{0.53}$ & $26.45_{1.38}$ & $27.65_{1.42}$ & $27.76_{0.53}$ \\\\\n",
      "  &     w losses  & $26.04_{0.29}$ & $26.37_{0.54}$ & $26.62_{0.50}$ & $27.65_{1.42}$ & $28.07_{1.28}$ \\\\\n",
      "  &   w sampling  & $26.20_{0.31}$ & $26.38_{0.31}$ & $26.36_{0.58}$ & $27.68_{1.03}$ & $27.81_{0.59}$ \\\\ \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_table([\"Cora\", \"Cite\", \"Pho\", \"Act\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9a62975-4f02-42ad-81f3-c818561683ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def do(dss, splits):\n",
    "    for ds in dss:\n",
    "        for split in splits:\n",
    "            print()\n",
    "            print(ds, split)\n",
    "            print()\n",
    "            df = pd.concat([pd.read_pickle(\"../results_comb/\"+ds+\"_\"+split+\".pkl\"), pd.read_pickle(\"../results_comb/\"+ds+\"_\"+split+\"r.pkl\")], ignore_index=True).drop([\n",
    "                \"val_loss\", \"loss_hist\", \"valtest_time\", \"train_time\", \"record_train\", \"save_models\", \"batch_size\", \"batch_size_test\", \"batch_size_val\", \"alpha\", \"delay\", \"save_embeds\",\n",
    "                \"context_size\", \"num_negative_samples\", \"max_iter\", \"patience\"], axis=1, errors=\"ignore\")\n",
    "            print_gen_save(df[df.w_ms.eq(0) & df.w_ndiv.eq(0) & df.prob_replace.eq(0) & df.delay_alpha.eq(\"0_1\")], \"base\")\n",
    "            print_gen_save(df[df.w_ms.eq(0) & df.w_ndiv.eq(0) & df.prob_replace.eq(0) & df.delay_alpha.ne(\"0_1\")], \"post\")\n",
    "            print_gen_save(df[df.prob_replace.eq(0)], \"loss\")\n",
    "            print_gen_save(df[df.prob_replace.ne(0)], \"prob\") #prob and loss hyperparameters were tuned separately -> prob >0 == loss =0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfc9e499-c037-4310-841d-9e00e5b03421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for feature prop\n",
    "def do_fp(dss, splits):\n",
    "    for ds in dss:\n",
    "        for split in splits:\n",
    "            print()\n",
    "            print(ds, split)\n",
    "            print()\n",
    "            df = pd.concat([pd.read_pickle(x) for x in list(Path(\"../results_comb/\").glob(ds+\"_\"+split+\"_fp_*.pkl\"))], ignore_index=True).drop([\n",
    "                \"val_loss\", \"loss_hist\", \"vadelay_alphaltest_time\", \"train_time\", \"record_train\", \"save_models\", \"batch_size\", \"batch_size_test\", \"batch_size_val\", \"alpha\", \"delay\", \"save_embeds\",\n",
    "                \"context_size\", \"num_negative_samples\", \"max_iter\", \"patience\"], axis=1, errors=\"ignore\")\n",
    "            print_gen_save(df[df.w_ms.eq(0) & df.w_ndiv.eq(0) & df.prob_replace.eq(0)], \"base_fp\")\n",
    "            print_gen_save(df[df.prob_replace.eq(0)], \"loss_fp\")\n",
    "            print_gen_save(df[df.prob_replace.ne(0)], \"prob_fp\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8b6ee12-ee04-4a50-8020-e838063ae6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_all(dss, splits):\n",
    "    for ds in dss:\n",
    "        for split in splits:\n",
    "            print()\n",
    "            print(ds, split)\n",
    "            pls =  list(Path(\"../results_comb/\").glob(ds+\"_\"+split+\"*.pkl\"))\n",
    "            print(pls)\n",
    "            print()\n",
    "            df_base = pd.concat([pd.read_pickle(x) for x in pls], ignore_index=True).drop([\n",
    "                \"val_loss\", \"loss_hist\", \"vadelay_alphaltest_time\", \"train_time\", \"record_train\", \"save_models\", \"batch_size\", \"batch_size_test\", \"batch_size_val\", \"alpha\", \"delay\", \"save_embeds\",\n",
    "                \"context_size\", \"num_negative_samples\", \"max_iter\", \"patience\", \"fp\"], axis=1, errors=\"ignore\")\n",
    "            df_base[[\"delay\", \"alpha\"]] = df_base.delay_alpha.str.split(\"_\", expand=True)\n",
    "            \n",
    "            df_inn2v = df_base[df_base.alpha.ne(\"fp\")]\n",
    "            print_gen_save(df_inn2v[df_inn2v.w_ms.eq(0) & df_inn2v.w_ndiv.eq(0) & df_inn2v.prob_replace.eq(0) & df_inn2v.delay_alpha.eq(\"0_1\")], \"base\")\n",
    "            print_gen_save(df_inn2v[df_inn2v.w_ms.eq(0) & df_inn2v.w_ndiv.eq(0) & df_inn2v.prob_replace.eq(0) & df_inn2v.delay_alpha.ne(\"0_1\")], \"post\")\n",
    "            print_gen_save(df_inn2v[df_inn2v.prob_replace.eq(0)], \"loss\")\n",
    "            print_gen_save(df_inn2v[df_inn2v.prob_replace.ne(0)], \"prob\") #prob and loss hyperparameters were tuned separately -> prob >0 == loss =0\n",
    "\n",
    "            df_fp = df_base[df_base.alpha.eq(\"fp\")]\n",
    "            print_gen_save(df_fp[df_fp.w_ms.eq(0) & df_fp.w_ndiv.eq(0) & df_fp.prob_replace.eq(0)], \"base_fp\")\n",
    "            print_gen_save(df_fp[df_fp.prob_replace.eq(0)], \"loss_fp\")\n",
    "            print_gen_save(df_fp[df_fp.prob_replace.ne(0)], \"prob_fp\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da52ddc2-595e-46e0-8c6b-cc401561f188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WCS 81\n",
      "[PosixPath('../results_comb/WCS_81_prob_64.pkl'), PosixPath('../results_comb/WCS_81_loss_256m.pkl'), PosixPath('../results_comb/WCS_81_loss_64.pkl'), PosixPath('../results_comb/WCS_81_loss_256s.pkl'), PosixPath('../results_comb/WCS_81_prob_256.pkl'), PosixPath('../results_comb/WCS_81_loss_256.pkl')]\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    1.0 &    1.0\n",
      "$74.96_{1.12}$\n",
      "74.95725750923157\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'delay', 'alpha']\n",
      "0_0.4 &    256 &    0.01 &    0.2 &    1.0 &    0 &    0.4\n",
      "$79.43_{0.98}$\n",
      "79.4301986694336\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv', 'delay', 'alpha']\n",
      "5_0.6 &    256 &    0.1 &    0.2 &    5.0 &    10.0 &    0.001 &    5 &    0.6\n",
      "$80.14_{0.35}$\n",
      "80.1424503326416\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q', 'delay', 'alpha']\n",
      "0_0.4 &    256 &    0.01 &    1.0 &    0.8 &    1.0 &    0 &    0.4\n",
      "$79.72_{0.70}$\n",
      "79.71510291099548\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'delay']\n",
      "10_fp &    256 &    0.001 &    5.0 &    5.0 &    10\n",
      "$71.94_{0.39}$\n",
      "71.93732261657715\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv', 'delay']\n",
      "10_fp &    256 &    0.01 &    5.0 &    5.0 &    10.0 &    0.01 &    10\n",
      "$74.13_{0.36}$\n",
      "74.13105964660645\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q', 'delay']\n",
      "10_fp &    256 &    0.001 &    5.0 &    0.2 &    1.0 &    10\n",
      "$70.48_{0.36}$\n",
      "70.48433423042297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dss = [\"WCS\"]\n",
    "#splits = [\"145\", \"24\", \"43\", \"62\", \"81\"]\n",
    "splits = [\"81\"]\n",
    "do_all(dss, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "911eb9ba-9a65-4ea0-975d-58cb2632a8b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Com 145\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                       trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr  p   q                                        \n",
      "40_fp       256           0.1 5.0 1.0             5.0  0.718102      1.0   \n",
      "60_fp       256           0.1 5.0 1.0             5.0  0.718102      1.0   \n",
      "\n",
      "                                       ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q                                 \n",
      "40_fp       256           0.1 5.0 1.0          0.0            1.0   \n",
      "60_fp       256           0.1 5.0 1.0          0.0            1.0   \n",
      "\n",
      "                                       optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q                                         \n",
      "40_fp       256           0.1 5.0 1.0            1.0           0.0  145.0   \n",
      "60_fp       256           0.1 5.0 1.0            1.0           0.0  145.0   \n",
      "\n",
      "                                       w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q                                            \n",
      "40_fp       256           0.1 5.0 1.0   0.0     0.0      20.0            10.0  \n",
      "60_fp       256           0.1 5.0 1.0   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "40_fp &    256 &    0.1 &    5.0 &    1.0\n",
      "$71.81_{2.71}$\n",
      "71.8101978302002\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "60_fp &    256 &    0.1 &    1.0 &    1.0 &    1.0 &    0.001\n",
      "$73.07_{2.13}$\n",
      "73.06511402130127\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "60_fp &    256 &    0.1 &    5.0 &    0.2 &    1.0\n",
      "$70.40_{2.22}$\n",
      "70.39909362792969\n",
      "\n",
      "\n",
      "Com 24\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                        trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr   p   q                                        \n",
      "40_fp       256           0.01 1.0 5.0       46.666667  0.770769      1.0   \n",
      "60_fp       256           0.01 1.0 5.0       46.666667  0.770769      1.0   \n",
      "\n",
      "                                        ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q                                 \n",
      "40_fp       256           0.01 1.0 5.0          0.0            1.0   \n",
      "60_fp       256           0.01 1.0 5.0          0.0            1.0   \n",
      "\n",
      "                                        optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q                                         \n",
      "40_fp       256           0.01 1.0 5.0            1.0           0.0   24.0   \n",
      "60_fp       256           0.01 1.0 5.0            1.0           0.0   24.0   \n",
      "\n",
      "                                        w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q                                            \n",
      "40_fp       256           0.01 1.0 5.0   0.0     0.0      20.0            10.0  \n",
      "60_fp       256           0.01 1.0 5.0   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "40_fp &    256 &    0.01 &    1.0 &    5.0\n",
      "$77.08_{0.97}$\n",
      "77.0768940448761\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "20_fp &    256 &    0.1 &    5.0 &    0.2 &    10.0 &    0.1\n",
      "$78.07_{0.45}$\n",
      "78.07065844535828\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                               \n",
      "20_fp       256           0.01 1.0 0.2          5.0       86.666667  0.764891   \n",
      "40_fp       256           0.01 1.0 0.2          5.0       86.666667  0.764891   \n",
      "60_fp       256           0.01 1.0 0.2          5.0       86.666667  0.764891   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "20_fp       256           0.01 1.0 0.2          5.0      1.0          0.0   \n",
      "40_fp       256           0.01 1.0 0.2          5.0      1.0          0.0   \n",
      "60_fp       256           0.01 1.0 0.2          5.0      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "20_fp       256           0.01 1.0 0.2          5.0            1.0   \n",
      "40_fp       256           0.01 1.0 0.2          5.0            1.0   \n",
      "60_fp       256           0.01 1.0 0.2          5.0            1.0   \n",
      "\n",
      "                                                     optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "20_fp       256           0.01 1.0 0.2          5.0            1.0   24.0   \n",
      "40_fp       256           0.01 1.0 0.2          5.0            1.0   24.0   \n",
      "60_fp       256           0.01 1.0 0.2          5.0            1.0   24.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                             \n",
      "20_fp       256           0.01 1.0 0.2          5.0   0.0     0.0      20.0   \n",
      "40_fp       256           0.01 1.0 0.2          5.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.01 1.0 0.2          5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "20_fp       256           0.01 1.0 0.2          5.0            10.0  \n",
      "40_fp       256           0.01 1.0 0.2          5.0            10.0  \n",
      "60_fp       256           0.01 1.0 0.2          5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "20_fp &    256 &    0.01 &    1.0 &    0.2 &    5.0\n",
      "$76.49_{1.38}$\n",
      "76.48912072181702\n",
      "\n",
      "\n",
      "Com 43\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                         trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr    p   q                                        \n",
      "20_fp       256           0.001 0.2 5.0      355.333333  0.814141      1.0   \n",
      "40_fp       256           0.001 0.2 5.0      355.333333  0.814141      1.0   \n",
      "60_fp       256           0.001 0.2 5.0      355.333333  0.814141      1.0   \n",
      "\n",
      "                                         ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   q                                 \n",
      "20_fp       256           0.001 0.2 5.0          0.0            1.0   \n",
      "40_fp       256           0.001 0.2 5.0          0.0            1.0   \n",
      "60_fp       256           0.001 0.2 5.0          0.0            1.0   \n",
      "\n",
      "                                         optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr    p   q                                         \n",
      "20_fp       256           0.001 0.2 5.0            1.0           0.0   43.0   \n",
      "40_fp       256           0.001 0.2 5.0            1.0           0.0   43.0   \n",
      "60_fp       256           0.001 0.2 5.0            1.0           0.0   43.0   \n",
      "\n",
      "                                         w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr    p   q                             \n",
      "20_fp       256           0.001 0.2 5.0   0.0     0.0      20.0   \n",
      "40_fp       256           0.001 0.2 5.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.001 0.2 5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                         walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   q                    \n",
      "20_fp       256           0.001 0.2 5.0            10.0  \n",
      "40_fp       256           0.001 0.2 5.0            10.0  \n",
      "60_fp       256           0.001 0.2 5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "20_fp &    256 &    0.001 &    0.2 &    5.0\n",
      "$81.41_{0.84}$\n",
      "81.41414523124695\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                             \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001       579.333333  0.823677   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001       579.333333  0.823677   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001       579.333333  0.823677   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                         \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001       1.0          0.0   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001       1.0          0.0   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001       1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                  \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "\n",
      "                                                     optim_cluster  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                  \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "\n",
      "                                                     prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                        \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001            0.0   43.0   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001            0.0   43.0   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001            0.0   43.0   \n",
      "\n",
      "                                                     walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                            \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001       20.0            10.0  \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001       20.0            10.0  \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001       20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "20_fp &    256 &    0.001 &    0.2 &    5.0 &    10.0 &    0.001\n",
      "$82.37_{0.98}$\n",
      "82.36767649650574\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                      trained_epochs  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                     \n",
      "40_fp       256           0.001 1.0 0.2          5.0      357.333333   \n",
      "60_fp       256           0.001 1.0 0.2          5.0      357.333333   \n",
      "\n",
      "                                                       val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                        \n",
      "40_fp       256           0.001 1.0 0.2          5.0  0.813091      1.0   \n",
      "60_fp       256           0.001 1.0 0.2          5.0  0.813091      1.0   \n",
      "\n",
      "                                                      ds_add_self  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                  \n",
      "40_fp       256           0.001 1.0 0.2          5.0          0.0   \n",
      "60_fp       256           0.001 1.0 0.2          5.0          0.0   \n",
      "\n",
      "                                                      ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                    \n",
      "40_fp       256           0.001 1.0 0.2          5.0            1.0   \n",
      "60_fp       256           0.001 1.0 0.2          5.0            1.0   \n",
      "\n",
      "                                                      optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                           \n",
      "40_fp       256           0.001 1.0 0.2          5.0            1.0   43.0   \n",
      "60_fp       256           0.001 1.0 0.2          5.0            1.0   43.0   \n",
      "\n",
      "                                                      w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                             \n",
      "40_fp       256           0.001 1.0 0.2          5.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.001 1.0 0.2          5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                      walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   prob_replace q                    \n",
      "40_fp       256           0.001 1.0 0.2          5.0            10.0  \n",
      "60_fp       256           0.001 1.0 0.2          5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "40_fp &    256 &    0.001 &    1.0 &    0.2 &    5.0\n",
      "$81.31_{0.75}$\n",
      "81.30908608436584\n",
      "\n",
      "\n",
      "Com 62\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                         trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr    p   q                                        \n",
      "20_fp       256           0.001 0.2 5.0           259.0  0.836302      1.0   \n",
      "40_fp       256           0.001 0.2 5.0           259.0  0.836302      1.0   \n",
      "60_fp       256           0.001 0.2 5.0           259.0  0.836302      1.0   \n",
      "\n",
      "                                         ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   q                                 \n",
      "20_fp       256           0.001 0.2 5.0          0.0            1.0   \n",
      "40_fp       256           0.001 0.2 5.0          0.0            1.0   \n",
      "60_fp       256           0.001 0.2 5.0          0.0            1.0   \n",
      "\n",
      "                                         optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr    p   q                                         \n",
      "20_fp       256           0.001 0.2 5.0            1.0           0.0   62.0   \n",
      "40_fp       256           0.001 0.2 5.0            1.0           0.0   62.0   \n",
      "60_fp       256           0.001 0.2 5.0            1.0           0.0   62.0   \n",
      "\n",
      "                                         w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr    p   q                             \n",
      "20_fp       256           0.001 0.2 5.0   0.0     0.0      20.0   \n",
      "40_fp       256           0.001 0.2 5.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.001 0.2 5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                         walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   q                    \n",
      "20_fp       256           0.001 0.2 5.0            10.0  \n",
      "40_fp       256           0.001 0.2 5.0            10.0  \n",
      "60_fp       256           0.001 0.2 5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "20_fp &    256 &    0.001 &    0.2 &    5.0\n",
      "$83.63_{0.64}$\n",
      "83.63019824028015\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                             \n",
      "10_fp       256           0.001 0.2 5.0 10.0 0.001       382.666667  0.845147   \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001       382.666667  0.845147   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001       382.666667  0.845147   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001       382.666667  0.845147   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                         \n",
      "10_fp       256           0.001 0.2 5.0 10.0 0.001       1.0          0.0   \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001       1.0          0.0   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001       1.0          0.0   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001       1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "\n",
      "                                                     optim_cluster  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "\n",
      "                                                     prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                        \n",
      "10_fp       256           0.001 0.2 5.0 10.0 0.001            0.0   62.0   \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001            0.0   62.0   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001            0.0   62.0   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001            0.0   62.0   \n",
      "\n",
      "                                                     walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                            \n",
      "10_fp       256           0.001 0.2 5.0 10.0 0.001       20.0            10.0  \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001       20.0            10.0  \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001       20.0            10.0  \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001       20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    256 &    0.001 &    0.2 &    5.0 &    10.0 &    0.001\n",
      "$84.51_{0.49}$\n",
      "84.514719247818\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    256 &    0.001 &    0.2 &    0.4 &    5.0\n",
      "$83.47_{0.33}$\n",
      "83.47268104553223\n",
      "\n",
      "\n",
      "Com 81\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                         trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr    p   q                                        \n",
      "10_fp       256           0.001 0.2 5.0      253.666667  0.839758      1.0   \n",
      "20_fp       256           0.001 0.2 5.0      253.666667  0.839758      1.0   \n",
      "40_fp       256           0.001 0.2 5.0      253.666667  0.839758      1.0   \n",
      "60_fp       256           0.001 0.2 5.0      253.666667  0.839758      1.0   \n",
      "\n",
      "                                         ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   q                                 \n",
      "10_fp       256           0.001 0.2 5.0          0.0            1.0   \n",
      "20_fp       256           0.001 0.2 5.0          0.0            1.0   \n",
      "40_fp       256           0.001 0.2 5.0          0.0            1.0   \n",
      "60_fp       256           0.001 0.2 5.0          0.0            1.0   \n",
      "\n",
      "                                         optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr    p   q                                         \n",
      "10_fp       256           0.001 0.2 5.0            1.0           0.0   81.0   \n",
      "20_fp       256           0.001 0.2 5.0            1.0           0.0   81.0   \n",
      "40_fp       256           0.001 0.2 5.0            1.0           0.0   81.0   \n",
      "60_fp       256           0.001 0.2 5.0            1.0           0.0   81.0   \n",
      "\n",
      "                                         w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr    p   q                             \n",
      "10_fp       256           0.001 0.2 5.0   0.0     0.0      20.0   \n",
      "20_fp       256           0.001 0.2 5.0   0.0     0.0      20.0   \n",
      "40_fp       256           0.001 0.2 5.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.001 0.2 5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                         walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   q                    \n",
      "10_fp       256           0.001 0.2 5.0            10.0  \n",
      "20_fp       256           0.001 0.2 5.0            10.0  \n",
      "40_fp       256           0.001 0.2 5.0            10.0  \n",
      "60_fp       256           0.001 0.2 5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "10_fp &    256 &    0.001 &    0.2 &    5.0\n",
      "$83.98_{1.06}$\n",
      "83.97576212882996\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                             \n",
      "10_fp       256           0.001 0.2 5.0 10.0 0.001            348.0  0.854545   \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001            348.0  0.854545   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001            348.0  0.854545   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001            348.0  0.854545   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                         \n",
      "10_fp       256           0.001 0.2 5.0 10.0 0.001       1.0          0.0   \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001       1.0          0.0   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001       1.0          0.0   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001       1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "\n",
      "                                                     optim_cluster  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001             1.0   \n",
      "\n",
      "                                                     prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                        \n",
      "10_fp       256           0.001 0.2 5.0 10.0 0.001            0.0   81.0   \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001            0.0   81.0   \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001            0.0   81.0   \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001            0.0   81.0   \n",
      "\n",
      "                                                     walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                            \n",
      "10_fp       256           0.001 0.2 5.0 10.0 0.001       20.0            10.0  \n",
      "20_fp       256           0.001 0.2 5.0 10.0 0.001       20.0            10.0  \n",
      "40_fp       256           0.001 0.2 5.0 10.0 0.001       20.0            10.0  \n",
      "60_fp       256           0.001 0.2 5.0 10.0 0.001       20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    256 &    0.001 &    0.2 &    5.0 &    10.0 &    0.001\n",
      "$85.45_{0.77}$\n",
      "85.45454144477844\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                      trained_epochs  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                     \n",
      "10_fp       256           0.001 0.2 0.2          5.0           283.0   \n",
      "20_fp       256           0.001 0.2 0.2          5.0           283.0   \n",
      "40_fp       256           0.001 0.2 0.2          5.0           283.0   \n",
      "60_fp       256           0.001 0.2 0.2          5.0           283.0   \n",
      "\n",
      "                                                       val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                        \n",
      "10_fp       256           0.001 0.2 0.2          5.0  0.838546      1.0   \n",
      "20_fp       256           0.001 0.2 0.2          5.0  0.838546      1.0   \n",
      "40_fp       256           0.001 0.2 0.2          5.0  0.838546      1.0   \n",
      "60_fp       256           0.001 0.2 0.2          5.0  0.838546      1.0   \n",
      "\n",
      "                                                      ds_add_self  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                  \n",
      "10_fp       256           0.001 0.2 0.2          5.0          0.0   \n",
      "20_fp       256           0.001 0.2 0.2          5.0          0.0   \n",
      "40_fp       256           0.001 0.2 0.2          5.0          0.0   \n",
      "60_fp       256           0.001 0.2 0.2          5.0          0.0   \n",
      "\n",
      "                                                      ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                    \n",
      "10_fp       256           0.001 0.2 0.2          5.0            1.0   \n",
      "20_fp       256           0.001 0.2 0.2          5.0            1.0   \n",
      "40_fp       256           0.001 0.2 0.2          5.0            1.0   \n",
      "60_fp       256           0.001 0.2 0.2          5.0            1.0   \n",
      "\n",
      "                                                      optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                           \n",
      "10_fp       256           0.001 0.2 0.2          5.0            1.0   81.0   \n",
      "20_fp       256           0.001 0.2 0.2          5.0            1.0   81.0   \n",
      "40_fp       256           0.001 0.2 0.2          5.0            1.0   81.0   \n",
      "60_fp       256           0.001 0.2 0.2          5.0            1.0   81.0   \n",
      "\n",
      "                                                      w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                             \n",
      "10_fp       256           0.001 0.2 0.2          5.0   0.0     0.0      20.0   \n",
      "20_fp       256           0.001 0.2 0.2          5.0   0.0     0.0      20.0   \n",
      "40_fp       256           0.001 0.2 0.2          5.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.001 0.2 0.2          5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                      walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   prob_replace q                    \n",
      "10_fp       256           0.001 0.2 0.2          5.0            10.0  \n",
      "20_fp       256           0.001 0.2 0.2          5.0            10.0  \n",
      "40_fp       256           0.001 0.2 0.2          5.0            10.0  \n",
      "60_fp       256           0.001 0.2 0.2          5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    256 &    0.001 &    0.2 &    0.2 &    5.0\n",
      "$83.85_{1.42}$\n",
      "83.85455012321472\n",
      "\n",
      "\n",
      "Ar 145\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q']\n",
      "10_fp &    256 &    0.1 &    False &    1.0 &    0.2\n",
      "$37.91_{0.47}$\n",
      "37.90600597858429\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    256 &    0.1 &    False &    0.2 &    5.0 &    10.0 &    0.01\n",
      "$38.21_{0.15}$\n",
      "38.211455941200256\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    256 &    0.1 &    0.2 &    0.2 &    5.0\n",
      "$37.91_{0.14}$\n",
      "37.91205585002899\n",
      "\n",
      "\n",
      "Ar 24\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "20_fp &    256 &    0.01 &    0.2 &    5.0\n",
      "$38.70_{0.56}$\n",
      "38.69551718235016\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "20_fp &    256 &    0.01 &    0.2 &    5.0 &    0.0 &    0.0\n",
      "$38.70_{0.56}$\n",
      "38.69551718235016\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "20_fp &    256 &    0.01 &    5.0 &    0.2 &    1.0\n",
      "$38.75_{0.71}$\n",
      "38.746556639671326\n",
      "\n",
      "\n",
      "Ar 43\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "10_fp &    256 &    0.01 &    1.0 &    0.2\n",
      "$40.71_{0.10}$\n",
      "40.71049392223358\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                    trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                             \n",
      "40_fp       256           0.01 0.2 0.2 10.0 0.001       193.666667  0.412186   \n",
      "60_fp       256           0.01 0.2 0.2 10.0 0.001       193.666667  0.412186   \n",
      "\n",
      "                                                    statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                         \n",
      "40_fp       256           0.01 0.2 0.2 10.0 0.001       1.0          0.0   \n",
      "60_fp       256           0.01 0.2 0.2 10.0 0.001       1.0          0.0   \n",
      "\n",
      "                                                    ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "40_fp       256           0.01 0.2 0.2 10.0 0.001             1.0   \n",
      "60_fp       256           0.01 0.2 0.2 10.0 0.001             1.0   \n",
      "\n",
      "                                                    optim_cluster  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "40_fp       256           0.01 0.2 0.2 10.0 0.001             1.0   \n",
      "60_fp       256           0.01 0.2 0.2 10.0 0.001             1.0   \n",
      "\n",
      "                                                    prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                        \n",
      "40_fp       256           0.01 0.2 0.2 10.0 0.001            0.0   43.0   \n",
      "60_fp       256           0.01 0.2 0.2 10.0 0.001            0.0   43.0   \n",
      "\n",
      "                                                    walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                            \n",
      "40_fp       256           0.01 0.2 0.2 10.0 0.001       20.0            10.0  \n",
      "60_fp       256           0.01 0.2 0.2 10.0 0.001       20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "40_fp &    256 &    0.01 &    0.2 &    0.2 &    10.0 &    0.001\n",
      "$41.22_{0.32}$\n",
      "41.21863842010498\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                      trained_epochs  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                     \n",
      "10_fp       256           0.001 5.0 0.6          5.0      313.000000   \n",
      "20_fp       256           0.001 5.0 0.6          1.0      324.666667   \n",
      "                                                 5.0      313.000000   \n",
      "40_fp       256           0.001 5.0 0.6          1.0      324.666667   \n",
      "\n",
      "                                                       val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                        \n",
      "10_fp       256           0.001 5.0 0.6          5.0  0.406742      1.0   \n",
      "20_fp       256           0.001 5.0 0.6          1.0  0.406742      1.0   \n",
      "                                                 5.0  0.406742      1.0   \n",
      "40_fp       256           0.001 5.0 0.6          1.0  0.406742      1.0   \n",
      "\n",
      "                                                      ds_add_self  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                  \n",
      "10_fp       256           0.001 5.0 0.6          5.0          0.0   \n",
      "20_fp       256           0.001 5.0 0.6          1.0          0.0   \n",
      "                                                 5.0          0.0   \n",
      "40_fp       256           0.001 5.0 0.6          1.0          0.0   \n",
      "\n",
      "                                                      ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                    \n",
      "10_fp       256           0.001 5.0 0.6          5.0            1.0   \n",
      "20_fp       256           0.001 5.0 0.6          1.0            1.0   \n",
      "                                                 5.0            1.0   \n",
      "40_fp       256           0.001 5.0 0.6          1.0            1.0   \n",
      "\n",
      "                                                      optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                           \n",
      "10_fp       256           0.001 5.0 0.6          5.0            1.0   43.0   \n",
      "20_fp       256           0.001 5.0 0.6          1.0            1.0   43.0   \n",
      "                                                 5.0            1.0   43.0   \n",
      "40_fp       256           0.001 5.0 0.6          1.0            1.0   43.0   \n",
      "\n",
      "                                                      w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                             \n",
      "10_fp       256           0.001 5.0 0.6          5.0   0.0     0.0      20.0   \n",
      "20_fp       256           0.001 5.0 0.6          1.0   0.0     0.0      20.0   \n",
      "                                                 5.0   0.0     0.0      20.0   \n",
      "40_fp       256           0.001 5.0 0.6          1.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                      walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   prob_replace q                    \n",
      "10_fp       256           0.001 5.0 0.6          5.0            10.0  \n",
      "20_fp       256           0.001 5.0 0.6          1.0            10.0  \n",
      "                                                 5.0            10.0  \n",
      "40_fp       256           0.001 5.0 0.6          1.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "20_fp &    256 &    0.001 &    5.0 &    0.6 &    5.0\n",
      "$40.67_{0.18}$\n",
      "40.67419767379761\n",
      "\n",
      "\n",
      "Ar 62\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                        trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr   p   q                                        \n",
      "20_fp       256           0.01 1.0 1.0       71.666667  0.426073      1.0   \n",
      "40_fp       256           0.01 1.0 1.0       71.666667  0.426073      1.0   \n",
      "60_fp       256           0.01 1.0 1.0       71.666667  0.426073      1.0   \n",
      "\n",
      "                                        ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q                                 \n",
      "20_fp       256           0.01 1.0 1.0          0.0            1.0   \n",
      "40_fp       256           0.01 1.0 1.0          0.0            1.0   \n",
      "60_fp       256           0.01 1.0 1.0          0.0            1.0   \n",
      "\n",
      "                                        optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q                                         \n",
      "20_fp       256           0.01 1.0 1.0            1.0           0.0   62.0   \n",
      "40_fp       256           0.01 1.0 1.0            1.0           0.0   62.0   \n",
      "60_fp       256           0.01 1.0 1.0            1.0           0.0   62.0   \n",
      "\n",
      "                                        w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q                                            \n",
      "20_fp       256           0.01 1.0 1.0   0.0     0.0      20.0            10.0  \n",
      "40_fp       256           0.01 1.0 1.0   0.0     0.0      20.0            10.0  \n",
      "60_fp       256           0.01 1.0 1.0   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "20_fp &    256 &    0.01 &    1.0 &    1.0\n",
      "$42.61_{0.55}$\n",
      "42.60733425617218\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "20_fp &    256 &    0.01 &    5.0 &    1.0 &    10.0 &    0.001\n",
      "$42.76_{0.42}$\n",
      "42.76382923126221\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                               \n",
      "20_fp       256           0.01 0.2 0.2          0.2      139.666667  0.422875   \n",
      "40_fp       256           0.01 0.2 0.2          0.2      139.666667  0.422875   \n",
      "60_fp       256           0.01 0.2 0.2          0.2      139.666667  0.422875   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "20_fp       256           0.01 0.2 0.2          0.2      1.0          0.0   \n",
      "40_fp       256           0.01 0.2 0.2          0.2      1.0          0.0   \n",
      "60_fp       256           0.01 0.2 0.2          0.2      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "20_fp       256           0.01 0.2 0.2          0.2            1.0   \n",
      "40_fp       256           0.01 0.2 0.2          0.2            1.0   \n",
      "60_fp       256           0.01 0.2 0.2          0.2            1.0   \n",
      "\n",
      "                                                     optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "20_fp       256           0.01 0.2 0.2          0.2            1.0   62.0   \n",
      "40_fp       256           0.01 0.2 0.2          0.2            1.0   62.0   \n",
      "60_fp       256           0.01 0.2 0.2          0.2            1.0   62.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                             \n",
      "20_fp       256           0.01 0.2 0.2          0.2   0.0     0.0      20.0   \n",
      "40_fp       256           0.01 0.2 0.2          0.2   0.0     0.0      20.0   \n",
      "60_fp       256           0.01 0.2 0.2          0.2   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "20_fp       256           0.01 0.2 0.2          0.2            10.0  \n",
      "40_fp       256           0.01 0.2 0.2          0.2            10.0  \n",
      "60_fp       256           0.01 0.2 0.2          0.2            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "20_fp &    256 &    0.01 &    0.2 &    0.2 &    0.2\n",
      "$42.29_{0.39}$\n",
      "42.287540435791016\n",
      "\n",
      "\n",
      "Ar 81\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                        trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr   p   q                                        \n",
      "10_fp       256           0.01 5.0 0.2       64.333333  0.427658      1.0   \n",
      "20_fp       256           0.01 5.0 0.2       64.333333  0.427658      1.0   \n",
      "40_fp       256           0.01 5.0 0.2       64.333333  0.427658      1.0   \n",
      "60_fp       256           0.01 5.0 0.2       64.333333  0.427658      1.0   \n",
      "\n",
      "                                        ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q                                 \n",
      "10_fp       256           0.01 5.0 0.2          0.0            1.0   \n",
      "20_fp       256           0.01 5.0 0.2          0.0            1.0   \n",
      "40_fp       256           0.01 5.0 0.2          0.0            1.0   \n",
      "60_fp       256           0.01 5.0 0.2          0.0            1.0   \n",
      "\n",
      "                                        optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q                                         \n",
      "10_fp       256           0.01 5.0 0.2            1.0           0.0   81.0   \n",
      "20_fp       256           0.01 5.0 0.2            1.0           0.0   81.0   \n",
      "40_fp       256           0.01 5.0 0.2            1.0           0.0   81.0   \n",
      "60_fp       256           0.01 5.0 0.2            1.0           0.0   81.0   \n",
      "\n",
      "                                        w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q                                            \n",
      "10_fp       256           0.01 5.0 0.2   0.0     0.0      20.0            10.0  \n",
      "20_fp       256           0.01 5.0 0.2   0.0     0.0      20.0            10.0  \n",
      "40_fp       256           0.01 5.0 0.2   0.0     0.0      20.0            10.0  \n",
      "60_fp       256           0.01 5.0 0.2   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "10_fp &    256 &    0.01 &    5.0 &    0.2\n",
      "$42.77_{1.47}$\n",
      "42.76575148105621\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                    trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                             \n",
      "10_fp       256           0.01 5.0 0.2 10.0 0.01             133.0  0.433782   \n",
      "20_fp       256           0.01 5.0 0.2 10.0 0.01             133.0  0.433782   \n",
      "40_fp       256           0.01 5.0 0.2 10.0 0.01             133.0  0.433782   \n",
      "60_fp       256           0.01 5.0 0.2 10.0 0.01             133.0  0.433782   \n",
      "\n",
      "                                                    statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                         \n",
      "10_fp       256           0.01 5.0 0.2 10.0 0.01        1.0          0.0   \n",
      "20_fp       256           0.01 5.0 0.2 10.0 0.01        1.0          0.0   \n",
      "40_fp       256           0.01 5.0 0.2 10.0 0.01        1.0          0.0   \n",
      "60_fp       256           0.01 5.0 0.2 10.0 0.01        1.0          0.0   \n",
      "\n",
      "                                                    ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.01 5.0 0.2 10.0 0.01              1.0   \n",
      "20_fp       256           0.01 5.0 0.2 10.0 0.01              1.0   \n",
      "40_fp       256           0.01 5.0 0.2 10.0 0.01              1.0   \n",
      "60_fp       256           0.01 5.0 0.2 10.0 0.01              1.0   \n",
      "\n",
      "                                                    optim_cluster  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.01 5.0 0.2 10.0 0.01              1.0   \n",
      "20_fp       256           0.01 5.0 0.2 10.0 0.01              1.0   \n",
      "40_fp       256           0.01 5.0 0.2 10.0 0.01              1.0   \n",
      "60_fp       256           0.01 5.0 0.2 10.0 0.01              1.0   \n",
      "\n",
      "                                                    prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                        \n",
      "10_fp       256           0.01 5.0 0.2 10.0 0.01             0.0   81.0   \n",
      "20_fp       256           0.01 5.0 0.2 10.0 0.01             0.0   81.0   \n",
      "40_fp       256           0.01 5.0 0.2 10.0 0.01             0.0   81.0   \n",
      "60_fp       256           0.01 5.0 0.2 10.0 0.01             0.0   81.0   \n",
      "\n",
      "                                                    walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                            \n",
      "10_fp       256           0.01 5.0 0.2 10.0 0.01        20.0            10.0  \n",
      "20_fp       256           0.01 5.0 0.2 10.0 0.01        20.0            10.0  \n",
      "40_fp       256           0.01 5.0 0.2 10.0 0.01        20.0            10.0  \n",
      "60_fp       256           0.01 5.0 0.2 10.0 0.01        20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    256 &    0.01 &    5.0 &    0.2 &    10.0 &    0.01\n",
      "$43.38_{1.97}$\n",
      "43.37824881076813\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                      trained_epochs  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                     \n",
      "10_fp       256           0.001 1.0 0.2          1.0           220.0   \n",
      "20_fp       256           0.001 1.0 0.2          1.0           220.0   \n",
      "40_fp       256           0.001 1.0 0.2          1.0           220.0   \n",
      "60_fp       256           0.001 1.0 0.2          1.0           220.0   \n",
      "\n",
      "                                                       val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                        \n",
      "10_fp       256           0.001 1.0 0.2          1.0  0.426433      1.0   \n",
      "20_fp       256           0.001 1.0 0.2          1.0  0.426433      1.0   \n",
      "40_fp       256           0.001 1.0 0.2          1.0  0.426433      1.0   \n",
      "60_fp       256           0.001 1.0 0.2          1.0  0.426433      1.0   \n",
      "\n",
      "                                                      ds_add_self  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                  \n",
      "10_fp       256           0.001 1.0 0.2          1.0          0.0   \n",
      "20_fp       256           0.001 1.0 0.2          1.0          0.0   \n",
      "40_fp       256           0.001 1.0 0.2          1.0          0.0   \n",
      "60_fp       256           0.001 1.0 0.2          1.0          0.0   \n",
      "\n",
      "                                                      ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                    \n",
      "10_fp       256           0.001 1.0 0.2          1.0            1.0   \n",
      "20_fp       256           0.001 1.0 0.2          1.0            1.0   \n",
      "40_fp       256           0.001 1.0 0.2          1.0            1.0   \n",
      "60_fp       256           0.001 1.0 0.2          1.0            1.0   \n",
      "\n",
      "                                                      optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                           \n",
      "10_fp       256           0.001 1.0 0.2          1.0            1.0   81.0   \n",
      "20_fp       256           0.001 1.0 0.2          1.0            1.0   81.0   \n",
      "40_fp       256           0.001 1.0 0.2          1.0            1.0   81.0   \n",
      "60_fp       256           0.001 1.0 0.2          1.0            1.0   81.0   \n",
      "\n",
      "                                                      w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                             \n",
      "10_fp       256           0.001 1.0 0.2          1.0   0.0     0.0      20.0   \n",
      "20_fp       256           0.001 1.0 0.2          1.0   0.0     0.0      20.0   \n",
      "40_fp       256           0.001 1.0 0.2          1.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.001 1.0 0.2          1.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                      walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   prob_replace q                    \n",
      "10_fp       256           0.001 1.0 0.2          1.0            10.0  \n",
      "20_fp       256           0.001 1.0 0.2          1.0            10.0  \n",
      "40_fp       256           0.001 1.0 0.2          1.0            10.0  \n",
      "60_fp       256           0.001 1.0 0.2          1.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    256 &    0.001 &    1.0 &    0.2 &    1.0\n",
      "$42.64_{1.55}$\n",
      "42.64325201511383\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dss = [\"Com\", \"Ar\"]\n",
    "splits = [\"145\", \"24\", \"43\", \"62\", \"81\"]\n",
    "do_fp(dss, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef5ab9de-f5b7-4d12-836c-0d5c39d7b244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cora 145\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                               \n",
      "60_fp       256           0.1 False         0.2 1.0        6.333333  0.661193   \n",
      "                                            1.0 5.0        5.000000  0.661193   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                           \n",
      "60_fp       256           0.1 False         0.2 1.0      1.0          0.0   \n",
      "                                            1.0 5.0      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                    \n",
      "60_fp       256           0.1 False         0.2 1.0            1.0   \n",
      "                                            1.0 5.0            1.0   \n",
      "\n",
      "                                                     prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                          \n",
      "60_fp       256           0.1 False         0.2 1.0           0.0  145.0   \n",
      "                                            1.0 5.0           0.0  145.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                             \n",
      "60_fp       256           0.1 False         0.2 1.0   0.0     0.0      20.0   \n",
      "                                            1.0 5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                    \n",
      "60_fp       256           0.1 False         0.2 1.0            10.0  \n",
      "                                            1.0 5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q']\n",
      "60_fp &    256 &    0.1 &    False &    0.2 &    1.0\n",
      "$66.12_{2.52}$\n",
      "66.11931920051575\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "60_fp &    256 &    0.1 &    False &    1.0 &    1.0 &    0.0 &    0.1\n",
      "$66.78_{2.53}$\n",
      "66.77613258361816\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "60_fp &    256 &    0.1 &    0.2 &    0.2 &    5.0\n",
      "$66.64_{2.57}$\n",
      "66.6392982006073\n",
      "\n",
      "\n",
      "Cora 24\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q']\n",
      "40_fp &    256 &    0.1 &    False &    0.2 &    0.2\n",
      "$71.59_{2.01}$\n",
      "71.59125804901123\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                                 trained_epochs  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                   \n",
      "40_fp       256           0.1 False         0.2 0.2 1.0  0.001        31.666667   \n",
      "60_fp       256           0.1 False         0.2 0.2 1.0  0.001        31.666667   \n",
      "                                            5.0 0.2 1.0  0.000        31.333333   \n",
      "\n",
      "                                                                  val_acc  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv             \n",
      "40_fp       256           0.1 False         0.2 0.2 1.0  0.001   0.717452   \n",
      "60_fp       256           0.1 False         0.2 0.2 1.0  0.001   0.717452   \n",
      "                                            5.0 0.2 1.0  0.000   0.717452   \n",
      "\n",
      "                                                                 statrep  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv            \n",
      "40_fp       256           0.1 False         0.2 0.2 1.0  0.001       1.0   \n",
      "60_fp       256           0.1 False         0.2 0.2 1.0  0.001       1.0   \n",
      "                                            5.0 0.2 1.0  0.000       1.0   \n",
      "\n",
      "                                                                 ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                \n",
      "40_fp       256           0.1 False         0.2 0.2 1.0  0.001           0.0   \n",
      "60_fp       256           0.1 False         0.2 0.2 1.0  0.001           0.0   \n",
      "                                            5.0 0.2 1.0  0.000           0.0   \n",
      "\n",
      "                                                                 ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                  \n",
      "40_fp       256           0.1 False         0.2 0.2 1.0  0.001             1.0   \n",
      "60_fp       256           0.1 False         0.2 0.2 1.0  0.001             1.0   \n",
      "                                            5.0 0.2 1.0  0.000             1.0   \n",
      "\n",
      "                                                                 prob_replace  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                 \n",
      "40_fp       256           0.1 False         0.2 0.2 1.0  0.001            0.0   \n",
      "60_fp       256           0.1 False         0.2 0.2 1.0  0.001            0.0   \n",
      "                                            5.0 0.2 1.0  0.000            0.0   \n",
      "\n",
      "                                                                 split  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv          \n",
      "40_fp       256           0.1 False         0.2 0.2 1.0  0.001    24.0   \n",
      "60_fp       256           0.1 False         0.2 0.2 1.0  0.001    24.0   \n",
      "                                            5.0 0.2 1.0  0.000    24.0   \n",
      "\n",
      "                                                                 walk_len  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv             \n",
      "40_fp       256           0.1 False         0.2 0.2 1.0  0.001       20.0   \n",
      "60_fp       256           0.1 False         0.2 0.2 1.0  0.001       20.0   \n",
      "                                            5.0 0.2 1.0  0.000       20.0   \n",
      "\n",
      "                                                                 walks_per_node  \n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                  \n",
      "40_fp       256           0.1 False         0.2 0.2 1.0  0.001             10.0  \n",
      "60_fp       256           0.1 False         0.2 0.2 1.0  0.001             10.0  \n",
      "                                            5.0 0.2 1.0  0.000             10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "60_fp &    256 &    0.1 &    False &    5.0 &    0.2 &    1.0 &    0.0\n",
      "$71.75_{0.80}$\n",
      "71.74515724182129\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "60_fp &    256 &    0.1 &    0.2 &    0.2 &    5.0\n",
      "$71.47_{2.00}$\n",
      "71.46814465522766\n",
      "\n",
      "\n",
      "Cora 43\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                               \n",
      "40_fp       256           0.1 False         1.0 5.0       14.666667  0.745797   \n",
      "60_fp       256           0.1 False         1.0 5.0       14.666667  0.745797   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                           \n",
      "40_fp       256           0.1 False         1.0 5.0      1.0          0.0   \n",
      "60_fp       256           0.1 False         1.0 5.0      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                    \n",
      "40_fp       256           0.1 False         1.0 5.0            1.0   \n",
      "60_fp       256           0.1 False         1.0 5.0            1.0   \n",
      "\n",
      "                                                     prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                          \n",
      "40_fp       256           0.1 False         1.0 5.0           0.0   43.0   \n",
      "60_fp       256           0.1 False         1.0 5.0           0.0   43.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                             \n",
      "40_fp       256           0.1 False         1.0 5.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.1 False         1.0 5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                    \n",
      "40_fp       256           0.1 False         1.0 5.0            10.0  \n",
      "60_fp       256           0.1 False         1.0 5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q']\n",
      "40_fp &    256 &    0.1 &    False &    1.0 &    5.0\n",
      "$74.58_{1.21}$\n",
      "74.57974553108215\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "60_fp &    256 &    0.1 &    False &    0.2 &    0.2 &    1.0 &    0.0\n",
      "$75.52_{2.18}$\n",
      "75.52275657653809\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                    trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                               \n",
      "40_fp       256           0.1 5.0 0.2          5.0        5.333333  0.742107   \n",
      "60_fp       256           0.1 5.0 0.2          5.0        5.333333  0.742107   \n",
      "\n",
      "                                                    statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                           \n",
      "40_fp       256           0.1 5.0 0.2          5.0      1.0          0.0   \n",
      "60_fp       256           0.1 5.0 0.2          5.0      1.0          0.0   \n",
      "\n",
      "                                                    ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                    \n",
      "40_fp       256           0.1 5.0 0.2          5.0            1.0   \n",
      "60_fp       256           0.1 5.0 0.2          5.0            1.0   \n",
      "\n",
      "                                                    optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                           \n",
      "40_fp       256           0.1 5.0 0.2          5.0            1.0   43.0   \n",
      "60_fp       256           0.1 5.0 0.2          5.0            1.0   43.0   \n",
      "\n",
      "                                                    w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                             \n",
      "40_fp       256           0.1 5.0 0.2          5.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.1 5.0 0.2          5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                    walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   prob_replace q                    \n",
      "40_fp       256           0.1 5.0 0.2          5.0            10.0  \n",
      "60_fp       256           0.1 5.0 0.2          5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "40_fp &    256 &    0.1 &    5.0 &    0.2 &    5.0\n",
      "$74.21_{1.02}$\n",
      "74.21073913574219\n",
      "\n",
      "\n",
      "Cora 62\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                        trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr   p   q                                        \n",
      "40_fp       256           0.01 1.0 0.2           160.0  0.788047      1.0   \n",
      "60_fp       256           0.01 1.0 0.2           160.0  0.788047      1.0   \n",
      "\n",
      "                                        ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q                                 \n",
      "40_fp       256           0.01 1.0 0.2          0.0            1.0   \n",
      "60_fp       256           0.01 1.0 0.2          0.0            1.0   \n",
      "\n",
      "                                        optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q                                         \n",
      "40_fp       256           0.01 1.0 0.2            1.0           0.0   62.0   \n",
      "60_fp       256           0.01 1.0 0.2            1.0           0.0   62.0   \n",
      "\n",
      "                                        w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q                                            \n",
      "40_fp       256           0.01 1.0 0.2   0.0     0.0      20.0            10.0  \n",
      "60_fp       256           0.01 1.0 0.2   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "40_fp &    256 &    0.01 &    1.0 &    0.2\n",
      "$78.80_{2.46}$\n",
      "78.80468368530273\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                   trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                             \n",
      "40_fp       256           0.1 5.0 1.0 10.0 0.001        28.666667  0.798521   \n",
      "60_fp       256           0.1 5.0 1.0 10.0 0.001        28.666667  0.798521   \n",
      "\n",
      "                                                   statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                         \n",
      "40_fp       256           0.1 5.0 1.0 10.0 0.001       1.0          0.0   \n",
      "60_fp       256           0.1 5.0 1.0 10.0 0.001       1.0          0.0   \n",
      "\n",
      "                                                   ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "40_fp       256           0.1 5.0 1.0 10.0 0.001             1.0   \n",
      "60_fp       256           0.1 5.0 1.0 10.0 0.001             1.0   \n",
      "\n",
      "                                                   optim_cluster  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "40_fp       256           0.1 5.0 1.0 10.0 0.001             1.0   \n",
      "60_fp       256           0.1 5.0 1.0 10.0 0.001             1.0   \n",
      "\n",
      "                                                   prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                        \n",
      "40_fp       256           0.1 5.0 1.0 10.0 0.001            0.0   62.0   \n",
      "60_fp       256           0.1 5.0 1.0 10.0 0.001            0.0   62.0   \n",
      "\n",
      "                                                   walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                            \n",
      "40_fp       256           0.1 5.0 1.0 10.0 0.001       20.0            10.0  \n",
      "60_fp       256           0.1 5.0 1.0 10.0 0.001       20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "40_fp &    256 &    0.1 &    5.0 &    1.0 &    10.0 &    0.001\n",
      "$79.85_{3.74}$\n",
      "79.85212802886963\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                               \n",
      "40_fp       256           0.01 5.0 0.2          5.0      155.666667  0.783734   \n",
      "60_fp       256           0.01 5.0 0.2          5.0      155.666667  0.783734   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "40_fp       256           0.01 5.0 0.2          5.0      1.0          0.0   \n",
      "60_fp       256           0.01 5.0 0.2          5.0      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "40_fp       256           0.01 5.0 0.2          5.0            1.0   \n",
      "60_fp       256           0.01 5.0 0.2          5.0            1.0   \n",
      "\n",
      "                                                     optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "40_fp       256           0.01 5.0 0.2          5.0            1.0   62.0   \n",
      "60_fp       256           0.01 5.0 0.2          5.0            1.0   62.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                             \n",
      "40_fp       256           0.01 5.0 0.2          5.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.01 5.0 0.2          5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "40_fp       256           0.01 5.0 0.2          5.0            10.0  \n",
      "60_fp       256           0.01 5.0 0.2          5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "40_fp &    256 &    0.01 &    5.0 &    0.2 &    5.0\n",
      "$78.37_{2.42}$\n",
      "78.37338447570801\n",
      "\n",
      "\n",
      "Cora 81\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                        trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr   p   q                                        \n",
      "10_fp       256           0.01 1.0 1.0           103.0  0.858549      1.0   \n",
      "20_fp       256           0.01 1.0 1.0           103.0  0.858549      1.0   \n",
      "40_fp       256           0.01 1.0 1.0           103.0  0.858549      1.0   \n",
      "60_fp       256           0.01 1.0 1.0           103.0  0.858549      1.0   \n",
      "\n",
      "                                        ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q                                 \n",
      "10_fp       256           0.01 1.0 1.0          0.0            1.0   \n",
      "20_fp       256           0.01 1.0 1.0          0.0            1.0   \n",
      "40_fp       256           0.01 1.0 1.0          0.0            1.0   \n",
      "60_fp       256           0.01 1.0 1.0          0.0            1.0   \n",
      "\n",
      "                                        optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q                                         \n",
      "10_fp       256           0.01 1.0 1.0            1.0           0.0   81.0   \n",
      "20_fp       256           0.01 1.0 1.0            1.0           0.0   81.0   \n",
      "40_fp       256           0.01 1.0 1.0            1.0           0.0   81.0   \n",
      "60_fp       256           0.01 1.0 1.0            1.0           0.0   81.0   \n",
      "\n",
      "                                        w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q                                            \n",
      "10_fp       256           0.01 1.0 1.0   0.0     0.0      20.0            10.0  \n",
      "20_fp       256           0.01 1.0 1.0   0.0     0.0      20.0            10.0  \n",
      "40_fp       256           0.01 1.0 1.0   0.0     0.0      20.0            10.0  \n",
      "60_fp       256           0.01 1.0 1.0   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "10_fp &    256 &    0.01 &    1.0 &    1.0\n",
      "$85.85_{0.93}$\n",
      "85.85485816001892\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                    trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                             \n",
      "10_fp       256           0.01 1.0 1.0 0.1  0.000            149.0  0.865929   \n",
      "                                            0.001            149.0  0.865929   \n",
      "20_fp       256           0.01 1.0 1.0 0.1  0.000            149.0  0.865929   \n",
      "                                            0.001            149.0  0.865929   \n",
      "40_fp       256           0.01 1.0 1.0 0.1  0.000            149.0  0.865929   \n",
      "                                            0.001            149.0  0.865929   \n",
      "60_fp       256           0.01 1.0 1.0 0.1  0.000            149.0  0.865929   \n",
      "                                            0.001            149.0  0.865929   \n",
      "\n",
      "                                                    statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                         \n",
      "10_fp       256           0.01 1.0 1.0 0.1  0.000       1.0          0.0   \n",
      "                                            0.001       1.0          0.0   \n",
      "20_fp       256           0.01 1.0 1.0 0.1  0.000       1.0          0.0   \n",
      "                                            0.001       1.0          0.0   \n",
      "40_fp       256           0.01 1.0 1.0 0.1  0.000       1.0          0.0   \n",
      "                                            0.001       1.0          0.0   \n",
      "60_fp       256           0.01 1.0 1.0 0.1  0.000       1.0          0.0   \n",
      "                                            0.001       1.0          0.0   \n",
      "\n",
      "                                                    ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.01 1.0 1.0 0.1  0.000             1.0   \n",
      "                                            0.001             1.0   \n",
      "20_fp       256           0.01 1.0 1.0 0.1  0.000             1.0   \n",
      "                                            0.001             1.0   \n",
      "40_fp       256           0.01 1.0 1.0 0.1  0.000             1.0   \n",
      "                                            0.001             1.0   \n",
      "60_fp       256           0.01 1.0 1.0 0.1  0.000             1.0   \n",
      "                                            0.001             1.0   \n",
      "\n",
      "                                                    optim_cluster  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.01 1.0 1.0 0.1  0.000             1.0   \n",
      "                                            0.001             1.0   \n",
      "20_fp       256           0.01 1.0 1.0 0.1  0.000             1.0   \n",
      "                                            0.001             1.0   \n",
      "40_fp       256           0.01 1.0 1.0 0.1  0.000             1.0   \n",
      "                                            0.001             1.0   \n",
      "60_fp       256           0.01 1.0 1.0 0.1  0.000             1.0   \n",
      "                                            0.001             1.0   \n",
      "\n",
      "                                                    prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                        \n",
      "10_fp       256           0.01 1.0 1.0 0.1  0.000            0.0   81.0   \n",
      "                                            0.001            0.0   81.0   \n",
      "20_fp       256           0.01 1.0 1.0 0.1  0.000            0.0   81.0   \n",
      "                                            0.001            0.0   81.0   \n",
      "40_fp       256           0.01 1.0 1.0 0.1  0.000            0.0   81.0   \n",
      "                                            0.001            0.0   81.0   \n",
      "60_fp       256           0.01 1.0 1.0 0.1  0.000            0.0   81.0   \n",
      "                                            0.001            0.0   81.0   \n",
      "\n",
      "                                                    walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                            \n",
      "10_fp       256           0.01 1.0 1.0 0.1  0.000       20.0            10.0  \n",
      "                                            0.001       20.0            10.0  \n",
      "20_fp       256           0.01 1.0 1.0 0.1  0.000       20.0            10.0  \n",
      "                                            0.001       20.0            10.0  \n",
      "40_fp       256           0.01 1.0 1.0 0.1  0.000       20.0            10.0  \n",
      "                                            0.001       20.0            10.0  \n",
      "60_fp       256           0.01 1.0 1.0 0.1  0.000       20.0            10.0  \n",
      "                                            0.001       20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    256 &    0.01 &    1.0 &    1.0 &    0.1 &    0.0\n",
      "$86.59_{0.85}$\n",
      "86.59286499023438\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                               \n",
      "10_fp       256           0.01 0.2 0.4          5.0      168.333333  0.849938   \n",
      "20_fp       256           0.01 0.2 0.4          5.0      168.333333  0.849938   \n",
      "40_fp       256           0.01 0.2 0.4          5.0      168.333333  0.849938   \n",
      "60_fp       256           0.01 0.2 0.4          5.0      168.333333  0.849938   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "10_fp       256           0.01 0.2 0.4          5.0      1.0          0.0   \n",
      "20_fp       256           0.01 0.2 0.4          5.0      1.0          0.0   \n",
      "40_fp       256           0.01 0.2 0.4          5.0      1.0          0.0   \n",
      "60_fp       256           0.01 0.2 0.4          5.0      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "10_fp       256           0.01 0.2 0.4          5.0            1.0   \n",
      "20_fp       256           0.01 0.2 0.4          5.0            1.0   \n",
      "40_fp       256           0.01 0.2 0.4          5.0            1.0   \n",
      "60_fp       256           0.01 0.2 0.4          5.0            1.0   \n",
      "\n",
      "                                                     optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "10_fp       256           0.01 0.2 0.4          5.0            1.0   81.0   \n",
      "20_fp       256           0.01 0.2 0.4          5.0            1.0   81.0   \n",
      "40_fp       256           0.01 0.2 0.4          5.0            1.0   81.0   \n",
      "60_fp       256           0.01 0.2 0.4          5.0            1.0   81.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                             \n",
      "10_fp       256           0.01 0.2 0.4          5.0   0.0     0.0      20.0   \n",
      "20_fp       256           0.01 0.2 0.4          5.0   0.0     0.0      20.0   \n",
      "40_fp       256           0.01 0.2 0.4          5.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.01 0.2 0.4          5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "10_fp       256           0.01 0.2 0.4          5.0            10.0  \n",
      "20_fp       256           0.01 0.2 0.4          5.0            10.0  \n",
      "40_fp       256           0.01 0.2 0.4          5.0            10.0  \n",
      "60_fp       256           0.01 0.2 0.4          5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    256 &    0.01 &    0.2 &    0.4 &    5.0\n",
      "$84.99_{2.72}$\n",
      "84.9938452243805\n",
      "\n",
      "\n",
      "Cite 145\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                               \n",
      "40_fp       256           0.1 False         0.2 5.0       25.000000  0.458027   \n",
      "60_fp       256           0.1 False         0.2 5.0       21.666667  0.458027   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                           \n",
      "40_fp       256           0.1 False         0.2 5.0      1.0          0.0   \n",
      "60_fp       256           0.1 False         0.2 5.0      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                    \n",
      "40_fp       256           0.1 False         0.2 5.0            1.0   \n",
      "60_fp       256           0.1 False         0.2 5.0            1.0   \n",
      "\n",
      "                                                     prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                          \n",
      "40_fp       256           0.1 False         0.2 5.0           0.0  145.0   \n",
      "60_fp       256           0.1 False         0.2 5.0           0.0  145.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                             \n",
      "40_fp       256           0.1 False         0.2 5.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.1 False         0.2 5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                    \n",
      "40_fp       256           0.1 False         0.2 5.0            10.0  \n",
      "60_fp       256           0.1 False         0.2 5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q']\n",
      "40_fp &    256 &    0.1 &    False &    0.2 &    5.0\n",
      "$45.80_{2.94}$\n",
      "45.80271542072296\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                                 trained_epochs  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                   \n",
      "40_fp       256           0.1 False         0.2 5.0 0.1  0.000        24.000000   \n",
      "60_fp       256           0.1 False         0.2 0.2 0.1  0.010        13.000000   \n",
      "                                            1.0 1.0 0.1  0.000         8.333333   \n",
      "                                                         0.001         8.000000   \n",
      "                                            5.0 0.2 0.1  0.000        22.333333   \n",
      "\n",
      "                                                                  val_acc  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv             \n",
      "40_fp       256           0.1 False         0.2 5.0 0.1  0.000   0.458918   \n",
      "60_fp       256           0.1 False         0.2 0.2 0.1  0.010   0.458918   \n",
      "                                            1.0 1.0 0.1  0.000   0.458918   \n",
      "                                                         0.001   0.458918   \n",
      "                                            5.0 0.2 0.1  0.000   0.458918   \n",
      "\n",
      "                                                                 statrep  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv            \n",
      "40_fp       256           0.1 False         0.2 5.0 0.1  0.000       1.0   \n",
      "60_fp       256           0.1 False         0.2 0.2 0.1  0.010       1.0   \n",
      "                                            1.0 1.0 0.1  0.000       1.0   \n",
      "                                                         0.001       1.0   \n",
      "                                            5.0 0.2 0.1  0.000       1.0   \n",
      "\n",
      "                                                                 ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                \n",
      "40_fp       256           0.1 False         0.2 5.0 0.1  0.000           0.0   \n",
      "60_fp       256           0.1 False         0.2 0.2 0.1  0.010           0.0   \n",
      "                                            1.0 1.0 0.1  0.000           0.0   \n",
      "                                                         0.001           0.0   \n",
      "                                            5.0 0.2 0.1  0.000           0.0   \n",
      "\n",
      "                                                                 ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                  \n",
      "40_fp       256           0.1 False         0.2 5.0 0.1  0.000             1.0   \n",
      "60_fp       256           0.1 False         0.2 0.2 0.1  0.010             1.0   \n",
      "                                            1.0 1.0 0.1  0.000             1.0   \n",
      "                                                         0.001             1.0   \n",
      "                                            5.0 0.2 0.1  0.000             1.0   \n",
      "\n",
      "                                                                 prob_replace  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                 \n",
      "40_fp       256           0.1 False         0.2 5.0 0.1  0.000            0.0   \n",
      "60_fp       256           0.1 False         0.2 0.2 0.1  0.010            0.0   \n",
      "                                            1.0 1.0 0.1  0.000            0.0   \n",
      "                                                         0.001            0.0   \n",
      "                                            5.0 0.2 0.1  0.000            0.0   \n",
      "\n",
      "                                                                 split  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv          \n",
      "40_fp       256           0.1 False         0.2 5.0 0.1  0.000   145.0   \n",
      "60_fp       256           0.1 False         0.2 0.2 0.1  0.010   145.0   \n",
      "                                            1.0 1.0 0.1  0.000   145.0   \n",
      "                                                         0.001   145.0   \n",
      "                                            5.0 0.2 0.1  0.000   145.0   \n",
      "\n",
      "                                                                 walk_len  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv             \n",
      "40_fp       256           0.1 False         0.2 5.0 0.1  0.000       20.0   \n",
      "60_fp       256           0.1 False         0.2 0.2 0.1  0.010       20.0   \n",
      "                                            1.0 1.0 0.1  0.000       20.0   \n",
      "                                                         0.001       20.0   \n",
      "                                            5.0 0.2 0.1  0.000       20.0   \n",
      "\n",
      "                                                                 walks_per_node  \n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                  \n",
      "40_fp       256           0.1 False         0.2 5.0 0.1  0.000             10.0  \n",
      "60_fp       256           0.1 False         0.2 0.2 0.1  0.010             10.0  \n",
      "                                            1.0 1.0 0.1  0.000             10.0  \n",
      "                                                         0.001             10.0  \n",
      "                                            5.0 0.2 0.1  0.000             10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "60_fp &    256 &    0.1 &    False &    5.0 &    0.2 &    0.1 &    0.0\n",
      "$45.89_{2.84}$\n",
      "45.891785621643066\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "60_fp &    256 &    0.1 &    5.0 &    0.6 &    5.0\n",
      "$47.81_{1.67}$\n",
      "47.80672490596771\n",
      "\n",
      "\n",
      "Cite 24\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                               \n",
      "40_fp       256           0.1 False         0.2 0.2        5.333333  0.523416   \n",
      "                                            5.0 1.0        8.666667  0.523416   \n",
      "60_fp       256           0.1 False         0.2 0.2        5.333333  0.523416   \n",
      "                                            5.0 1.0        8.666667  0.523416   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                           \n",
      "40_fp       256           0.1 False         0.2 0.2      1.0          0.0   \n",
      "                                            5.0 1.0      1.0          0.0   \n",
      "60_fp       256           0.1 False         0.2 0.2      1.0          0.0   \n",
      "                                            5.0 1.0      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                    \n",
      "40_fp       256           0.1 False         0.2 0.2            1.0   \n",
      "                                            5.0 1.0            1.0   \n",
      "60_fp       256           0.1 False         0.2 0.2            1.0   \n",
      "                                            5.0 1.0            1.0   \n",
      "\n",
      "                                                     prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                          \n",
      "40_fp       256           0.1 False         0.2 0.2           0.0   24.0   \n",
      "                                            5.0 1.0           0.0   24.0   \n",
      "60_fp       256           0.1 False         0.2 0.2           0.0   24.0   \n",
      "                                            5.0 1.0           0.0   24.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                             \n",
      "40_fp       256           0.1 False         0.2 0.2   0.0     0.0      20.0   \n",
      "                                            5.0 1.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.1 False         0.2 0.2   0.0     0.0      20.0   \n",
      "                                            5.0 1.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                    \n",
      "40_fp       256           0.1 False         0.2 0.2            10.0  \n",
      "                                            5.0 1.0            10.0  \n",
      "60_fp       256           0.1 False         0.2 0.2            10.0  \n",
      "                                            5.0 1.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q']\n",
      "40_fp &    256 &    0.1 &    False &    5.0 &    1.0\n",
      "$52.34_{0.24}$\n",
      "52.34159827232361\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "60_fp &    256 &    0.1 &    False &    0.2 &    5.0 &    10.0 &    0.1\n",
      "$52.44_{0.64}$\n",
      "52.44176983833313\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                    trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                               \n",
      "20_fp       256           0.1 0.2 0.6          5.0       33.666667  0.527173   \n",
      "40_fp       256           0.1 0.2 0.6          5.0       33.666667  0.527173   \n",
      "\n",
      "                                                    statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                           \n",
      "20_fp       256           0.1 0.2 0.6          5.0      1.0          0.0   \n",
      "40_fp       256           0.1 0.2 0.6          5.0      1.0          0.0   \n",
      "\n",
      "                                                    ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                    \n",
      "20_fp       256           0.1 0.2 0.6          5.0            1.0   \n",
      "40_fp       256           0.1 0.2 0.6          5.0            1.0   \n",
      "\n",
      "                                                    optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                           \n",
      "20_fp       256           0.1 0.2 0.6          5.0            1.0   24.0   \n",
      "40_fp       256           0.1 0.2 0.6          5.0            1.0   24.0   \n",
      "\n",
      "                                                    w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                             \n",
      "20_fp       256           0.1 0.2 0.6          5.0   0.0     0.0      20.0   \n",
      "40_fp       256           0.1 0.2 0.6          5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                    walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   prob_replace q                    \n",
      "20_fp       256           0.1 0.2 0.6          5.0            10.0  \n",
      "40_fp       256           0.1 0.2 0.6          5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "20_fp &    256 &    0.1 &    0.2 &    0.6 &    5.0\n",
      "$52.72_{0.53}$\n",
      "52.71725654602051\n",
      "\n",
      "\n",
      "Cite 43\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q']\n",
      "20_fp &    256 &    0.1 &    False &    1.0 &    0.2\n",
      "$55.08_{2.06}$\n",
      "55.07681965827942\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                                 trained_epochs  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                   \n",
      "40_fp       256           0.1 False         1.0 1.0 1.0  0.001             50.0   \n",
      "60_fp       256           0.1 False         1.0 1.0 1.0  0.001             50.0   \n",
      "\n",
      "                                                                  val_acc  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv             \n",
      "40_fp       256           0.1 False         1.0 1.0 1.0  0.001   0.556446   \n",
      "60_fp       256           0.1 False         1.0 1.0 1.0  0.001   0.556446   \n",
      "\n",
      "                                                                 statrep  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv            \n",
      "40_fp       256           0.1 False         1.0 1.0 1.0  0.001       1.0   \n",
      "60_fp       256           0.1 False         1.0 1.0 1.0  0.001       1.0   \n",
      "\n",
      "                                                                 ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                \n",
      "40_fp       256           0.1 False         1.0 1.0 1.0  0.001           0.0   \n",
      "60_fp       256           0.1 False         1.0 1.0 1.0  0.001           0.0   \n",
      "\n",
      "                                                                 ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                  \n",
      "40_fp       256           0.1 False         1.0 1.0 1.0  0.001             1.0   \n",
      "60_fp       256           0.1 False         1.0 1.0 1.0  0.001             1.0   \n",
      "\n",
      "                                                                 prob_replace  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                 \n",
      "40_fp       256           0.1 False         1.0 1.0 1.0  0.001            0.0   \n",
      "60_fp       256           0.1 False         1.0 1.0 1.0  0.001            0.0   \n",
      "\n",
      "                                                                 split  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv          \n",
      "40_fp       256           0.1 False         1.0 1.0 1.0  0.001    43.0   \n",
      "60_fp       256           0.1 False         1.0 1.0 1.0  0.001    43.0   \n",
      "\n",
      "                                                                 walk_len  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv             \n",
      "40_fp       256           0.1 False         1.0 1.0 1.0  0.001       20.0   \n",
      "60_fp       256           0.1 False         1.0 1.0 1.0  0.001       20.0   \n",
      "\n",
      "                                                                 walks_per_node  \n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                  \n",
      "40_fp       256           0.1 False         1.0 1.0 1.0  0.001             10.0  \n",
      "60_fp       256           0.1 False         1.0 1.0 1.0  0.001             10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "40_fp &    256 &    0.1 &    False &    1.0 &    1.0 &    1.0 &    0.001\n",
      "$55.64_{2.15}$\n",
      "55.644625425338745\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    256 &    0.1 &    1.0 &    0.6 &    1.0\n",
      "$55.21_{2.27}$\n",
      "55.21042346954346\n",
      "\n",
      "\n",
      "Cite 62\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                        trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr   p   q                                        \n",
      "10_fp       256           0.01 1.0 1.0      145.666667  0.581582      1.0   \n",
      "20_fp       256           0.01 1.0 1.0      145.333333  0.581582      1.0   \n",
      "40_fp       256           0.01 1.0 1.0      145.333333  0.581582      1.0   \n",
      "60_fp       256           0.01 1.0 1.0      145.333333  0.581582      1.0   \n",
      "\n",
      "                                        ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q                                 \n",
      "10_fp       256           0.01 1.0 1.0          0.0            1.0   \n",
      "20_fp       256           0.01 1.0 1.0          0.0            1.0   \n",
      "40_fp       256           0.01 1.0 1.0          0.0            1.0   \n",
      "60_fp       256           0.01 1.0 1.0          0.0            1.0   \n",
      "\n",
      "                                        optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q                                         \n",
      "10_fp       256           0.01 1.0 1.0            1.0           0.0   62.0   \n",
      "20_fp       256           0.01 1.0 1.0            1.0           0.0   62.0   \n",
      "40_fp       256           0.01 1.0 1.0            1.0           0.0   62.0   \n",
      "60_fp       256           0.01 1.0 1.0            1.0           0.0   62.0   \n",
      "\n",
      "                                        w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q                                            \n",
      "10_fp       256           0.01 1.0 1.0   0.0     0.0      20.0            10.0  \n",
      "20_fp       256           0.01 1.0 1.0   0.0     0.0      20.0            10.0  \n",
      "40_fp       256           0.01 1.0 1.0   0.0     0.0      20.0            10.0  \n",
      "60_fp       256           0.01 1.0 1.0   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "10_fp &    256 &    0.01 &    1.0 &    1.0\n",
      "$58.16_{0.95}$\n",
      "58.158159255981445\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    256 &    0.01 &    0.2 &    0.2 &    0.1 &    0.0\n",
      "$58.36_{0.69}$\n",
      "58.35835933685303\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    256 &    0.01 &    5.0 &    0.6 &    0.2\n",
      "$57.91_{1.79}$\n",
      "57.90790915489197\n",
      "\n",
      "\n",
      "Cite 81\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                        trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr   p   q                                        \n",
      "10_fp       256           0.01 0.2 1.0           142.0  0.648594      1.0   \n",
      "20_fp       256           0.01 0.2 1.0           142.0  0.648594      1.0   \n",
      "40_fp       256           0.01 0.2 1.0           142.0  0.648594      1.0   \n",
      "60_fp       256           0.01 0.2 1.0           142.0  0.648594      1.0   \n",
      "\n",
      "                                        ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q                                 \n",
      "10_fp       256           0.01 0.2 1.0          0.0            1.0   \n",
      "20_fp       256           0.01 0.2 1.0          0.0            1.0   \n",
      "40_fp       256           0.01 0.2 1.0          0.0            1.0   \n",
      "60_fp       256           0.01 0.2 1.0          0.0            1.0   \n",
      "\n",
      "                                        optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q                                         \n",
      "10_fp       256           0.01 0.2 1.0            1.0           0.0   81.0   \n",
      "20_fp       256           0.01 0.2 1.0            1.0           0.0   81.0   \n",
      "40_fp       256           0.01 0.2 1.0            1.0           0.0   81.0   \n",
      "60_fp       256           0.01 0.2 1.0            1.0           0.0   81.0   \n",
      "\n",
      "                                        w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q                                            \n",
      "10_fp       256           0.01 0.2 1.0   0.0     0.0      20.0            10.0  \n",
      "20_fp       256           0.01 0.2 1.0   0.0     0.0      20.0            10.0  \n",
      "40_fp       256           0.01 0.2 1.0   0.0     0.0      20.0            10.0  \n",
      "60_fp       256           0.01 0.2 1.0   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "10_fp &    256 &    0.01 &    0.2 &    1.0\n",
      "$64.86_{1.36}$\n",
      "64.85943794250488\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                    trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                             \n",
      "10_fp       256           0.01 0.2 1.0 0.0  0.0              142.0  0.648594   \n",
      "20_fp       256           0.01 0.2 1.0 0.0  0.0              142.0  0.648594   \n",
      "40_fp       256           0.01 0.2 1.0 0.0  0.0              142.0  0.648594   \n",
      "60_fp       256           0.01 0.2 1.0 0.0  0.0              142.0  0.648594   \n",
      "\n",
      "                                                    statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                         \n",
      "10_fp       256           0.01 0.2 1.0 0.0  0.0         1.0          0.0   \n",
      "20_fp       256           0.01 0.2 1.0 0.0  0.0         1.0          0.0   \n",
      "40_fp       256           0.01 0.2 1.0 0.0  0.0         1.0          0.0   \n",
      "60_fp       256           0.01 0.2 1.0 0.0  0.0         1.0          0.0   \n",
      "\n",
      "                                                    ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.01 0.2 1.0 0.0  0.0               1.0   \n",
      "20_fp       256           0.01 0.2 1.0 0.0  0.0               1.0   \n",
      "40_fp       256           0.01 0.2 1.0 0.0  0.0               1.0   \n",
      "60_fp       256           0.01 0.2 1.0 0.0  0.0               1.0   \n",
      "\n",
      "                                                    optim_cluster  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.01 0.2 1.0 0.0  0.0               1.0   \n",
      "20_fp       256           0.01 0.2 1.0 0.0  0.0               1.0   \n",
      "40_fp       256           0.01 0.2 1.0 0.0  0.0               1.0   \n",
      "60_fp       256           0.01 0.2 1.0 0.0  0.0               1.0   \n",
      "\n",
      "                                                    prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                        \n",
      "10_fp       256           0.01 0.2 1.0 0.0  0.0              0.0   81.0   \n",
      "20_fp       256           0.01 0.2 1.0 0.0  0.0              0.0   81.0   \n",
      "40_fp       256           0.01 0.2 1.0 0.0  0.0              0.0   81.0   \n",
      "60_fp       256           0.01 0.2 1.0 0.0  0.0              0.0   81.0   \n",
      "\n",
      "                                                    walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                            \n",
      "10_fp       256           0.01 0.2 1.0 0.0  0.0         20.0            10.0  \n",
      "20_fp       256           0.01 0.2 1.0 0.0  0.0         20.0            10.0  \n",
      "40_fp       256           0.01 0.2 1.0 0.0  0.0         20.0            10.0  \n",
      "60_fp       256           0.01 0.2 1.0 0.0  0.0         20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    256 &    0.01 &    0.2 &    1.0 &    0.0 &    0.0\n",
      "$64.86_{1.36}$\n",
      "64.85943794250488\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                               \n",
      "10_fp       256           0.01 1.0 0.4          1.0           127.0  0.639558   \n",
      "20_fp       256           0.01 1.0 0.4          1.0           127.0  0.639558   \n",
      "40_fp       256           0.01 1.0 0.4          1.0           127.0  0.639558   \n",
      "60_fp       256           0.01 1.0 0.4          1.0           127.0  0.639558   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "10_fp       256           0.01 1.0 0.4          1.0      1.0          0.0   \n",
      "20_fp       256           0.01 1.0 0.4          1.0      1.0          0.0   \n",
      "40_fp       256           0.01 1.0 0.4          1.0      1.0          0.0   \n",
      "60_fp       256           0.01 1.0 0.4          1.0      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "10_fp       256           0.01 1.0 0.4          1.0            1.0   \n",
      "20_fp       256           0.01 1.0 0.4          1.0            1.0   \n",
      "40_fp       256           0.01 1.0 0.4          1.0            1.0   \n",
      "60_fp       256           0.01 1.0 0.4          1.0            1.0   \n",
      "\n",
      "                                                     optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "10_fp       256           0.01 1.0 0.4          1.0            1.0   81.0   \n",
      "20_fp       256           0.01 1.0 0.4          1.0            1.0   81.0   \n",
      "40_fp       256           0.01 1.0 0.4          1.0            1.0   81.0   \n",
      "60_fp       256           0.01 1.0 0.4          1.0            1.0   81.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                             \n",
      "10_fp       256           0.01 1.0 0.4          1.0   0.0     0.0      20.0   \n",
      "20_fp       256           0.01 1.0 0.4          1.0   0.0     0.0      20.0   \n",
      "40_fp       256           0.01 1.0 0.4          1.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.01 1.0 0.4          1.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "10_fp       256           0.01 1.0 0.4          1.0            10.0  \n",
      "20_fp       256           0.01 1.0 0.4          1.0            10.0  \n",
      "40_fp       256           0.01 1.0 0.4          1.0            10.0  \n",
      "60_fp       256           0.01 1.0 0.4          1.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    256 &    0.01 &    1.0 &    0.4 &    1.0\n",
      "$63.96_{1.06}$\n",
      "63.95582556724548\n",
      "\n",
      "\n",
      "PM 145\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q']\n",
      "60_fp &    256 &    0.1 &    False &    0.2 &    0.2\n",
      "$60.93_{1.19}$\n",
      "60.933274030685425\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "60_fp &    256 &    0.1 &    False &    5.0 &    5.0 &    10.0 &    0.01\n",
      "$61.64_{0.96}$\n",
      "61.64336800575256\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "60_fp &    256 &    0.01 &    0.2 &    0.6 &    1.0\n",
      "$61.35_{0.50}$\n",
      "61.34655475616455\n",
      "\n",
      "\n",
      "PM 24\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "60_fp &    256 &    0.001 &    1.0 &    1.0\n",
      "$62.72_{1.46}$\n",
      "62.71501183509827\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "20_fp &    256 &    0.001 &    1.0 &    1.0 &    10.0 &    0.001\n",
      "$63.36_{2.07}$\n",
      "63.361650705337524\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "60_fp &    256 &    0.001 &    1.0 &    0.2 &    1.0\n",
      "$62.48_{1.24}$\n",
      "62.4825656414032\n",
      "\n",
      "\n",
      "PM 43\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                         trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr    p   q                                        \n",
      "40_fp       256           0.001 5.0 0.2      286.666667  0.687856      1.0   \n",
      "60_fp       256           0.001 5.0 0.2      286.666667  0.687856      1.0   \n",
      "\n",
      "                                         ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   q                                 \n",
      "40_fp       256           0.001 5.0 0.2          0.0            1.0   \n",
      "60_fp       256           0.001 5.0 0.2          0.0            1.0   \n",
      "\n",
      "                                         optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr    p   q                                         \n",
      "40_fp       256           0.001 5.0 0.2            1.0           0.0   43.0   \n",
      "60_fp       256           0.001 5.0 0.2            1.0           0.0   43.0   \n",
      "\n",
      "                                         w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr    p   q                             \n",
      "40_fp       256           0.001 5.0 0.2   0.0     0.0      20.0   \n",
      "60_fp       256           0.001 5.0 0.2   0.0     0.0      20.0   \n",
      "\n",
      "                                         walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   q                    \n",
      "40_fp       256           0.001 5.0 0.2            10.0  \n",
      "60_fp       256           0.001 5.0 0.2            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "40_fp &    256 &    0.001 &    5.0 &    0.2\n",
      "$68.79_{0.75}$\n",
      "68.78557205200195\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "60_fp &    256 &    0.001 &    0.2 &    0.2 &    10.0 &    0.001\n",
      "$69.41_{1.07}$\n",
      "69.41110491752625\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                      trained_epochs  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                     \n",
      "20_fp       256           0.001 0.2 0.2          0.2           312.0   \n",
      "40_fp       256           0.001 0.2 0.2          0.2           312.0   \n",
      "60_fp       256           0.001 0.2 0.2          0.2           312.0   \n",
      "\n",
      "                                                       val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                        \n",
      "20_fp       256           0.001 0.2 0.2          0.2  0.683855      1.0   \n",
      "40_fp       256           0.001 0.2 0.2          0.2  0.683855      1.0   \n",
      "60_fp       256           0.001 0.2 0.2          0.2  0.683855      1.0   \n",
      "\n",
      "                                                      ds_add_self  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                  \n",
      "20_fp       256           0.001 0.2 0.2          0.2          0.0   \n",
      "40_fp       256           0.001 0.2 0.2          0.2          0.0   \n",
      "60_fp       256           0.001 0.2 0.2          0.2          0.0   \n",
      "\n",
      "                                                      ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                    \n",
      "20_fp       256           0.001 0.2 0.2          0.2            1.0   \n",
      "40_fp       256           0.001 0.2 0.2          0.2            1.0   \n",
      "60_fp       256           0.001 0.2 0.2          0.2            1.0   \n",
      "\n",
      "                                                      optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                           \n",
      "20_fp       256           0.001 0.2 0.2          0.2            1.0   43.0   \n",
      "40_fp       256           0.001 0.2 0.2          0.2            1.0   43.0   \n",
      "60_fp       256           0.001 0.2 0.2          0.2            1.0   43.0   \n",
      "\n",
      "                                                      w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                             \n",
      "20_fp       256           0.001 0.2 0.2          0.2   0.0     0.0      20.0   \n",
      "40_fp       256           0.001 0.2 0.2          0.2   0.0     0.0      20.0   \n",
      "60_fp       256           0.001 0.2 0.2          0.2   0.0     0.0      20.0   \n",
      "\n",
      "                                                      walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   prob_replace q                    \n",
      "20_fp       256           0.001 0.2 0.2          0.2            10.0  \n",
      "40_fp       256           0.001 0.2 0.2          0.2            10.0  \n",
      "60_fp       256           0.001 0.2 0.2          0.2            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "20_fp &    256 &    0.001 &    0.2 &    0.2 &    0.2\n",
      "$68.39_{0.79}$\n",
      "68.38545799255371\n",
      "\n",
      "\n",
      "PM 62\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                         trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr    p   q                                        \n",
      "20_fp       256           0.001 5.0 1.0      296.333333  0.736308      1.0   \n",
      "40_fp       256           0.001 5.0 1.0      296.333333  0.736308      1.0   \n",
      "60_fp       256           0.001 5.0 1.0      296.333333  0.736308      1.0   \n",
      "\n",
      "                                         ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   q                                 \n",
      "20_fp       256           0.001 5.0 1.0          0.0            1.0   \n",
      "40_fp       256           0.001 5.0 1.0          0.0            1.0   \n",
      "60_fp       256           0.001 5.0 1.0          0.0            1.0   \n",
      "\n",
      "                                         optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr    p   q                                         \n",
      "20_fp       256           0.001 5.0 1.0            1.0           0.0   62.0   \n",
      "40_fp       256           0.001 5.0 1.0            1.0           0.0   62.0   \n",
      "60_fp       256           0.001 5.0 1.0            1.0           0.0   62.0   \n",
      "\n",
      "                                         w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr    p   q                             \n",
      "20_fp       256           0.001 5.0 1.0   0.0     0.0      20.0   \n",
      "40_fp       256           0.001 5.0 1.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.001 5.0 1.0   0.0     0.0      20.0   \n",
      "\n",
      "                                         walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   q                    \n",
      "20_fp       256           0.001 5.0 1.0            10.0  \n",
      "40_fp       256           0.001 5.0 1.0            10.0  \n",
      "60_fp       256           0.001 5.0 1.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "20_fp &    256 &    0.001 &    5.0 &    1.0\n",
      "$73.63_{0.41}$\n",
      "73.63083362579346\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs  val_acc  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                            \n",
      "20_fp       256           0.001 5.0 0.2 10.0 0.001       398.666667  0.74307   \n",
      "40_fp       256           0.001 5.0 0.2 10.0 0.001       398.666667  0.74307   \n",
      "60_fp       256           0.001 5.0 0.2 10.0 0.001       398.666667  0.74307   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                         \n",
      "20_fp       256           0.001 5.0 0.2 10.0 0.001       1.0          0.0   \n",
      "40_fp       256           0.001 5.0 0.2 10.0 0.001       1.0          0.0   \n",
      "60_fp       256           0.001 5.0 0.2 10.0 0.001       1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                  \n",
      "20_fp       256           0.001 5.0 0.2 10.0 0.001             1.0   \n",
      "40_fp       256           0.001 5.0 0.2 10.0 0.001             1.0   \n",
      "60_fp       256           0.001 5.0 0.2 10.0 0.001             1.0   \n",
      "\n",
      "                                                     optim_cluster  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                  \n",
      "20_fp       256           0.001 5.0 0.2 10.0 0.001             1.0   \n",
      "40_fp       256           0.001 5.0 0.2 10.0 0.001             1.0   \n",
      "60_fp       256           0.001 5.0 0.2 10.0 0.001             1.0   \n",
      "\n",
      "                                                     prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                        \n",
      "20_fp       256           0.001 5.0 0.2 10.0 0.001            0.0   62.0   \n",
      "40_fp       256           0.001 5.0 0.2 10.0 0.001            0.0   62.0   \n",
      "60_fp       256           0.001 5.0 0.2 10.0 0.001            0.0   62.0   \n",
      "\n",
      "                                                     walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   q   w_ms w_ndiv                            \n",
      "20_fp       256           0.001 5.0 0.2 10.0 0.001       20.0            10.0  \n",
      "40_fp       256           0.001 5.0 0.2 10.0 0.001       20.0            10.0  \n",
      "60_fp       256           0.001 5.0 0.2 10.0 0.001       20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "20_fp &    256 &    0.001 &    5.0 &    0.2 &    10.0 &    0.001\n",
      "$74.31_{0.45}$\n",
      "74.30696487426758\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                      trained_epochs  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                     \n",
      "20_fp       256           0.001 1.0 0.2          0.2      228.333333   \n",
      "40_fp       256           0.001 1.0 0.2          0.2      228.333333   \n",
      "60_fp       256           0.001 1.0 0.2          0.2      228.333333   \n",
      "\n",
      "                                                       val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                        \n",
      "20_fp       256           0.001 1.0 0.2          0.2  0.724899      1.0   \n",
      "40_fp       256           0.001 1.0 0.2          0.2  0.724899      1.0   \n",
      "60_fp       256           0.001 1.0 0.2          0.2  0.724899      1.0   \n",
      "\n",
      "                                                      ds_add_self  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                  \n",
      "20_fp       256           0.001 1.0 0.2          0.2          0.0   \n",
      "40_fp       256           0.001 1.0 0.2          0.2          0.0   \n",
      "60_fp       256           0.001 1.0 0.2          0.2          0.0   \n",
      "\n",
      "                                                      ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                    \n",
      "20_fp       256           0.001 1.0 0.2          0.2            1.0   \n",
      "40_fp       256           0.001 1.0 0.2          0.2            1.0   \n",
      "60_fp       256           0.001 1.0 0.2          0.2            1.0   \n",
      "\n",
      "                                                      optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                           \n",
      "20_fp       256           0.001 1.0 0.2          0.2            1.0   62.0   \n",
      "40_fp       256           0.001 1.0 0.2          0.2            1.0   62.0   \n",
      "60_fp       256           0.001 1.0 0.2          0.2            1.0   62.0   \n",
      "\n",
      "                                                      w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                             \n",
      "20_fp       256           0.001 1.0 0.2          0.2   0.0     0.0      20.0   \n",
      "40_fp       256           0.001 1.0 0.2          0.2   0.0     0.0      20.0   \n",
      "60_fp       256           0.001 1.0 0.2          0.2   0.0     0.0      20.0   \n",
      "\n",
      "                                                      walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   prob_replace q                    \n",
      "20_fp       256           0.001 1.0 0.2          0.2            10.0  \n",
      "40_fp       256           0.001 1.0 0.2          0.2            10.0  \n",
      "60_fp       256           0.001 1.0 0.2          0.2            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "20_fp &    256 &    0.001 &    1.0 &    0.2 &    0.2\n",
      "$72.49_{0.95}$\n",
      "72.48985767364502\n",
      "\n",
      "\n",
      "PM 81\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                         trained_epochs  val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr    p   q                                       \n",
      "10_fp       256           0.001 0.2 0.2      279.666667  0.76966      1.0   \n",
      "20_fp       256           0.001 0.2 0.2      279.666667  0.76966      1.0   \n",
      "40_fp       256           0.001 0.2 0.2      279.666667  0.76966      1.0   \n",
      "60_fp       256           0.001 0.2 0.2      279.666667  0.76966      1.0   \n",
      "\n",
      "                                         ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   q                                 \n",
      "10_fp       256           0.001 0.2 0.2          0.0            1.0   \n",
      "20_fp       256           0.001 0.2 0.2          0.0            1.0   \n",
      "40_fp       256           0.001 0.2 0.2          0.0            1.0   \n",
      "60_fp       256           0.001 0.2 0.2          0.0            1.0   \n",
      "\n",
      "                                         optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr    p   q                                         \n",
      "10_fp       256           0.001 0.2 0.2            1.0           0.0   81.0   \n",
      "20_fp       256           0.001 0.2 0.2            1.0           0.0   81.0   \n",
      "40_fp       256           0.001 0.2 0.2            1.0           0.0   81.0   \n",
      "60_fp       256           0.001 0.2 0.2            1.0           0.0   81.0   \n",
      "\n",
      "                                         w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr    p   q                             \n",
      "10_fp       256           0.001 0.2 0.2   0.0     0.0      20.0   \n",
      "20_fp       256           0.001 0.2 0.2   0.0     0.0      20.0   \n",
      "40_fp       256           0.001 0.2 0.2   0.0     0.0      20.0   \n",
      "60_fp       256           0.001 0.2 0.2   0.0     0.0      20.0   \n",
      "\n",
      "                                         walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   q                    \n",
      "10_fp       256           0.001 0.2 0.2            10.0  \n",
      "20_fp       256           0.001 0.2 0.2            10.0  \n",
      "40_fp       256           0.001 0.2 0.2            10.0  \n",
      "60_fp       256           0.001 0.2 0.2            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "10_fp &    256 &    0.001 &    0.2 &    0.2\n",
      "$76.97_{1.22}$\n",
      "76.96600556373596\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                    trained_epochs  val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                            \n",
      "10_fp       256           0.01 1.0 1.0 10.0 0.0         135.666667  0.77152   \n",
      "                               5.0 5.0 10.0 0.0         118.333333  0.77152   \n",
      "20_fp       256           0.01 1.0 1.0 10.0 0.0         135.666667  0.77152   \n",
      "                               5.0 5.0 10.0 0.0         118.333333  0.77152   \n",
      "40_fp       256           0.01 1.0 1.0 10.0 0.0         135.666667  0.77152   \n",
      "                               5.0 5.0 10.0 0.0         118.333333  0.77152   \n",
      "60_fp       256           0.01 1.0 1.0 10.0 0.0         135.666667  0.77152   \n",
      "                               5.0 5.0 10.0 0.0         118.333333  0.77152   \n",
      "\n",
      "                                                    statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                         \n",
      "10_fp       256           0.01 1.0 1.0 10.0 0.0         1.0          0.0   \n",
      "                               5.0 5.0 10.0 0.0         1.0          0.0   \n",
      "20_fp       256           0.01 1.0 1.0 10.0 0.0         1.0          0.0   \n",
      "                               5.0 5.0 10.0 0.0         1.0          0.0   \n",
      "40_fp       256           0.01 1.0 1.0 10.0 0.0         1.0          0.0   \n",
      "                               5.0 5.0 10.0 0.0         1.0          0.0   \n",
      "60_fp       256           0.01 1.0 1.0 10.0 0.0         1.0          0.0   \n",
      "                               5.0 5.0 10.0 0.0         1.0          0.0   \n",
      "\n",
      "                                                    ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.01 1.0 1.0 10.0 0.0               1.0   \n",
      "                               5.0 5.0 10.0 0.0               1.0   \n",
      "20_fp       256           0.01 1.0 1.0 10.0 0.0               1.0   \n",
      "                               5.0 5.0 10.0 0.0               1.0   \n",
      "40_fp       256           0.01 1.0 1.0 10.0 0.0               1.0   \n",
      "                               5.0 5.0 10.0 0.0               1.0   \n",
      "60_fp       256           0.01 1.0 1.0 10.0 0.0               1.0   \n",
      "                               5.0 5.0 10.0 0.0               1.0   \n",
      "\n",
      "                                                    optim_cluster  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.01 1.0 1.0 10.0 0.0               1.0   \n",
      "                               5.0 5.0 10.0 0.0               1.0   \n",
      "20_fp       256           0.01 1.0 1.0 10.0 0.0               1.0   \n",
      "                               5.0 5.0 10.0 0.0               1.0   \n",
      "40_fp       256           0.01 1.0 1.0 10.0 0.0               1.0   \n",
      "                               5.0 5.0 10.0 0.0               1.0   \n",
      "60_fp       256           0.01 1.0 1.0 10.0 0.0               1.0   \n",
      "                               5.0 5.0 10.0 0.0               1.0   \n",
      "\n",
      "                                                    prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                        \n",
      "10_fp       256           0.01 1.0 1.0 10.0 0.0              0.0   81.0   \n",
      "                               5.0 5.0 10.0 0.0              0.0   81.0   \n",
      "20_fp       256           0.01 1.0 1.0 10.0 0.0              0.0   81.0   \n",
      "                               5.0 5.0 10.0 0.0              0.0   81.0   \n",
      "40_fp       256           0.01 1.0 1.0 10.0 0.0              0.0   81.0   \n",
      "                               5.0 5.0 10.0 0.0              0.0   81.0   \n",
      "60_fp       256           0.01 1.0 1.0 10.0 0.0              0.0   81.0   \n",
      "                               5.0 5.0 10.0 0.0              0.0   81.0   \n",
      "\n",
      "                                                    walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                            \n",
      "10_fp       256           0.01 1.0 1.0 10.0 0.0         20.0            10.0  \n",
      "                               5.0 5.0 10.0 0.0         20.0            10.0  \n",
      "20_fp       256           0.01 1.0 1.0 10.0 0.0         20.0            10.0  \n",
      "                               5.0 5.0 10.0 0.0         20.0            10.0  \n",
      "40_fp       256           0.01 1.0 1.0 10.0 0.0         20.0            10.0  \n",
      "                               5.0 5.0 10.0 0.0         20.0            10.0  \n",
      "60_fp       256           0.01 1.0 1.0 10.0 0.0         20.0            10.0  \n",
      "                               5.0 5.0 10.0 0.0         20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    256 &    0.01 &    5.0 &    5.0 &    10.0 &    0.0\n",
      "$77.15_{1.13}$\n",
      "77.15203762054443\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                               \n",
      "10_fp       256           0.01 5.0 0.2          1.0       44.666667  0.755792   \n",
      "20_fp       256           0.01 5.0 0.2          1.0       44.666667  0.755792   \n",
      "40_fp       256           0.01 5.0 0.2          1.0       44.666667  0.755792   \n",
      "60_fp       256           0.01 5.0 0.2          1.0       44.666667  0.755792   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "10_fp       256           0.01 5.0 0.2          1.0      1.0          0.0   \n",
      "20_fp       256           0.01 5.0 0.2          1.0      1.0          0.0   \n",
      "40_fp       256           0.01 5.0 0.2          1.0      1.0          0.0   \n",
      "60_fp       256           0.01 5.0 0.2          1.0      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "10_fp       256           0.01 5.0 0.2          1.0            1.0   \n",
      "20_fp       256           0.01 5.0 0.2          1.0            1.0   \n",
      "40_fp       256           0.01 5.0 0.2          1.0            1.0   \n",
      "60_fp       256           0.01 5.0 0.2          1.0            1.0   \n",
      "\n",
      "                                                     optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "10_fp       256           0.01 5.0 0.2          1.0            1.0   81.0   \n",
      "20_fp       256           0.01 5.0 0.2          1.0            1.0   81.0   \n",
      "40_fp       256           0.01 5.0 0.2          1.0            1.0   81.0   \n",
      "60_fp       256           0.01 5.0 0.2          1.0            1.0   81.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                             \n",
      "10_fp       256           0.01 5.0 0.2          1.0   0.0     0.0      20.0   \n",
      "20_fp       256           0.01 5.0 0.2          1.0   0.0     0.0      20.0   \n",
      "40_fp       256           0.01 5.0 0.2          1.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.01 5.0 0.2          1.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "10_fp       256           0.01 5.0 0.2          1.0            10.0  \n",
      "20_fp       256           0.01 5.0 0.2          1.0            10.0  \n",
      "40_fp       256           0.01 5.0 0.2          1.0            10.0  \n",
      "60_fp       256           0.01 5.0 0.2          1.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    256 &    0.01 &    5.0 &    0.2 &    1.0\n",
      "$75.58_{1.35}$\n",
      "75.57923197746277\n",
      "\n",
      "\n",
      "Pho 145\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                       trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr  p   q                                        \n",
      "40_fp       256           0.1 0.2 1.0       68.666667  0.831833      1.0   \n",
      "60_fp       256           0.1 0.2 1.0       68.666667  0.831833      1.0   \n",
      "\n",
      "                                       ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q                                 \n",
      "40_fp       256           0.1 0.2 1.0          0.0            1.0   \n",
      "60_fp       256           0.1 0.2 1.0          0.0            1.0   \n",
      "\n",
      "                                       optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q                                         \n",
      "40_fp       256           0.1 0.2 1.0            1.0           0.0  145.0   \n",
      "60_fp       256           0.1 0.2 1.0            1.0           0.0  145.0   \n",
      "\n",
      "                                       w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q                                            \n",
      "40_fp       256           0.1 0.2 1.0   0.0     0.0      20.0            10.0  \n",
      "60_fp       256           0.1 0.2 1.0   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "40_fp &    256 &    0.1 &    0.2 &    1.0\n",
      "$83.18_{1.27}$\n",
      "83.18327069282532\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "60_fp &    256 &    0.1 &    0.2 &    5.0 &    0.1 &    0.0\n",
      "$84.59_{0.69}$\n",
      "84.58707928657532\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "60_fp &    256 &    0.1 &    1.0 &    0.2 &    5.0\n",
      "$82.77_{0.66}$\n",
      "82.76696801185608\n",
      "\n",
      "\n",
      "Pho 24\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                       trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr  p   q                                        \n",
      "40_fp       256           0.1 0.2 5.0        7.333333  0.864161      1.0   \n",
      "60_fp       256           0.1 0.2 5.0        7.333333  0.864161      1.0   \n",
      "\n",
      "                                       ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q                                 \n",
      "40_fp       256           0.1 0.2 5.0          0.0            1.0   \n",
      "60_fp       256           0.1 0.2 5.0          0.0            1.0   \n",
      "\n",
      "                                       optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q                                         \n",
      "40_fp       256           0.1 0.2 5.0            1.0           0.0   24.0   \n",
      "60_fp       256           0.1 0.2 5.0            1.0           0.0   24.0   \n",
      "\n",
      "                                       w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q                                            \n",
      "40_fp       256           0.1 0.2 5.0   0.0     0.0      20.0            10.0  \n",
      "60_fp       256           0.1 0.2 5.0   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "40_fp &    256 &    0.1 &    0.2 &    5.0\n",
      "$86.42_{0.19}$\n",
      "86.41612529754639\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                   trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                             \n",
      "20_fp       256           0.1 1.0 5.0 10.0 0.001             48.0  0.875926   \n",
      "40_fp       256           0.1 1.0 5.0 10.0 0.001             48.0  0.875926   \n",
      "60_fp       256           0.1 1.0 5.0 10.0 0.001             48.0  0.875926   \n",
      "\n",
      "                                                   statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                         \n",
      "20_fp       256           0.1 1.0 5.0 10.0 0.001       1.0          0.0   \n",
      "40_fp       256           0.1 1.0 5.0 10.0 0.001       1.0          0.0   \n",
      "60_fp       256           0.1 1.0 5.0 10.0 0.001       1.0          0.0   \n",
      "\n",
      "                                                   ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "20_fp       256           0.1 1.0 5.0 10.0 0.001             1.0   \n",
      "40_fp       256           0.1 1.0 5.0 10.0 0.001             1.0   \n",
      "60_fp       256           0.1 1.0 5.0 10.0 0.001             1.0   \n",
      "\n",
      "                                                   optim_cluster  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "20_fp       256           0.1 1.0 5.0 10.0 0.001             1.0   \n",
      "40_fp       256           0.1 1.0 5.0 10.0 0.001             1.0   \n",
      "60_fp       256           0.1 1.0 5.0 10.0 0.001             1.0   \n",
      "\n",
      "                                                   prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                        \n",
      "20_fp       256           0.1 1.0 5.0 10.0 0.001            0.0   24.0   \n",
      "40_fp       256           0.1 1.0 5.0 10.0 0.001            0.0   24.0   \n",
      "60_fp       256           0.1 1.0 5.0 10.0 0.001            0.0   24.0   \n",
      "\n",
      "                                                   walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                            \n",
      "20_fp       256           0.1 1.0 5.0 10.0 0.001       20.0            10.0  \n",
      "40_fp       256           0.1 1.0 5.0 10.0 0.001       20.0            10.0  \n",
      "60_fp       256           0.1 1.0 5.0 10.0 0.001       20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "20_fp &    256 &    0.1 &    1.0 &    5.0 &    10.0 &    0.001\n",
      "$87.59_{0.43}$\n",
      "87.59259581565857\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                               \n",
      "20_fp       256           0.01 1.0 0.2          0.2       54.666667  0.861656   \n",
      "40_fp       256           0.01 1.0 0.2          0.2       54.666667  0.861656   \n",
      "60_fp       256           0.01 1.0 0.2          0.2       54.666667  0.861656   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "20_fp       256           0.01 1.0 0.2          0.2      1.0          0.0   \n",
      "40_fp       256           0.01 1.0 0.2          0.2      1.0          0.0   \n",
      "60_fp       256           0.01 1.0 0.2          0.2      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "20_fp       256           0.01 1.0 0.2          0.2            1.0   \n",
      "40_fp       256           0.01 1.0 0.2          0.2            1.0   \n",
      "60_fp       256           0.01 1.0 0.2          0.2            1.0   \n",
      "\n",
      "                                                     optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "20_fp       256           0.01 1.0 0.2          0.2            1.0   24.0   \n",
      "40_fp       256           0.01 1.0 0.2          0.2            1.0   24.0   \n",
      "60_fp       256           0.01 1.0 0.2          0.2            1.0   24.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                             \n",
      "20_fp       256           0.01 1.0 0.2          0.2   0.0     0.0      20.0   \n",
      "40_fp       256           0.01 1.0 0.2          0.2   0.0     0.0      20.0   \n",
      "60_fp       256           0.01 1.0 0.2          0.2   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "20_fp       256           0.01 1.0 0.2          0.2            10.0  \n",
      "40_fp       256           0.01 1.0 0.2          0.2            10.0  \n",
      "60_fp       256           0.01 1.0 0.2          0.2            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "20_fp &    256 &    0.01 &    1.0 &    0.2 &    0.2\n",
      "$86.17_{0.80}$\n",
      "86.16557717323303\n",
      "\n",
      "\n",
      "Pho 43\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                        trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr   p   q                                        \n",
      "20_fp       256           0.01 0.2 5.0      109.333333  0.893827      1.0   \n",
      "40_fp       256           0.01 0.2 5.0      109.333333  0.893827      1.0   \n",
      "60_fp       256           0.01 0.2 5.0      109.333333  0.893827      1.0   \n",
      "\n",
      "                                        ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q                                 \n",
      "20_fp       256           0.01 0.2 5.0          0.0            1.0   \n",
      "40_fp       256           0.01 0.2 5.0          0.0            1.0   \n",
      "60_fp       256           0.01 0.2 5.0          0.0            1.0   \n",
      "\n",
      "                                        optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q                                         \n",
      "20_fp       256           0.01 0.2 5.0            1.0           0.0   43.0   \n",
      "40_fp       256           0.01 0.2 5.0            1.0           0.0   43.0   \n",
      "60_fp       256           0.01 0.2 5.0            1.0           0.0   43.0   \n",
      "\n",
      "                                        w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q                                            \n",
      "20_fp       256           0.01 0.2 5.0   0.0     0.0      20.0            10.0  \n",
      "40_fp       256           0.01 0.2 5.0   0.0     0.0      20.0            10.0  \n",
      "60_fp       256           0.01 0.2 5.0   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "20_fp &    256 &    0.01 &    0.2 &    5.0\n",
      "$89.38_{0.65}$\n",
      "89.38271999359131\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                   trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                             \n",
      "10_fp       256           0.1 1.0 0.2 10.0 0.1          12.666667  0.898911   \n",
      "20_fp       256           0.1 1.0 0.2 10.0 0.1          12.666667  0.898911   \n",
      "                              5.0 5.0 10.0 0.0          14.000000  0.898911   \n",
      "40_fp       256           0.1 1.0 0.2 10.0 0.1          12.666667  0.898911   \n",
      "                              5.0 5.0 10.0 0.0          14.000000  0.898911   \n",
      "60_fp       256           0.1 1.0 0.2 10.0 0.1          12.666667  0.898911   \n",
      "                              5.0 5.0 10.0 0.0          14.000000  0.898911   \n",
      "\n",
      "                                                   statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                         \n",
      "10_fp       256           0.1 1.0 0.2 10.0 0.1         1.0          0.0   \n",
      "20_fp       256           0.1 1.0 0.2 10.0 0.1         1.0          0.0   \n",
      "                              5.0 5.0 10.0 0.0         1.0          0.0   \n",
      "40_fp       256           0.1 1.0 0.2 10.0 0.1         1.0          0.0   \n",
      "                              5.0 5.0 10.0 0.0         1.0          0.0   \n",
      "60_fp       256           0.1 1.0 0.2 10.0 0.1         1.0          0.0   \n",
      "                              5.0 5.0 10.0 0.0         1.0          0.0   \n",
      "\n",
      "                                                   ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.1 1.0 0.2 10.0 0.1               1.0   \n",
      "20_fp       256           0.1 1.0 0.2 10.0 0.1               1.0   \n",
      "                              5.0 5.0 10.0 0.0               1.0   \n",
      "40_fp       256           0.1 1.0 0.2 10.0 0.1               1.0   \n",
      "                              5.0 5.0 10.0 0.0               1.0   \n",
      "60_fp       256           0.1 1.0 0.2 10.0 0.1               1.0   \n",
      "                              5.0 5.0 10.0 0.0               1.0   \n",
      "\n",
      "                                                   optim_cluster  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.1 1.0 0.2 10.0 0.1               1.0   \n",
      "20_fp       256           0.1 1.0 0.2 10.0 0.1               1.0   \n",
      "                              5.0 5.0 10.0 0.0               1.0   \n",
      "40_fp       256           0.1 1.0 0.2 10.0 0.1               1.0   \n",
      "                              5.0 5.0 10.0 0.0               1.0   \n",
      "60_fp       256           0.1 1.0 0.2 10.0 0.1               1.0   \n",
      "                              5.0 5.0 10.0 0.0               1.0   \n",
      "\n",
      "                                                   prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                        \n",
      "10_fp       256           0.1 1.0 0.2 10.0 0.1              0.0   43.0   \n",
      "20_fp       256           0.1 1.0 0.2 10.0 0.1              0.0   43.0   \n",
      "                              5.0 5.0 10.0 0.0              0.0   43.0   \n",
      "40_fp       256           0.1 1.0 0.2 10.0 0.1              0.0   43.0   \n",
      "                              5.0 5.0 10.0 0.0              0.0   43.0   \n",
      "60_fp       256           0.1 1.0 0.2 10.0 0.1              0.0   43.0   \n",
      "                              5.0 5.0 10.0 0.0              0.0   43.0   \n",
      "\n",
      "                                                   walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                            \n",
      "10_fp       256           0.1 1.0 0.2 10.0 0.1         20.0            10.0  \n",
      "20_fp       256           0.1 1.0 0.2 10.0 0.1         20.0            10.0  \n",
      "                              5.0 5.0 10.0 0.0         20.0            10.0  \n",
      "40_fp       256           0.1 1.0 0.2 10.0 0.1         20.0            10.0  \n",
      "                              5.0 5.0 10.0 0.0         20.0            10.0  \n",
      "60_fp       256           0.1 1.0 0.2 10.0 0.1         20.0            10.0  \n",
      "                              5.0 5.0 10.0 0.0         20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    256 &    0.1 &    1.0 &    0.2 &    10.0 &    0.1\n",
      "$89.89_{0.42}$\n",
      "89.89107012748718\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                               \n",
      "40_fp       256           0.01 5.0 0.2          1.0      127.666667  0.893827   \n",
      "60_fp       256           0.01 5.0 0.2          1.0      127.666667  0.893827   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "40_fp       256           0.01 5.0 0.2          1.0      1.0          0.0   \n",
      "60_fp       256           0.01 5.0 0.2          1.0      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "40_fp       256           0.01 5.0 0.2          1.0            1.0   \n",
      "60_fp       256           0.01 5.0 0.2          1.0            1.0   \n",
      "\n",
      "                                                     optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "40_fp       256           0.01 5.0 0.2          1.0            1.0   43.0   \n",
      "60_fp       256           0.01 5.0 0.2          1.0            1.0   43.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                             \n",
      "40_fp       256           0.01 5.0 0.2          1.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.01 5.0 0.2          1.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "40_fp       256           0.01 5.0 0.2          1.0            10.0  \n",
      "60_fp       256           0.01 5.0 0.2          1.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "40_fp &    256 &    0.01 &    5.0 &    0.2 &    1.0\n",
      "$89.38_{0.70}$\n",
      "89.38271999359131\n",
      "\n",
      "\n",
      "Pho 62\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                        trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr   p   q                                        \n",
      "20_fp       256           0.01 5.0 5.0            81.0  0.909368      1.0   \n",
      "40_fp       256           0.01 5.0 5.0            81.0  0.909368      1.0   \n",
      "60_fp       256           0.01 5.0 5.0            81.0  0.909368      1.0   \n",
      "\n",
      "                                        ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q                                 \n",
      "20_fp       256           0.01 5.0 5.0          0.0            1.0   \n",
      "40_fp       256           0.01 5.0 5.0          0.0            1.0   \n",
      "60_fp       256           0.01 5.0 5.0          0.0            1.0   \n",
      "\n",
      "                                        optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q                                         \n",
      "20_fp       256           0.01 5.0 5.0            1.0           0.0   62.0   \n",
      "40_fp       256           0.01 5.0 5.0            1.0           0.0   62.0   \n",
      "60_fp       256           0.01 5.0 5.0            1.0           0.0   62.0   \n",
      "\n",
      "                                        w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q                                            \n",
      "20_fp       256           0.01 5.0 5.0   0.0     0.0      20.0            10.0  \n",
      "40_fp       256           0.01 5.0 5.0   0.0     0.0      20.0            10.0  \n",
      "60_fp       256           0.01 5.0 5.0   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "20_fp &    256 &    0.01 &    5.0 &    5.0\n",
      "$90.94_{0.67}$\n",
      "90.93682169914246\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                    trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                             \n",
      "10_fp       256           0.01 5.0 0.2 10.0 0.001            178.0  0.914161   \n",
      "20_fp       256           0.01 5.0 0.2 10.0 0.001            178.0  0.914161   \n",
      "40_fp       256           0.01 5.0 0.2 10.0 0.001            178.0  0.914161   \n",
      "60_fp       256           0.01 5.0 0.2 10.0 0.001            178.0  0.914161   \n",
      "\n",
      "                                                    statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                         \n",
      "10_fp       256           0.01 5.0 0.2 10.0 0.001       1.0          0.0   \n",
      "20_fp       256           0.01 5.0 0.2 10.0 0.001       1.0          0.0   \n",
      "40_fp       256           0.01 5.0 0.2 10.0 0.001       1.0          0.0   \n",
      "60_fp       256           0.01 5.0 0.2 10.0 0.001       1.0          0.0   \n",
      "\n",
      "                                                    ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.01 5.0 0.2 10.0 0.001             1.0   \n",
      "20_fp       256           0.01 5.0 0.2 10.0 0.001             1.0   \n",
      "40_fp       256           0.01 5.0 0.2 10.0 0.001             1.0   \n",
      "60_fp       256           0.01 5.0 0.2 10.0 0.001             1.0   \n",
      "\n",
      "                                                    optim_cluster  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.01 5.0 0.2 10.0 0.001             1.0   \n",
      "20_fp       256           0.01 5.0 0.2 10.0 0.001             1.0   \n",
      "40_fp       256           0.01 5.0 0.2 10.0 0.001             1.0   \n",
      "60_fp       256           0.01 5.0 0.2 10.0 0.001             1.0   \n",
      "\n",
      "                                                    prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                        \n",
      "10_fp       256           0.01 5.0 0.2 10.0 0.001            0.0   62.0   \n",
      "20_fp       256           0.01 5.0 0.2 10.0 0.001            0.0   62.0   \n",
      "40_fp       256           0.01 5.0 0.2 10.0 0.001            0.0   62.0   \n",
      "60_fp       256           0.01 5.0 0.2 10.0 0.001            0.0   62.0   \n",
      "\n",
      "                                                    walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                            \n",
      "10_fp       256           0.01 5.0 0.2 10.0 0.001       20.0            10.0  \n",
      "20_fp       256           0.01 5.0 0.2 10.0 0.001       20.0            10.0  \n",
      "40_fp       256           0.01 5.0 0.2 10.0 0.001       20.0            10.0  \n",
      "60_fp       256           0.01 5.0 0.2 10.0 0.001       20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    256 &    0.01 &    5.0 &    0.2 &    10.0 &    0.001\n",
      "$91.42_{0.57}$\n",
      "91.4161205291748\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                               \n",
      "10_fp       256           0.01 5.0 0.4          0.2      114.333333  0.907407   \n",
      "20_fp       256           0.01 5.0 0.4          0.2      114.333333  0.907407   \n",
      "40_fp       256           0.01 5.0 0.4          0.2      114.333333  0.907407   \n",
      "60_fp       256           0.01 5.0 0.4          0.2      114.333333  0.907407   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "10_fp       256           0.01 5.0 0.4          0.2      1.0          0.0   \n",
      "20_fp       256           0.01 5.0 0.4          0.2      1.0          0.0   \n",
      "40_fp       256           0.01 5.0 0.4          0.2      1.0          0.0   \n",
      "60_fp       256           0.01 5.0 0.4          0.2      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "10_fp       256           0.01 5.0 0.4          0.2            1.0   \n",
      "20_fp       256           0.01 5.0 0.4          0.2            1.0   \n",
      "40_fp       256           0.01 5.0 0.4          0.2            1.0   \n",
      "60_fp       256           0.01 5.0 0.4          0.2            1.0   \n",
      "\n",
      "                                                     optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "10_fp       256           0.01 5.0 0.4          0.2            1.0   62.0   \n",
      "20_fp       256           0.01 5.0 0.4          0.2            1.0   62.0   \n",
      "40_fp       256           0.01 5.0 0.4          0.2            1.0   62.0   \n",
      "60_fp       256           0.01 5.0 0.4          0.2            1.0   62.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                             \n",
      "10_fp       256           0.01 5.0 0.4          0.2   0.0     0.0      20.0   \n",
      "20_fp       256           0.01 5.0 0.4          0.2   0.0     0.0      20.0   \n",
      "40_fp       256           0.01 5.0 0.4          0.2   0.0     0.0      20.0   \n",
      "60_fp       256           0.01 5.0 0.4          0.2   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "10_fp       256           0.01 5.0 0.4          0.2            10.0  \n",
      "20_fp       256           0.01 5.0 0.4          0.2            10.0  \n",
      "40_fp       256           0.01 5.0 0.4          0.2            10.0  \n",
      "60_fp       256           0.01 5.0 0.4          0.2            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    256 &    0.01 &    5.0 &    0.4 &    0.2\n",
      "$90.74_{0.59}$\n",
      "90.74074625968933\n",
      "\n",
      "\n",
      "Pho 81\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                        trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr   p   q                                        \n",
      "10_fp       256           0.01 1.0 5.0       68.000000  0.920261      1.0   \n",
      "                               5.0 5.0       69.333333  0.920261      1.0   \n",
      "20_fp       256           0.01 1.0 5.0       68.000000  0.920261      1.0   \n",
      "                               5.0 5.0       69.333333  0.920261      1.0   \n",
      "40_fp       256           0.01 1.0 5.0       68.000000  0.920261      1.0   \n",
      "                               5.0 5.0       69.333333  0.920261      1.0   \n",
      "60_fp       256           0.01 1.0 5.0       68.000000  0.920261      1.0   \n",
      "                               5.0 5.0       69.333333  0.920261      1.0   \n",
      "\n",
      "                                        ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q                                 \n",
      "10_fp       256           0.01 1.0 5.0          0.0            1.0   \n",
      "                               5.0 5.0          0.0            1.0   \n",
      "20_fp       256           0.01 1.0 5.0          0.0            1.0   \n",
      "                               5.0 5.0          0.0            1.0   \n",
      "40_fp       256           0.01 1.0 5.0          0.0            1.0   \n",
      "                               5.0 5.0          0.0            1.0   \n",
      "60_fp       256           0.01 1.0 5.0          0.0            1.0   \n",
      "                               5.0 5.0          0.0            1.0   \n",
      "\n",
      "                                        optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q                                         \n",
      "10_fp       256           0.01 1.0 5.0            1.0           0.0   81.0   \n",
      "                               5.0 5.0            1.0           0.0   81.0   \n",
      "20_fp       256           0.01 1.0 5.0            1.0           0.0   81.0   \n",
      "                               5.0 5.0            1.0           0.0   81.0   \n",
      "40_fp       256           0.01 1.0 5.0            1.0           0.0   81.0   \n",
      "                               5.0 5.0            1.0           0.0   81.0   \n",
      "60_fp       256           0.01 1.0 5.0            1.0           0.0   81.0   \n",
      "                               5.0 5.0            1.0           0.0   81.0   \n",
      "\n",
      "                                        w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q                                            \n",
      "10_fp       256           0.01 1.0 5.0   0.0     0.0      20.0            10.0  \n",
      "                               5.0 5.0   0.0     0.0      20.0            10.0  \n",
      "20_fp       256           0.01 1.0 5.0   0.0     0.0      20.0            10.0  \n",
      "                               5.0 5.0   0.0     0.0      20.0            10.0  \n",
      "40_fp       256           0.01 1.0 5.0   0.0     0.0      20.0            10.0  \n",
      "                               5.0 5.0   0.0     0.0      20.0            10.0  \n",
      "60_fp       256           0.01 1.0 5.0   0.0     0.0      20.0            10.0  \n",
      "                               5.0 5.0   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "10_fp &    256 &    0.01 &    5.0 &    5.0\n",
      "$92.03_{0.39}$\n",
      "92.02614426612854\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                    trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                             \n",
      "10_fp       256           0.01 1.0 5.0 10.0 0.0              111.0  0.924183   \n",
      "20_fp       256           0.01 1.0 5.0 10.0 0.0              111.0  0.924183   \n",
      "40_fp       256           0.01 1.0 5.0 10.0 0.0              111.0  0.924183   \n",
      "60_fp       256           0.01 1.0 5.0 10.0 0.0              111.0  0.924183   \n",
      "\n",
      "                                                    statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                         \n",
      "10_fp       256           0.01 1.0 5.0 10.0 0.0         1.0          0.0   \n",
      "20_fp       256           0.01 1.0 5.0 10.0 0.0         1.0          0.0   \n",
      "40_fp       256           0.01 1.0 5.0 10.0 0.0         1.0          0.0   \n",
      "60_fp       256           0.01 1.0 5.0 10.0 0.0         1.0          0.0   \n",
      "\n",
      "                                                    ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.01 1.0 5.0 10.0 0.0               1.0   \n",
      "20_fp       256           0.01 1.0 5.0 10.0 0.0               1.0   \n",
      "40_fp       256           0.01 1.0 5.0 10.0 0.0               1.0   \n",
      "60_fp       256           0.01 1.0 5.0 10.0 0.0               1.0   \n",
      "\n",
      "                                                    optim_cluster  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.01 1.0 5.0 10.0 0.0               1.0   \n",
      "20_fp       256           0.01 1.0 5.0 10.0 0.0               1.0   \n",
      "40_fp       256           0.01 1.0 5.0 10.0 0.0               1.0   \n",
      "60_fp       256           0.01 1.0 5.0 10.0 0.0               1.0   \n",
      "\n",
      "                                                    prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                        \n",
      "10_fp       256           0.01 1.0 5.0 10.0 0.0              0.0   81.0   \n",
      "20_fp       256           0.01 1.0 5.0 10.0 0.0              0.0   81.0   \n",
      "40_fp       256           0.01 1.0 5.0 10.0 0.0              0.0   81.0   \n",
      "60_fp       256           0.01 1.0 5.0 10.0 0.0              0.0   81.0   \n",
      "\n",
      "                                                    walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                            \n",
      "10_fp       256           0.01 1.0 5.0 10.0 0.0         20.0            10.0  \n",
      "20_fp       256           0.01 1.0 5.0 10.0 0.0         20.0            10.0  \n",
      "40_fp       256           0.01 1.0 5.0 10.0 0.0         20.0            10.0  \n",
      "60_fp       256           0.01 1.0 5.0 10.0 0.0         20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    256 &    0.01 &    1.0 &    5.0 &    10.0 &    0.0\n",
      "$92.42_{0.35}$\n",
      "92.41830706596375\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                      trained_epochs  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                     \n",
      "10_fp       256           0.001 1.0 0.2          5.0      256.666667   \n",
      "                          0.010 0.2 0.2          5.0       94.000000   \n",
      "20_fp       256           0.001 1.0 0.2          5.0      256.666667   \n",
      "                          0.010 0.2 0.2          5.0       94.000000   \n",
      "40_fp       256           0.001 1.0 0.2          5.0      256.666667   \n",
      "                          0.010 0.2 0.2          5.0       94.000000   \n",
      "60_fp       256           0.001 1.0 0.2          5.0      256.666667   \n",
      "                          0.010 0.2 0.2          5.0       94.000000   \n",
      "\n",
      "                                                       val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                        \n",
      "10_fp       256           0.001 1.0 0.2          5.0  0.918519      1.0   \n",
      "                          0.010 0.2 0.2          5.0  0.918519      1.0   \n",
      "20_fp       256           0.001 1.0 0.2          5.0  0.918519      1.0   \n",
      "                          0.010 0.2 0.2          5.0  0.918519      1.0   \n",
      "40_fp       256           0.001 1.0 0.2          5.0  0.918519      1.0   \n",
      "                          0.010 0.2 0.2          5.0  0.918519      1.0   \n",
      "60_fp       256           0.001 1.0 0.2          5.0  0.918519      1.0   \n",
      "                          0.010 0.2 0.2          5.0  0.918519      1.0   \n",
      "\n",
      "                                                      ds_add_self  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                  \n",
      "10_fp       256           0.001 1.0 0.2          5.0          0.0   \n",
      "                          0.010 0.2 0.2          5.0          0.0   \n",
      "20_fp       256           0.001 1.0 0.2          5.0          0.0   \n",
      "                          0.010 0.2 0.2          5.0          0.0   \n",
      "40_fp       256           0.001 1.0 0.2          5.0          0.0   \n",
      "                          0.010 0.2 0.2          5.0          0.0   \n",
      "60_fp       256           0.001 1.0 0.2          5.0          0.0   \n",
      "                          0.010 0.2 0.2          5.0          0.0   \n",
      "\n",
      "                                                      ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                    \n",
      "10_fp       256           0.001 1.0 0.2          5.0            1.0   \n",
      "                          0.010 0.2 0.2          5.0            1.0   \n",
      "20_fp       256           0.001 1.0 0.2          5.0            1.0   \n",
      "                          0.010 0.2 0.2          5.0            1.0   \n",
      "40_fp       256           0.001 1.0 0.2          5.0            1.0   \n",
      "                          0.010 0.2 0.2          5.0            1.0   \n",
      "60_fp       256           0.001 1.0 0.2          5.0            1.0   \n",
      "                          0.010 0.2 0.2          5.0            1.0   \n",
      "\n",
      "                                                      optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                           \n",
      "10_fp       256           0.001 1.0 0.2          5.0            1.0   81.0   \n",
      "                          0.010 0.2 0.2          5.0            1.0   81.0   \n",
      "20_fp       256           0.001 1.0 0.2          5.0            1.0   81.0   \n",
      "                          0.010 0.2 0.2          5.0            1.0   81.0   \n",
      "40_fp       256           0.001 1.0 0.2          5.0            1.0   81.0   \n",
      "                          0.010 0.2 0.2          5.0            1.0   81.0   \n",
      "60_fp       256           0.001 1.0 0.2          5.0            1.0   81.0   \n",
      "                          0.010 0.2 0.2          5.0            1.0   81.0   \n",
      "\n",
      "                                                      w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr    p   prob_replace q                             \n",
      "10_fp       256           0.001 1.0 0.2          5.0   0.0     0.0      20.0   \n",
      "                          0.010 0.2 0.2          5.0   0.0     0.0      20.0   \n",
      "20_fp       256           0.001 1.0 0.2          5.0   0.0     0.0      20.0   \n",
      "                          0.010 0.2 0.2          5.0   0.0     0.0      20.0   \n",
      "40_fp       256           0.001 1.0 0.2          5.0   0.0     0.0      20.0   \n",
      "                          0.010 0.2 0.2          5.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.001 1.0 0.2          5.0   0.0     0.0      20.0   \n",
      "                          0.010 0.2 0.2          5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                      walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   prob_replace q                    \n",
      "10_fp       256           0.001 1.0 0.2          5.0            10.0  \n",
      "                          0.010 0.2 0.2          5.0            10.0  \n",
      "20_fp       256           0.001 1.0 0.2          5.0            10.0  \n",
      "                          0.010 0.2 0.2          5.0            10.0  \n",
      "40_fp       256           0.001 1.0 0.2          5.0            10.0  \n",
      "                          0.010 0.2 0.2          5.0            10.0  \n",
      "60_fp       256           0.001 1.0 0.2          5.0            10.0  \n",
      "                          0.010 0.2 0.2          5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    256 &    0.01 &    0.2 &    0.2 &    5.0\n",
      "$91.85_{0.40}$\n",
      "91.85185432434082\n",
      "\n",
      "\n",
      "Act 145\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q']\n",
      "60_fp &    64 &    0.1 &    False &    0.2 &    5.0\n",
      "$25.99_{0.61}$\n",
      "25.994151830673218\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                                 trained_epochs  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                   \n",
      "40_fp       64            0.1 False         5.0 5.0 1.0  0.0          83.666667   \n",
      "60_fp       64            0.1 False         5.0 5.0 1.0  0.0          83.666667   \n",
      "\n",
      "                                                                  val_acc  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv             \n",
      "40_fp       64            0.1 False         5.0 5.0 1.0  0.0     0.261988   \n",
      "60_fp       64            0.1 False         5.0 5.0 1.0  0.0     0.261988   \n",
      "\n",
      "                                                                 statrep  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv            \n",
      "40_fp       64            0.1 False         5.0 5.0 1.0  0.0         1.0   \n",
      "60_fp       64            0.1 False         5.0 5.0 1.0  0.0         1.0   \n",
      "\n",
      "                                                                 ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                \n",
      "40_fp       64            0.1 False         5.0 5.0 1.0  0.0             0.0   \n",
      "60_fp       64            0.1 False         5.0 5.0 1.0  0.0             0.0   \n",
      "\n",
      "                                                                 ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                  \n",
      "40_fp       64            0.1 False         5.0 5.0 1.0  0.0               1.0   \n",
      "60_fp       64            0.1 False         5.0 5.0 1.0  0.0               1.0   \n",
      "\n",
      "                                                                 prob_replace  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                 \n",
      "40_fp       64            0.1 False         5.0 5.0 1.0  0.0              0.0   \n",
      "60_fp       64            0.1 False         5.0 5.0 1.0  0.0              0.0   \n",
      "\n",
      "                                                                 split  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv          \n",
      "40_fp       64            0.1 False         5.0 5.0 1.0  0.0     145.0   \n",
      "60_fp       64            0.1 False         5.0 5.0 1.0  0.0     145.0   \n",
      "\n",
      "                                                                 walk_len  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv             \n",
      "40_fp       64            0.1 False         5.0 5.0 1.0  0.0         20.0   \n",
      "60_fp       64            0.1 False         5.0 5.0 1.0  0.0         20.0   \n",
      "\n",
      "                                                                 walks_per_node  \n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                  \n",
      "40_fp       64            0.1 False         5.0 5.0 1.0  0.0               10.0  \n",
      "60_fp       64            0.1 False         5.0 5.0 1.0  0.0               10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "40_fp &    64 &    0.1 &    False &    5.0 &    5.0 &    1.0 &    0.0\n",
      "$26.20_{0.13}$\n",
      "26.19883120059967\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "60_fp &    64 &    0.1 &    5.0 &    0.8 &    0.2\n",
      "$25.93_{0.59}$\n",
      "25.925925374031067\n",
      "\n",
      "\n",
      "Act 24\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q']\n",
      "10_fp &    256 &    0.1 &    True &    1.0 &    0.2\n",
      "$26.30_{0.28}$\n",
      "26.304826140403748\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                                 trained_epochs  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                   \n",
      "10_fp       64            0.1 False         0.2 1.0 0.0  0.1          84.000000   \n",
      "20_fp       64            0.1 False         5.0 0.2 10.0 0.0          50.333333   \n",
      "\n",
      "                                                                  val_acc  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv             \n",
      "10_fp       64            0.1 False         0.2 1.0 0.0  0.1     0.264145   \n",
      "20_fp       64            0.1 False         5.0 0.2 10.0 0.0     0.264145   \n",
      "\n",
      "                                                                 statrep  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv            \n",
      "10_fp       64            0.1 False         0.2 1.0 0.0  0.1         1.0   \n",
      "20_fp       64            0.1 False         5.0 0.2 10.0 0.0         1.0   \n",
      "\n",
      "                                                                 ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                \n",
      "10_fp       64            0.1 False         0.2 1.0 0.0  0.1             0.0   \n",
      "20_fp       64            0.1 False         5.0 0.2 10.0 0.0             0.0   \n",
      "\n",
      "                                                                 ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                  \n",
      "10_fp       64            0.1 False         0.2 1.0 0.0  0.1               1.0   \n",
      "20_fp       64            0.1 False         5.0 0.2 10.0 0.0               1.0   \n",
      "\n",
      "                                                                 prob_replace  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                 \n",
      "10_fp       64            0.1 False         0.2 1.0 0.0  0.1              0.0   \n",
      "20_fp       64            0.1 False         5.0 0.2 10.0 0.0              0.0   \n",
      "\n",
      "                                                                 split  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv          \n",
      "10_fp       64            0.1 False         0.2 1.0 0.0  0.1      24.0   \n",
      "20_fp       64            0.1 False         5.0 0.2 10.0 0.0      24.0   \n",
      "\n",
      "                                                                 walk_len  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv             \n",
      "10_fp       64            0.1 False         0.2 1.0 0.0  0.1         20.0   \n",
      "20_fp       64            0.1 False         5.0 0.2 10.0 0.0         20.0   \n",
      "\n",
      "                                                                 walks_per_node  \n",
      "delay_alpha embedding_dim lr  optim_cluster p   q   w_ms w_ndiv                  \n",
      "10_fp       64            0.1 False         0.2 1.0 0.0  0.1               10.0  \n",
      "20_fp       64            0.1 False         5.0 0.2 10.0 0.0               10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    64 &    0.1 &    False &    0.2 &    1.0 &    0.0 &    0.1\n",
      "$26.41_{0.49}$\n",
      "26.414474844932556\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                                  trained_epochs  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q                     \n",
      "10_fp       64            0.1 False         0.2 0.6          1.0       62.333333   \n",
      "20_fp       64            0.1 False         0.2 0.6          1.0       82.000000   \n",
      "\n",
      "                                                                   val_acc  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q               \n",
      "10_fp       64            0.1 False         0.2 0.6          1.0  0.263597   \n",
      "20_fp       64            0.1 False         0.2 0.6          1.0  0.263597   \n",
      "\n",
      "                                                                  statrep  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q              \n",
      "10_fp       64            0.1 False         0.2 0.6          1.0      1.0   \n",
      "20_fp       64            0.1 False         0.2 0.6          1.0      1.0   \n",
      "\n",
      "                                                                  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q                  \n",
      "10_fp       64            0.1 False         0.2 0.6          1.0          0.0   \n",
      "20_fp       64            0.1 False         0.2 0.6          1.0          0.0   \n",
      "\n",
      "                                                                  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q                    \n",
      "10_fp       64            0.1 False         0.2 0.6          1.0            1.0   \n",
      "20_fp       64            0.1 False         0.2 0.6          1.0            1.0   \n",
      "\n",
      "                                                                  split  w_ms  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q                  \n",
      "10_fp       64            0.1 False         0.2 0.6          1.0   24.0   0.0   \n",
      "20_fp       64            0.1 False         0.2 0.6          1.0   24.0   0.0   \n",
      "\n",
      "                                                                  w_ndiv  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q             \n",
      "10_fp       64            0.1 False         0.2 0.6          1.0     0.0   \n",
      "20_fp       64            0.1 False         0.2 0.6          1.0     0.0   \n",
      "\n",
      "                                                                  walk_len  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q               \n",
      "10_fp       64            0.1 False         0.2 0.6          1.0      20.0   \n",
      "20_fp       64            0.1 False         0.2 0.6          1.0      20.0   \n",
      "\n",
      "                                                                  walks_per_node  \n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q                    \n",
      "10_fp       64            0.1 False         0.2 0.6          1.0            10.0  \n",
      "20_fp       64            0.1 False         0.2 0.6          1.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'prob_replace', 'q']\n",
      "20_fp &    64 &    0.1 &    False &    0.2 &    0.6 &    1.0\n",
      "$26.36_{0.89}$\n",
      "26.359650492668152\n",
      "\n",
      "\n",
      "Act 43\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "20_fp &    64 &    0.1 &    0.2 &    0.2\n",
      "$26.35_{0.55}$\n",
      "26.34502947330475\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                   trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                             \n",
      "20_fp       64            0.1 0.2 1.0 0.1  0.0          47.666667  0.266667   \n",
      "40_fp       64            0.1 0.2 1.0 0.1  0.0          47.666667  0.266667   \n",
      "60_fp       64            0.1 0.2 1.0 0.1  0.0          47.666667  0.266667   \n",
      "\n",
      "                                                   statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                         \n",
      "20_fp       64            0.1 0.2 1.0 0.1  0.0         1.0          0.0   \n",
      "40_fp       64            0.1 0.2 1.0 0.1  0.0         1.0          0.0   \n",
      "60_fp       64            0.1 0.2 1.0 0.1  0.0         1.0          0.0   \n",
      "\n",
      "                                                   ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "20_fp       64            0.1 0.2 1.0 0.1  0.0               1.0   \n",
      "40_fp       64            0.1 0.2 1.0 0.1  0.0               1.0   \n",
      "60_fp       64            0.1 0.2 1.0 0.1  0.0               1.0   \n",
      "\n",
      "                                                   optim_cluster  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "20_fp       64            0.1 0.2 1.0 0.1  0.0               1.0   \n",
      "40_fp       64            0.1 0.2 1.0 0.1  0.0               1.0   \n",
      "60_fp       64            0.1 0.2 1.0 0.1  0.0               1.0   \n",
      "\n",
      "                                                   prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                        \n",
      "20_fp       64            0.1 0.2 1.0 0.1  0.0              0.0   43.0   \n",
      "40_fp       64            0.1 0.2 1.0 0.1  0.0              0.0   43.0   \n",
      "60_fp       64            0.1 0.2 1.0 0.1  0.0              0.0   43.0   \n",
      "\n",
      "                                                   walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                            \n",
      "20_fp       64            0.1 0.2 1.0 0.1  0.0         20.0            10.0  \n",
      "40_fp       64            0.1 0.2 1.0 0.1  0.0         20.0            10.0  \n",
      "60_fp       64            0.1 0.2 1.0 0.1  0.0         20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "20_fp &    64 &    0.1 &    0.2 &    1.0 &    0.1 &    0.0\n",
      "$26.67_{0.84}$\n",
      "26.66666805744171\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                                  trained_epochs  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q                     \n",
      "20_fp       256           0.1 True          5.0 0.6          0.2            48.0   \n",
      "40_fp       256           0.1 True          5.0 0.6          0.2            48.0   \n",
      "60_fp       256           0.1 True          5.0 0.6          0.2            48.0   \n",
      "\n",
      "                                                                   val_acc  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q               \n",
      "20_fp       256           0.1 True          5.0 0.6          0.2  0.261988   \n",
      "40_fp       256           0.1 True          5.0 0.6          0.2  0.261988   \n",
      "60_fp       256           0.1 True          5.0 0.6          0.2  0.261988   \n",
      "\n",
      "                                                                  statrep  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q              \n",
      "20_fp       256           0.1 True          5.0 0.6          0.2      1.0   \n",
      "40_fp       256           0.1 True          5.0 0.6          0.2      1.0   \n",
      "60_fp       256           0.1 True          5.0 0.6          0.2      1.0   \n",
      "\n",
      "                                                                  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q                  \n",
      "20_fp       256           0.1 True          5.0 0.6          0.2          0.0   \n",
      "40_fp       256           0.1 True          5.0 0.6          0.2          0.0   \n",
      "60_fp       256           0.1 True          5.0 0.6          0.2          0.0   \n",
      "\n",
      "                                                                  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q                    \n",
      "20_fp       256           0.1 True          5.0 0.6          0.2            1.0   \n",
      "40_fp       256           0.1 True          5.0 0.6          0.2            1.0   \n",
      "60_fp       256           0.1 True          5.0 0.6          0.2            1.0   \n",
      "\n",
      "                                                                  split  w_ms  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q                  \n",
      "20_fp       256           0.1 True          5.0 0.6          0.2   43.0   0.0   \n",
      "40_fp       256           0.1 True          5.0 0.6          0.2   43.0   0.0   \n",
      "60_fp       256           0.1 True          5.0 0.6          0.2   43.0   0.0   \n",
      "\n",
      "                                                                  w_ndiv  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q             \n",
      "20_fp       256           0.1 True          5.0 0.6          0.2     0.0   \n",
      "40_fp       256           0.1 True          5.0 0.6          0.2     0.0   \n",
      "60_fp       256           0.1 True          5.0 0.6          0.2     0.0   \n",
      "\n",
      "                                                                  walk_len  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q               \n",
      "20_fp       256           0.1 True          5.0 0.6          0.2      20.0   \n",
      "40_fp       256           0.1 True          5.0 0.6          0.2      20.0   \n",
      "60_fp       256           0.1 True          5.0 0.6          0.2      20.0   \n",
      "\n",
      "                                                                  walks_per_node  \n",
      "delay_alpha embedding_dim lr  optim_cluster p   prob_replace q                    \n",
      "20_fp       256           0.1 True          5.0 0.6          0.2            10.0  \n",
      "40_fp       256           0.1 True          5.0 0.6          0.2            10.0  \n",
      "60_fp       256           0.1 True          5.0 0.6          0.2            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'prob_replace', 'q']\n",
      "20_fp &    256 &    0.1 &    True &    5.0 &    0.6 &    0.2\n",
      "$26.20_{0.96}$\n",
      "26.19883120059967\n",
      "\n",
      "\n",
      "Act 62\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                               \n",
      "10_fp       64            0.1 False         1.0 5.0       76.000000  0.273465   \n",
      "20_fp       64            0.1 False         1.0 5.0       92.333333  0.273465   \n",
      "40_fp       64            0.1 False         1.0 5.0       92.333333  0.273465   \n",
      "60_fp       64            0.1 False         1.0 5.0       92.333333  0.273465   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                           \n",
      "10_fp       64            0.1 False         1.0 5.0      1.0          0.0   \n",
      "20_fp       64            0.1 False         1.0 5.0      1.0          0.0   \n",
      "40_fp       64            0.1 False         1.0 5.0      1.0          0.0   \n",
      "60_fp       64            0.1 False         1.0 5.0      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                    \n",
      "10_fp       64            0.1 False         1.0 5.0            1.0   \n",
      "20_fp       64            0.1 False         1.0 5.0            1.0   \n",
      "40_fp       64            0.1 False         1.0 5.0            1.0   \n",
      "60_fp       64            0.1 False         1.0 5.0            1.0   \n",
      "\n",
      "                                                     prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                          \n",
      "10_fp       64            0.1 False         1.0 5.0           0.0   62.0   \n",
      "20_fp       64            0.1 False         1.0 5.0           0.0   62.0   \n",
      "40_fp       64            0.1 False         1.0 5.0           0.0   62.0   \n",
      "60_fp       64            0.1 False         1.0 5.0           0.0   62.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                             \n",
      "10_fp       64            0.1 False         1.0 5.0   0.0     0.0      20.0   \n",
      "20_fp       64            0.1 False         1.0 5.0   0.0     0.0      20.0   \n",
      "40_fp       64            0.1 False         1.0 5.0   0.0     0.0      20.0   \n",
      "60_fp       64            0.1 False         1.0 5.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr  optim_cluster p   q                    \n",
      "10_fp       64            0.1 False         1.0 5.0            10.0  \n",
      "20_fp       64            0.1 False         1.0 5.0            10.0  \n",
      "40_fp       64            0.1 False         1.0 5.0            10.0  \n",
      "60_fp       64            0.1 False         1.0 5.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q']\n",
      "10_fp &    64 &    0.1 &    False &    1.0 &    5.0\n",
      "$27.35_{1.25}$\n",
      "27.346491813659668\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'optim_cluster', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    64 &    0.1 &    False &    1.0 &    5.0 &    0.0 &    0.001\n",
      "$27.50_{1.23}$\n",
      "27.500000596046448\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    64 &    0.1 &    0.2 &    0.8 &    1.0\n",
      "$27.59_{1.32}$\n",
      "27.58772075176239\n",
      "\n",
      "\n",
      "Act 81\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                       trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr  p   q                                        \n",
      "10_fp       256           0.1 1.0 0.2       46.333333  0.281579      1.0   \n",
      "20_fp       256           0.1 1.0 0.2       46.333333  0.281579      1.0   \n",
      "40_fp       256           0.1 1.0 0.2       46.333333  0.281579      1.0   \n",
      "60_fp       256           0.1 1.0 0.2       46.333333  0.281579      1.0   \n",
      "\n",
      "                                       ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q                                 \n",
      "10_fp       256           0.1 1.0 0.2          0.0            1.0   \n",
      "20_fp       256           0.1 1.0 0.2          0.0            1.0   \n",
      "40_fp       256           0.1 1.0 0.2          0.0            1.0   \n",
      "60_fp       256           0.1 1.0 0.2          0.0            1.0   \n",
      "\n",
      "                                       optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q                                         \n",
      "10_fp       256           0.1 1.0 0.2            1.0           0.0   81.0   \n",
      "20_fp       256           0.1 1.0 0.2            1.0           0.0   81.0   \n",
      "40_fp       256           0.1 1.0 0.2            1.0           0.0   81.0   \n",
      "60_fp       256           0.1 1.0 0.2            1.0           0.0   81.0   \n",
      "\n",
      "                                       w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q                                            \n",
      "10_fp       256           0.1 1.0 0.2   0.0     0.0      20.0            10.0  \n",
      "20_fp       256           0.1 1.0 0.2   0.0     0.0      20.0            10.0  \n",
      "40_fp       256           0.1 1.0 0.2   0.0     0.0      20.0            10.0  \n",
      "60_fp       256           0.1 1.0 0.2   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "10_fp &    256 &    0.1 &    1.0 &    0.2\n",
      "$28.16_{1.14}$\n",
      "28.1578928232193\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                   trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                             \n",
      "10_fp       256           0.1 5.0 0.2 0.1  0.001             63.0  0.284211   \n",
      "20_fp       256           0.1 5.0 0.2 0.1  0.001             63.0  0.284211   \n",
      "40_fp       256           0.1 5.0 0.2 0.1  0.001             63.0  0.284211   \n",
      "60_fp       256           0.1 5.0 0.2 0.1  0.001             63.0  0.284211   \n",
      "\n",
      "                                                   statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                         \n",
      "10_fp       256           0.1 5.0 0.2 0.1  0.001       1.0          0.0   \n",
      "20_fp       256           0.1 5.0 0.2 0.1  0.001       1.0          0.0   \n",
      "40_fp       256           0.1 5.0 0.2 0.1  0.001       1.0          0.0   \n",
      "60_fp       256           0.1 5.0 0.2 0.1  0.001       1.0          0.0   \n",
      "\n",
      "                                                   ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.1 5.0 0.2 0.1  0.001             1.0   \n",
      "20_fp       256           0.1 5.0 0.2 0.1  0.001             1.0   \n",
      "40_fp       256           0.1 5.0 0.2 0.1  0.001             1.0   \n",
      "60_fp       256           0.1 5.0 0.2 0.1  0.001             1.0   \n",
      "\n",
      "                                                   optim_cluster  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "10_fp       256           0.1 5.0 0.2 0.1  0.001             1.0   \n",
      "20_fp       256           0.1 5.0 0.2 0.1  0.001             1.0   \n",
      "40_fp       256           0.1 5.0 0.2 0.1  0.001             1.0   \n",
      "60_fp       256           0.1 5.0 0.2 0.1  0.001             1.0   \n",
      "\n",
      "                                                   prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                        \n",
      "10_fp       256           0.1 5.0 0.2 0.1  0.001            0.0   81.0   \n",
      "20_fp       256           0.1 5.0 0.2 0.1  0.001            0.0   81.0   \n",
      "40_fp       256           0.1 5.0 0.2 0.1  0.001            0.0   81.0   \n",
      "60_fp       256           0.1 5.0 0.2 0.1  0.001            0.0   81.0   \n",
      "\n",
      "                                                   walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                            \n",
      "10_fp       256           0.1 5.0 0.2 0.1  0.001       20.0            10.0  \n",
      "20_fp       256           0.1 5.0 0.2 0.1  0.001       20.0            10.0  \n",
      "40_fp       256           0.1 5.0 0.2 0.1  0.001       20.0            10.0  \n",
      "60_fp       256           0.1 5.0 0.2 0.1  0.001       20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    256 &    0.1 &    5.0 &    0.2 &    0.1 &    0.001\n",
      "$28.42_{1.30}$\n",
      "28.421053290367126\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                    trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                               \n",
      "10_fp       256           0.1 5.0 0.6          1.0       47.666667  0.284649   \n",
      "20_fp       256           0.1 5.0 0.6          1.0       47.666667  0.284649   \n",
      "40_fp       256           0.1 5.0 0.6          1.0       47.666667  0.284649   \n",
      "60_fp       256           0.1 5.0 0.6          1.0       47.666667  0.284649   \n",
      "\n",
      "                                                    statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                           \n",
      "10_fp       256           0.1 5.0 0.6          1.0      1.0          0.0   \n",
      "20_fp       256           0.1 5.0 0.6          1.0      1.0          0.0   \n",
      "40_fp       256           0.1 5.0 0.6          1.0      1.0          0.0   \n",
      "60_fp       256           0.1 5.0 0.6          1.0      1.0          0.0   \n",
      "\n",
      "                                                    ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                    \n",
      "10_fp       256           0.1 5.0 0.6          1.0            1.0   \n",
      "20_fp       256           0.1 5.0 0.6          1.0            1.0   \n",
      "40_fp       256           0.1 5.0 0.6          1.0            1.0   \n",
      "60_fp       256           0.1 5.0 0.6          1.0            1.0   \n",
      "\n",
      "                                                    optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                           \n",
      "10_fp       256           0.1 5.0 0.6          1.0            1.0   81.0   \n",
      "20_fp       256           0.1 5.0 0.6          1.0            1.0   81.0   \n",
      "40_fp       256           0.1 5.0 0.6          1.0            1.0   81.0   \n",
      "60_fp       256           0.1 5.0 0.6          1.0            1.0   81.0   \n",
      "\n",
      "                                                    w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                             \n",
      "10_fp       256           0.1 5.0 0.6          1.0   0.0     0.0      20.0   \n",
      "20_fp       256           0.1 5.0 0.6          1.0   0.0     0.0      20.0   \n",
      "40_fp       256           0.1 5.0 0.6          1.0   0.0     0.0      20.0   \n",
      "60_fp       256           0.1 5.0 0.6          1.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                    walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   prob_replace q                    \n",
      "10_fp       256           0.1 5.0 0.6          1.0            10.0  \n",
      "20_fp       256           0.1 5.0 0.6          1.0            10.0  \n",
      "40_fp       256           0.1 5.0 0.6          1.0            10.0  \n",
      "60_fp       256           0.1 5.0 0.6          1.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    256 &    0.1 &    5.0 &    0.6 &    1.0\n",
      "$28.46_{2.24}$\n",
      "28.464913368225098\n",
      "\n",
      "\n",
      "Re 145\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "10_fp &    64 &    0.1 &    5.0 &    0.2\n",
      "$13.42_{0.22}$\n",
      "13.424201309680939\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    64 &    0.01 &    0.2 &    5.0 &    10.0 &    0.001\n",
      "$13.49_{0.29}$\n",
      "13.492842018604279\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    64 &    0.1 &    1.0 &    0.6 &    0.2\n",
      "$13.51_{0.34}$\n",
      "13.50591629743576\n",
      "\n",
      "\n",
      "Re 24\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                        trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr   p   q                                        \n",
      "10_fp       64            0.01 0.2 5.0       17.333333  0.133591      1.0   \n",
      "                               5.0 1.0        9.666667  0.133591      1.0   \n",
      "\n",
      "                                        ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q                                 \n",
      "10_fp       64            0.01 0.2 5.0          0.0            1.0   \n",
      "                               5.0 1.0          0.0            1.0   \n",
      "\n",
      "                                        optim_cluster  prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q                                         \n",
      "10_fp       64            0.01 0.2 5.0            1.0           0.0   24.0   \n",
      "                               5.0 1.0            1.0           0.0   24.0   \n",
      "\n",
      "                                        w_ms  w_ndiv  walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q                                            \n",
      "10_fp       64            0.01 0.2 5.0   0.0     0.0      20.0            10.0  \n",
      "                               5.0 1.0   0.0     0.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "10_fp &    64 &    0.01 &    5.0 &    1.0\n",
      "$13.36_{0.31}$\n",
      "13.359074294567108\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    64 &    0.01 &    1.0 &    1.0 &    10.0 &    0.1\n",
      "$13.47_{0.34}$\n",
      "13.469387590885162\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    64 &    0.1 &    1.0 &    0.8 &    0.2\n",
      "$13.47_{0.34}$\n",
      "13.46570998430252\n",
      "\n",
      "\n",
      "Re 43\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "10_fp &    64 &    0.01 &    1.0 &    1.0\n",
      "$13.46_{0.14}$\n",
      "13.459841907024384\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    64 &    0.1 &    0.2 &    5.0 &    0.0 &    0.1\n",
      "$13.51_{0.19}$\n",
      "13.50887417793274\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    64 &    0.1 &    0.2 &    0.6 &    1.0\n",
      "$13.60_{0.11}$\n",
      "13.597136735916138\n",
      "\n",
      "\n",
      "Re 62\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "10_fp &    64 &    0.1 &    1.0 &    5.0\n",
      "$13.27_{0.28}$\n",
      "13.273034989833832\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    64 &    0.1 &    0.2 &    5.0 &    0.1 &    0.1\n",
      "$13.86_{0.38}$\n",
      "13.861313462257385\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "20_fp &    64 &    0.1 &    0.2 &    0.6 &    1.0\n",
      "$13.83_{0.57}$\n",
      "13.83190006017685\n",
      "\n",
      "\n",
      "Re 81\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "10_fp &    64 &    0.1 &    5.0 &    5.0\n",
      "$13.92_{0.17}$\n",
      "13.915857672691345\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                   trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                             \n",
      "10_fp       64            0.1 5.0 0.2 10.0 0.0          69.000000  0.141071   \n",
      "                                  1.0 1.0  0.1          28.666667  0.141071   \n",
      "20_fp       64            0.1 5.0 0.2 10.0 0.0          69.000000  0.141071   \n",
      "                                  1.0 1.0  0.1          28.666667  0.141071   \n",
      "40_fp       64            0.1 5.0 0.2 10.0 0.0          69.000000  0.141071   \n",
      "                                  1.0 1.0  0.1          28.666667  0.141071   \n",
      "60_fp       64            0.1 5.0 0.2 10.0 0.0          69.000000  0.141071   \n",
      "                                  1.0 1.0  0.1          28.666667  0.141071   \n",
      "\n",
      "                                                   statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                         \n",
      "10_fp       64            0.1 5.0 0.2 10.0 0.0         1.0          0.0   \n",
      "                                  1.0 1.0  0.1         1.0          0.0   \n",
      "20_fp       64            0.1 5.0 0.2 10.0 0.0         1.0          0.0   \n",
      "                                  1.0 1.0  0.1         1.0          0.0   \n",
      "40_fp       64            0.1 5.0 0.2 10.0 0.0         1.0          0.0   \n",
      "                                  1.0 1.0  0.1         1.0          0.0   \n",
      "60_fp       64            0.1 5.0 0.2 10.0 0.0         1.0          0.0   \n",
      "                                  1.0 1.0  0.1         1.0          0.0   \n",
      "\n",
      "                                                   ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "10_fp       64            0.1 5.0 0.2 10.0 0.0               1.0   \n",
      "                                  1.0 1.0  0.1               1.0   \n",
      "20_fp       64            0.1 5.0 0.2 10.0 0.0               1.0   \n",
      "                                  1.0 1.0  0.1               1.0   \n",
      "40_fp       64            0.1 5.0 0.2 10.0 0.0               1.0   \n",
      "                                  1.0 1.0  0.1               1.0   \n",
      "60_fp       64            0.1 5.0 0.2 10.0 0.0               1.0   \n",
      "                                  1.0 1.0  0.1               1.0   \n",
      "\n",
      "                                                   optim_cluster  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "10_fp       64            0.1 5.0 0.2 10.0 0.0               1.0   \n",
      "                                  1.0 1.0  0.1               1.0   \n",
      "20_fp       64            0.1 5.0 0.2 10.0 0.0               1.0   \n",
      "                                  1.0 1.0  0.1               1.0   \n",
      "40_fp       64            0.1 5.0 0.2 10.0 0.0               1.0   \n",
      "                                  1.0 1.0  0.1               1.0   \n",
      "60_fp       64            0.1 5.0 0.2 10.0 0.0               1.0   \n",
      "                                  1.0 1.0  0.1               1.0   \n",
      "\n",
      "                                                   prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                        \n",
      "10_fp       64            0.1 5.0 0.2 10.0 0.0              0.0   81.0   \n",
      "                                  1.0 1.0  0.1              0.0   81.0   \n",
      "20_fp       64            0.1 5.0 0.2 10.0 0.0              0.0   81.0   \n",
      "                                  1.0 1.0  0.1              0.0   81.0   \n",
      "40_fp       64            0.1 5.0 0.2 10.0 0.0              0.0   81.0   \n",
      "                                  1.0 1.0  0.1              0.0   81.0   \n",
      "60_fp       64            0.1 5.0 0.2 10.0 0.0              0.0   81.0   \n",
      "                                  1.0 1.0  0.1              0.0   81.0   \n",
      "\n",
      "                                                   walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                            \n",
      "10_fp       64            0.1 5.0 0.2 10.0 0.0         20.0            10.0  \n",
      "                                  1.0 1.0  0.1         20.0            10.0  \n",
      "20_fp       64            0.1 5.0 0.2 10.0 0.0         20.0            10.0  \n",
      "                                  1.0 1.0  0.1         20.0            10.0  \n",
      "40_fp       64            0.1 5.0 0.2 10.0 0.0         20.0            10.0  \n",
      "                                  1.0 1.0  0.1         20.0            10.0  \n",
      "60_fp       64            0.1 5.0 0.2 10.0 0.0         20.0            10.0  \n",
      "                                  1.0 1.0  0.1         20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "10_fp &    64 &    0.1 &    5.0 &    1.0 &    1.0 &    0.1\n",
      "$14.11_{0.31}$\n",
      "14.10709023475647\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                    trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                               \n",
      "10_fp       64            0.1 1.0 0.2          0.2       32.666667  0.141512   \n",
      "20_fp       64            0.1 1.0 0.2          0.2       32.666667  0.141512   \n",
      "40_fp       64            0.1 1.0 0.2          0.2       32.666667  0.141512   \n",
      "60_fp       64            0.1 1.0 0.2          0.2       32.666667  0.141512   \n",
      "\n",
      "                                                    statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                           \n",
      "10_fp       64            0.1 1.0 0.2          0.2      1.0          0.0   \n",
      "20_fp       64            0.1 1.0 0.2          0.2      1.0          0.0   \n",
      "40_fp       64            0.1 1.0 0.2          0.2      1.0          0.0   \n",
      "60_fp       64            0.1 1.0 0.2          0.2      1.0          0.0   \n",
      "\n",
      "                                                    ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                    \n",
      "10_fp       64            0.1 1.0 0.2          0.2            1.0   \n",
      "20_fp       64            0.1 1.0 0.2          0.2            1.0   \n",
      "40_fp       64            0.1 1.0 0.2          0.2            1.0   \n",
      "60_fp       64            0.1 1.0 0.2          0.2            1.0   \n",
      "\n",
      "                                                    optim_cluster  split  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                           \n",
      "10_fp       64            0.1 1.0 0.2          0.2            1.0   81.0   \n",
      "20_fp       64            0.1 1.0 0.2          0.2            1.0   81.0   \n",
      "40_fp       64            0.1 1.0 0.2          0.2            1.0   81.0   \n",
      "60_fp       64            0.1 1.0 0.2          0.2            1.0   81.0   \n",
      "\n",
      "                                                    w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                             \n",
      "10_fp       64            0.1 1.0 0.2          0.2   0.0     0.0      20.0   \n",
      "20_fp       64            0.1 1.0 0.2          0.2   0.0     0.0      20.0   \n",
      "40_fp       64            0.1 1.0 0.2          0.2   0.0     0.0      20.0   \n",
      "60_fp       64            0.1 1.0 0.2          0.2   0.0     0.0      20.0   \n",
      "\n",
      "                                                    walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   prob_replace q                    \n",
      "10_fp       64            0.1 1.0 0.2          0.2            10.0  \n",
      "20_fp       64            0.1 1.0 0.2          0.2            10.0  \n",
      "40_fp       64            0.1 1.0 0.2          0.2            10.0  \n",
      "60_fp       64            0.1 1.0 0.2          0.2            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "10_fp &    64 &    0.1 &    1.0 &    0.2 &    0.2\n",
      "$14.15_{0.53}$\n",
      "14.151221513748169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dss = [\"Cora\", \"Cite\", \"PM\", \"Pho\", \"Act\", \"Re\"]\n",
    "#dss = [Com\", Ar\"]\n",
    "splits = [\"145\", \"24\", \"43\", \"62\", \"81\"]\n",
    "do_fp(dss, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb297849-9f77-4d51-a696-c7564f356b11",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PM 62\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    5.0\n",
      "$75.30_{0.26}$\n",
      "75.30425190925598\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.2 &    256 &    0.01 &    5.0 &    5.0\n",
      "$77.30_{0.33}$\n",
      "77.2988498210907\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.2 &    256 &    0.01 &    5.0 &    5.0 &    10.0 &    0.001\n",
      "$77.50_{0.06}$\n",
      "77.50169634819031\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0.2 &    256 &    0.01 &    5.0 &    0.8 &    0.2\n",
      "$77.27_{0.22}$\n",
      "77.27349400520325\n",
      "\n",
      "\n",
      "PM 81\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    5.0\n",
      "$79.45_{0.84}$\n",
      "79.45205569267273\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.4 &    256 &    0.01 &    5.0 &    5.0\n",
      "$80.79_{0.52}$\n",
      "80.78809380531311\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.6 &    256 &    0.01 &    5.0 &    1.0 &    0.1 &    0.0\n",
      "$80.92_{0.53}$\n",
      "80.92339038848877\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0.2 &    256 &    0.01 &    1.0 &    0.4 &    5.0\n",
      "$80.79_{0.58}$\n",
      "80.78809380531311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dss = [\"PM\"]\n",
    "splits = [\"62\", \"81\"]\n",
    "do(dss, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f41d107f-5f08-4919-bb62-7b01e63d18f1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cora 145\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    0.2 &    5.0\n",
      "$67.49_{1.86}$\n",
      "67.4876868724823\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0 &    256 &    0.1 &    0.2 &    5.0\n",
      "$68.34_{2.46}$\n",
      "68.3360755443573\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.2 &    256 &    0.1 &    0.2 &    5.0 &    10.0 &    0.01\n",
      "$68.42_{1.74}$\n",
      "68.41816902160645\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0 &    256 &    0.1 &    5.0 &    0.8 &    0.2\n",
      "$68.66_{2.22}$\n",
      "68.66447925567627\n",
      "\n",
      "\n",
      "Cora 24\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    0.2 &    0.2\n",
      "$72.24_{1.35}$\n",
      "72.23761081695557\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "1_0.6 &    256 &    0.1 &    0.2 &    1.0\n",
      "$73.28_{1.35}$\n",
      "73.28408360481262\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "3_0.6 &    256 &    0.1 &    1.0 &    0.2 &    0.0 &    0.1\n",
      "$73.44_{1.76}$\n",
      "73.4379768371582\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0.2 &    256 &    0.1 &    1.0 &    0.4 &    0.2\n",
      "$73.62_{0.72}$\n",
      "73.62265586853027\n",
      "\n",
      "\n",
      "Cora 43\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                           trained_epochs   val_acc  statrep  ds_add_self  \\\n",
      "embedding_dim lr  p   q                                                     \n",
      "256           0.1 1.0 0.2        2.666667  0.766298      1.0          0.0   \n",
      "                  5.0 5.0        3.000000  0.766298      1.0          0.0   \n",
      "\n",
      "                           ds_make_undir  prob_replace  split  w_ms  w_ndiv  \\\n",
      "embedding_dim lr  p   q                                                       \n",
      "256           0.1 1.0 0.2            1.0           0.0   43.0   0.0     0.0   \n",
      "                  5.0 5.0            1.0           0.0   43.0   0.0     0.0   \n",
      "\n",
      "                           walk_len  walks_per_node  \n",
      "embedding_dim lr  p   q                              \n",
      "256           0.1 1.0 0.2      20.0            10.0  \n",
      "                  5.0 5.0      20.0            10.0  \n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    5.0 &    5.0\n",
      "$76.63_{1.23}$\n",
      "76.62976384162903\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "3_0.2 &    256 &    0.01 &    5.0 &    5.0\n",
      "$79.70_{1.25}$\n",
      "79.70479130744934\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "3_0.2 &    256 &    0.01 &    0.2 &    0.2 &    0.1 &    0.001\n",
      "$79.83_{1.30}$\n",
      "79.82780337333679\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "0_0.4 &    256 &    0.1 &    5.0 &    0.8 &    0.2\n",
      "$79.95_{1.19}$\n",
      "79.95080351829529\n",
      "\n",
      "\n",
      "Cora 62\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    1.0 &    1.0\n",
      "$79.61_{2.72}$\n",
      "79.60567474365234\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.8 &    256 &    0.1 &    5.0 &    0.2\n",
      "$82.81_{3.60}$\n",
      "82.80961513519287\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                   trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                             \n",
      "0_0.2       256           0.1 5.0 1.0 10.0 0.000        74.666667  0.833025   \n",
      "1_0.4       256           0.1 5.0 0.2 10.0 0.001        52.666667  0.833025   \n",
      "3_0.6       256           0.1 5.0 0.2 10.0 0.001        52.666667  0.833025   \n",
      "5_0.6       256           0.1 5.0 1.0 10.0 0.000        44.666667  0.833025   \n",
      "\n",
      "                                                   statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                         \n",
      "0_0.2       256           0.1 5.0 1.0 10.0 0.000       1.0          0.0   \n",
      "1_0.4       256           0.1 5.0 0.2 10.0 0.001       1.0          0.0   \n",
      "3_0.6       256           0.1 5.0 0.2 10.0 0.001       1.0          0.0   \n",
      "5_0.6       256           0.1 5.0 1.0 10.0 0.000       1.0          0.0   \n",
      "\n",
      "                                                   ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "0_0.2       256           0.1 5.0 1.0 10.0 0.000             1.0   \n",
      "1_0.4       256           0.1 5.0 0.2 10.0 0.001             1.0   \n",
      "3_0.6       256           0.1 5.0 0.2 10.0 0.001             1.0   \n",
      "5_0.6       256           0.1 5.0 1.0 10.0 0.000             1.0   \n",
      "\n",
      "                                                   prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                        \n",
      "0_0.2       256           0.1 5.0 1.0 10.0 0.000            0.0   62.0   \n",
      "1_0.4       256           0.1 5.0 0.2 10.0 0.001            0.0   62.0   \n",
      "3_0.6       256           0.1 5.0 0.2 10.0 0.001            0.0   62.0   \n",
      "5_0.6       256           0.1 5.0 1.0 10.0 0.000            0.0   62.0   \n",
      "\n",
      "                                                   walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                            \n",
      "0_0.2       256           0.1 5.0 1.0 10.0 0.000       20.0            10.0  \n",
      "1_0.4       256           0.1 5.0 0.2 10.0 0.001       20.0            10.0  \n",
      "3_0.6       256           0.1 5.0 0.2 10.0 0.001       20.0            10.0  \n",
      "5_0.6       256           0.1 5.0 1.0 10.0 0.000       20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "0_0.2 &    256 &    0.1 &    5.0 &    1.0 &    10.0 &    0.0\n",
      "$83.30_{2.83}$\n",
      "83.30252766609192\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "3_0.6 &    256 &    0.1 &    1.0 &    0.8 &    0.2\n",
      "$83.67_{3.33}$\n",
      "83.67221355438232\n",
      "\n",
      "\n",
      "Cora 81\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.01 &    0.2 &    0.2\n",
      "$86.72_{0.37}$\n",
      "86.71586513519287\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                       trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr  p   q                                        \n",
      "3_0.4       256           0.1 0.2 1.0       49.666667  0.892989      1.0   \n",
      "                                  5.0       47.333333  0.892989      1.0   \n",
      "\n",
      "                                       ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q                                 \n",
      "3_0.4       256           0.1 0.2 1.0          0.0            1.0   \n",
      "                                  5.0          0.0            1.0   \n",
      "\n",
      "                                       prob_replace  split  w_ms  w_ndiv  \\\n",
      "delay_alpha embedding_dim lr  p   q                                        \n",
      "3_0.4       256           0.1 0.2 1.0           0.0   81.0   0.0     0.0   \n",
      "                                  5.0           0.0   81.0   0.0     0.0   \n",
      "\n",
      "                                       walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q                              \n",
      "3_0.4       256           0.1 0.2 1.0      20.0            10.0  \n",
      "                                  5.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "3_0.4 &    256 &    0.1 &    0.2 &    1.0\n",
      "$89.30_{1.11}$\n",
      "89.2988920211792\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                   trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                             \n",
      "1_0.4       256           0.1 0.2 0.2 1.0  0.010        35.333333  0.895449   \n",
      "                              5.0 0.2 0.0  0.001        38.333333  0.895449   \n",
      "\n",
      "                                                   statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                         \n",
      "1_0.4       256           0.1 0.2 0.2 1.0  0.010       1.0          0.0   \n",
      "                              5.0 0.2 0.0  0.001       1.0          0.0   \n",
      "\n",
      "                                                   ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "1_0.4       256           0.1 0.2 0.2 1.0  0.010             1.0   \n",
      "                              5.0 0.2 0.0  0.001             1.0   \n",
      "\n",
      "                                                   prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                        \n",
      "1_0.4       256           0.1 0.2 0.2 1.0  0.010            0.0   81.0   \n",
      "                              5.0 0.2 0.0  0.001            0.0   81.0   \n",
      "\n",
      "                                                   walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                            \n",
      "1_0.4       256           0.1 0.2 0.2 1.0  0.010       20.0            10.0  \n",
      "                              5.0 0.2 0.0  0.001       20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "1_0.4 &    256 &    0.1 &    0.2 &    0.2 &    1.0 &    0.01\n",
      "$89.54_{0.77}$\n",
      "89.54489827156067\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "1_0.2 &    256 &    0.1 &    1.0 &    0.8 &    0.2\n",
      "$89.79_{0.93}$\n",
      "89.79089856147766\n",
      "\n",
      "\n",
      "Cite 145\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    0.2 &    5.0\n",
      "$44.91_{3.16}$\n",
      "44.9120432138443\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "3_0.2 &    256 &    0.1 &    1.0 &    0.2\n",
      "$47.12_{1.99}$\n",
      "47.11645543575287\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                   trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                             \n",
      "3_0.2       256           0.1 0.2 5.0 0.1  0.0          46.666667  0.472055   \n",
      "5_0.2       256           0.1 1.0 1.0 10.0 0.0           8.666667  0.472055   \n",
      "\n",
      "                                                   statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                         \n",
      "3_0.2       256           0.1 0.2 5.0 0.1  0.0         1.0          0.0   \n",
      "5_0.2       256           0.1 1.0 1.0 10.0 0.0         1.0          0.0   \n",
      "\n",
      "                                                   ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "3_0.2       256           0.1 0.2 5.0 0.1  0.0               1.0   \n",
      "5_0.2       256           0.1 1.0 1.0 10.0 0.0               1.0   \n",
      "\n",
      "                                                   prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                        \n",
      "3_0.2       256           0.1 0.2 5.0 0.1  0.0              0.0  145.0   \n",
      "5_0.2       256           0.1 1.0 1.0 10.0 0.0              0.0  145.0   \n",
      "\n",
      "                                                   walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                            \n",
      "3_0.2       256           0.1 0.2 5.0 0.1  0.0         20.0            10.0  \n",
      "5_0.2       256           0.1 1.0 1.0 10.0 0.0         20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.2 &    256 &    0.1 &    1.0 &    1.0 &    10.0 &    0.0\n",
      "$47.21_{1.72}$\n",
      "47.205522656440735\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                    trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                               \n",
      "3_0.2       256           0.1 0.2 0.8          1.0       32.666667  0.473837   \n",
      "                              1.0 0.6          0.2       37.000000  0.473837   \n",
      "5_0.2       256           0.1 1.0 0.6          0.2       38.000000  0.473837   \n",
      "\n",
      "                                                    statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                           \n",
      "3_0.2       256           0.1 0.2 0.8          1.0      1.0          0.0   \n",
      "                              1.0 0.6          0.2      1.0          0.0   \n",
      "5_0.2       256           0.1 1.0 0.6          0.2      1.0          0.0   \n",
      "\n",
      "                                                    ds_make_undir  split  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                           \n",
      "3_0.2       256           0.1 0.2 0.8          1.0            1.0  145.0   \n",
      "                              1.0 0.6          0.2            1.0  145.0   \n",
      "5_0.2       256           0.1 1.0 0.6          0.2            1.0  145.0   \n",
      "\n",
      "                                                    w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                             \n",
      "3_0.2       256           0.1 0.2 0.8          1.0   0.0     0.0      20.0   \n",
      "                              1.0 0.6          0.2   0.0     0.0      20.0   \n",
      "5_0.2       256           0.1 1.0 0.6          0.2   0.0     0.0      20.0   \n",
      "\n",
      "                                                    walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   prob_replace q                    \n",
      "3_0.2       256           0.1 0.2 0.8          1.0            10.0  \n",
      "                              1.0 0.6          0.2            10.0  \n",
      "5_0.2       256           0.1 1.0 0.6          0.2            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0.2 &    256 &    0.1 &    1.0 &    0.6 &    0.2\n",
      "$47.38_{1.47}$\n",
      "47.38365709781647\n",
      "\n",
      "\n",
      "Cite 24\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    1.0 &    5.0\n",
      "$51.97_{0.58}$\n",
      "51.96594595909119\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.2 &    256 &    0.1 &    0.2 &    1.0\n",
      "$53.62_{0.68}$\n",
      "53.61883044242859\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.2 &    256 &    0.1 &    0.2 &    5.0 &    0.1 &    0.0\n",
      "$53.69_{0.93}$\n",
      "53.69396209716797\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "3_0.2 &    256 &    0.1 &    1.0 &    0.6 &    5.0\n",
      "$53.62_{1.00}$\n",
      "53.618836402893066\n",
      "\n",
      "\n",
      "Cite 43\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    5.0 &    5.0\n",
      "$54.18_{1.86}$\n",
      "54.175013303756714\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.2 &    256 &    0.001 &    1.0 &    1.0\n",
      "$61.69_{0.95}$\n",
      "61.69005036354065\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                    trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                             \n",
      "5_0.2       256           0.01 1.0 1.0 1.0  0.000         1.333333  0.617902   \n",
      "                                            0.001         1.333333  0.617902   \n",
      "\n",
      "                                                    statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                         \n",
      "5_0.2       256           0.01 1.0 1.0 1.0  0.000       1.0          0.0   \n",
      "                                            0.001       1.0          0.0   \n",
      "\n",
      "                                                    ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                  \n",
      "5_0.2       256           0.01 1.0 1.0 1.0  0.000             1.0   \n",
      "                                            0.001             1.0   \n",
      "\n",
      "                                                    prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                        \n",
      "5_0.2       256           0.01 1.0 1.0 1.0  0.000            0.0   43.0   \n",
      "                                            0.001            0.0   43.0   \n",
      "\n",
      "                                                    walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   q   w_ms w_ndiv                            \n",
      "5_0.2       256           0.01 1.0 1.0 1.0  0.000       20.0            10.0  \n",
      "                                            0.001       20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.2 &    256 &    0.01 &    1.0 &    1.0 &    1.0 &    0.0\n",
      "$61.79_{0.76}$\n",
      "61.79024577140808\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0.2 &    256 &    0.01 &    1.0 &    0.2 &    1.0\n",
      "$61.76_{1.00}$\n",
      "61.75684928894043\n",
      "\n",
      "\n",
      "Cite 62\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.01 &    1.0 &    1.0\n",
      "$58.36_{1.13}$\n",
      "58.35835933685303\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                       trained_epochs  val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr  p   q                                       \n",
      "3_0.2       256           0.1 1.0 1.0       47.333333  0.63013      1.0   \n",
      "5_0.2       256           0.1 0.2 0.2        7.000000  0.63013      1.0   \n",
      "                                  5.0        9.000000  0.63013      1.0   \n",
      "\n",
      "                                       ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q                                 \n",
      "3_0.2       256           0.1 1.0 1.0          0.0            1.0   \n",
      "5_0.2       256           0.1 0.2 0.2          0.0            1.0   \n",
      "                                  5.0          0.0            1.0   \n",
      "\n",
      "                                       prob_replace  split  w_ms  w_ndiv  \\\n",
      "delay_alpha embedding_dim lr  p   q                                        \n",
      "3_0.2       256           0.1 1.0 1.0           0.0   62.0   0.0     0.0   \n",
      "5_0.2       256           0.1 0.2 0.2           0.0   62.0   0.0     0.0   \n",
      "                                  5.0           0.0   62.0   0.0     0.0   \n",
      "\n",
      "                                       walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q                              \n",
      "3_0.2       256           0.1 1.0 1.0      20.0            10.0  \n",
      "5_0.2       256           0.1 0.2 0.2      20.0            10.0  \n",
      "                                  5.0      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.2 &    256 &    0.1 &    0.2 &    5.0\n",
      "$63.01_{0.74}$\n",
      "63.01301121711731\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.2 &    256 &    0.1 &    5.0 &    0.2 &    0.0 &    0.001\n",
      "$63.91_{1.50}$\n",
      "63.91391158103943\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0.2 &    256 &    0.1 &    5.0 &    0.8 &    0.2\n",
      "$64.81_{1.26}$\n",
      "64.81481194496155\n",
      "\n",
      "\n",
      "Cite 81\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.01 &    5.0 &    0.2\n",
      "$63.96_{1.52}$\n",
      "63.95582556724548\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                         trained_epochs   val_acc  statrep  \\\n",
      "delay_alpha embedding_dim lr    p   q                                        \n",
      "5_0.2       256           0.001 1.0 0.2       47.333333  0.685743      1.0   \n",
      "                                    1.0       50.333333  0.685743      1.0   \n",
      "                                5.0 0.2       48.000000  0.685743      1.0   \n",
      "                                    1.0       48.000000  0.685743      1.0   \n",
      "                          0.100 5.0 0.2       18.666667  0.685743      1.0   \n",
      "\n",
      "                                         ds_add_self  ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr    p   q                                 \n",
      "5_0.2       256           0.001 1.0 0.2          0.0            1.0   \n",
      "                                    1.0          0.0            1.0   \n",
      "                                5.0 0.2          0.0            1.0   \n",
      "                                    1.0          0.0            1.0   \n",
      "                          0.100 5.0 0.2          0.0            1.0   \n",
      "\n",
      "                                         prob_replace  split  w_ms  w_ndiv  \\\n",
      "delay_alpha embedding_dim lr    p   q                                        \n",
      "5_0.2       256           0.001 1.0 0.2           0.0   81.0   0.0     0.0   \n",
      "                                    1.0           0.0   81.0   0.0     0.0   \n",
      "                                5.0 0.2           0.0   81.0   0.0     0.0   \n",
      "                                    1.0           0.0   81.0   0.0     0.0   \n",
      "                          0.100 5.0 0.2           0.0   81.0   0.0     0.0   \n",
      "\n",
      "                                         walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr    p   q                              \n",
      "5_0.2       256           0.001 1.0 0.2      20.0            10.0  \n",
      "                                    1.0      20.0            10.0  \n",
      "                                5.0 0.2      20.0            10.0  \n",
      "                                    1.0      20.0            10.0  \n",
      "                          0.100 5.0 0.2      20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.2 &    256 &    0.1 &    5.0 &    0.2\n",
      "$68.57_{1.82}$\n",
      "68.57430338859558\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.2 &    256 &    0.1 &    1.0 &    0.2 &    10.0 &    0.01\n",
      "$69.48_{1.22}$\n",
      "69.4779098033905\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0.2 &    256 &    0.1 &    5.0 &    0.8 &    1.0\n",
      "$72.29_{3.42}$\n",
      "72.28915691375732\n",
      "\n",
      "\n",
      "Pho 145\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                           trained_epochs   val_acc  statrep  ds_add_self  \\\n",
      "embedding_dim lr  p   q                                                     \n",
      "256           0.1 0.2 1.0       50.000000  0.847614      1.0          0.0   \n",
      "                  1.0 1.0       68.333333  0.847614      1.0          0.0   \n",
      "\n",
      "                           ds_make_undir  prob_replace  split  w_ms  w_ndiv  \\\n",
      "embedding_dim lr  p   q                                                       \n",
      "256           0.1 0.2 1.0            1.0           0.0  145.0   0.0     0.0   \n",
      "                  1.0 1.0            1.0           0.0  145.0   0.0     0.0   \n",
      "\n",
      "                           walk_len  walks_per_node  \n",
      "embedding_dim lr  p   q                              \n",
      "256           0.1 0.2 1.0      20.0            10.0  \n",
      "                  1.0 1.0      20.0            10.0  \n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    1.0 &    1.0\n",
      "$84.76_{0.12}$\n",
      "84.7613513469696\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "0_0.4 &    256 &    0.1 &    0.2 &    5.0\n",
      "$89.13_{0.15}$\n",
      "89.1277015209198\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "3_0.6 &    256 &    0.1 &    1.0 &    0.2 &    10.0 &    0.1\n",
      "$89.23_{0.25}$\n",
      "89.23419117927551\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "0_0.4 &    256 &    0.1 &    0.2 &    0.6 &    5.0\n",
      "$89.25_{0.05}$\n",
      "89.25355076789856\n",
      "\n",
      "\n",
      "Pho 24\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    1.0 &    1.0\n",
      "$87.54_{0.41}$\n",
      "87.53812909126282\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "1_0.4 &    256 &    0.01 &    0.2 &    0.2\n",
      "$90.38_{0.18}$\n",
      "90.38126468658447\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                   trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                             \n",
      "0_0.2       256           0.1 0.2 5.0 1.0  0.10          1.666667  0.904575   \n",
      "                              1.0 5.0 10.0 0.01          1.333333  0.904575   \n",
      "\n",
      "                                                   statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                         \n",
      "0_0.2       256           0.1 0.2 5.0 1.0  0.10        1.0          0.0   \n",
      "                              1.0 5.0 10.0 0.01        1.0          0.0   \n",
      "\n",
      "                                                   ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "0_0.2       256           0.1 0.2 5.0 1.0  0.10              1.0   \n",
      "                              1.0 5.0 10.0 0.01              1.0   \n",
      "\n",
      "                                                   prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                        \n",
      "0_0.2       256           0.1 0.2 5.0 1.0  0.10             0.0   24.0   \n",
      "                              1.0 5.0 10.0 0.01             0.0   24.0   \n",
      "\n",
      "                                                   walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                            \n",
      "0_0.2       256           0.1 0.2 5.0 1.0  0.10        20.0            10.0  \n",
      "                              1.0 5.0 10.0 0.01        20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "0_0.2 &    256 &    0.1 &    1.0 &    5.0 &    10.0 &    0.01\n",
      "$90.46_{0.20}$\n",
      "90.45751690864563\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "0_0.2 &    256 &    0.01 &    0.2 &    0.6 &    1.0\n",
      "$90.38_{0.08}$\n",
      "90.38126468658447\n",
      "\n",
      "\n",
      "Pho 43\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.01 &    1.0 &    1.0\n",
      "$89.69_{0.83}$\n",
      "89.68772888183594\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "1_0.4 &    256 &    0.01 &    0.2 &    0.2\n",
      "$91.46_{0.17}$\n",
      "91.45969748497009\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                   trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                             \n",
      "0_0.2       256           0.1 5.0 5.0 10.0 0.10          7.666667  0.916195   \n",
      "1_0.4       256           0.1 1.0 1.0 10.0 0.01          1.666667  0.916195   \n",
      "\n",
      "                                                   statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                         \n",
      "0_0.2       256           0.1 5.0 5.0 10.0 0.10        1.0          0.0   \n",
      "1_0.4       256           0.1 1.0 1.0 10.0 0.01        1.0          0.0   \n",
      "\n",
      "                                                   ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "0_0.2       256           0.1 5.0 5.0 10.0 0.10              1.0   \n",
      "1_0.4       256           0.1 1.0 1.0 10.0 0.01              1.0   \n",
      "\n",
      "                                                   prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                        \n",
      "0_0.2       256           0.1 5.0 5.0 10.0 0.10             0.0   43.0   \n",
      "1_0.4       256           0.1 1.0 1.0 10.0 0.01             0.0   43.0   \n",
      "\n",
      "                                                   walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                            \n",
      "0_0.2       256           0.1 5.0 5.0 10.0 0.10        20.0            10.0  \n",
      "1_0.4       256           0.1 1.0 1.0 10.0 0.01        20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "1_0.4 &    256 &    0.1 &    1.0 &    1.0 &    10.0 &    0.01\n",
      "$91.62_{0.27}$\n",
      "91.61946177482605\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "1_0.4 &    256 &    0.001 &    0.2 &    0.2 &    0.2\n",
      "$91.47_{0.15}$\n",
      "91.47422313690186\n",
      "\n",
      "\n",
      "Pho 62\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.01 &    1.0 &    1.0\n",
      "$91.61_{0.85}$\n",
      "91.61219596862793\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "0_0.2 &    256 &    0.1 &    0.2 &    1.0\n",
      "$92.75_{0.34}$\n",
      "92.7450954914093\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "1_0.4 &    256 &    0.1 &    0.2 &    5.0 &    10.0 &    0.01\n",
      "$92.98_{0.33}$\n",
      "92.98474788665771\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "0_0.4 &    256 &    0.1 &    0.2 &    0.8 &    1.0\n",
      "$92.79_{0.20}$\n",
      "92.78866648674011\n",
      "\n",
      "\n",
      "Pho 81\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.01 &    1.0 &    1.0\n",
      "$92.33_{0.42}$\n",
      "92.33115315437317\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "0_0 &    256 &    0.1 &    0.2 &    5.0\n",
      "$93.42_{0.08}$\n",
      "93.42048168182373\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                   trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                             \n",
      "0_0.2       256           0.1 0.2 1.0 10.0 0.1          20.333333  0.938998   \n",
      "                              5.0 0.2 10.0 0.1          16.000000  0.938998   \n",
      "\n",
      "                                                   statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                         \n",
      "0_0.2       256           0.1 0.2 1.0 10.0 0.1         1.0          0.0   \n",
      "                              5.0 0.2 10.0 0.1         1.0          0.0   \n",
      "\n",
      "                                                   ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "0_0.2       256           0.1 0.2 1.0 10.0 0.1               1.0   \n",
      "                              5.0 0.2 10.0 0.1               1.0   \n",
      "\n",
      "                                                   prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                        \n",
      "0_0.2       256           0.1 0.2 1.0 10.0 0.1              0.0   81.0   \n",
      "                              5.0 0.2 10.0 0.1              0.0   81.0   \n",
      "\n",
      "                                                   walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                            \n",
      "0_0.2       256           0.1 0.2 1.0 10.0 0.1         20.0            10.0  \n",
      "                              5.0 0.2 10.0 0.1         20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "0_0.2 &    256 &    0.1 &    5.0 &    0.2 &    10.0 &    0.1\n",
      "$93.90_{0.46}$\n",
      "93.89978051185608\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "0_0.2 &    256 &    0.1 &    0.2 &    0.6 &    5.0\n",
      "$93.73_{0.39}$\n",
      "93.72549057006836\n",
      "\n",
      "\n",
      "Act 145\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    0.2 &    1.0\n",
      "$25.16_{0.53}$\n",
      "25.155946612358093\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0 &    64 &    0.1 &    0.2 &    5.0\n",
      "$26.03_{0.29}$\n",
      "26.0331392288208\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "3_0 &    64 &    0.1 &    0.2 &    1.0 &    0.1 &    0.1\n",
      "$26.04_{0.29}$\n",
      "26.042887568473816\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0 &    64 &    0.1 &    0.2 &    0.6 &    0.2\n",
      "$26.20_{0.31}$\n",
      "26.19883120059967\n",
      "\n",
      "\n",
      "Act 24\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    1.0 &    5.0\n",
      "$25.73_{0.27}$\n",
      "25.73464810848236\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.4 &    64 &    0.1 &    0.2 &    1.0\n",
      "$26.33_{0.53}$\n",
      "26.326754689216614\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "3_0 &    256 &    0.1 &    1.0 &    1.0 &    1.0 &    0.01\n",
      "$26.37_{0.54}$\n",
      "26.370614767074585\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "3_0 &    64 &    0.1 &    5.0 &    0.8 &    0.2\n",
      "$26.38_{0.31}$\n",
      "26.381579041481018\n",
      "\n",
      "\n",
      "Act 43\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    1.0 &    1.0\n",
      "$26.04_{0.67}$\n",
      "26.03801190853119\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "0_0 &    64 &    0.1 &    0.2 &    1.0\n",
      "$26.45_{1.38}$\n",
      "26.447367668151855\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                   trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                             \n",
      "3_0         64            0.1 5.0 1.0 0.1  0.0          39.333333  0.266228   \n",
      "5_0         64            0.1 5.0 1.0 0.1  0.0          64.666667  0.266228   \n",
      "\n",
      "                                                   statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                         \n",
      "3_0         64            0.1 5.0 1.0 0.1  0.0         1.0          0.0   \n",
      "5_0         64            0.1 5.0 1.0 0.1  0.0         1.0          0.0   \n",
      "\n",
      "                                                   ds_make_undir  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                  \n",
      "3_0         64            0.1 5.0 1.0 0.1  0.0               1.0   \n",
      "5_0         64            0.1 5.0 1.0 0.1  0.0               1.0   \n",
      "\n",
      "                                                   prob_replace  split  \\\n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                        \n",
      "3_0         64            0.1 5.0 1.0 0.1  0.0              0.0   43.0   \n",
      "5_0         64            0.1 5.0 1.0 0.1  0.0              0.0   43.0   \n",
      "\n",
      "                                                   walk_len  walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   q   w_ms w_ndiv                            \n",
      "3_0         64            0.1 5.0 1.0 0.1  0.0         20.0            10.0  \n",
      "5_0         64            0.1 5.0 1.0 0.1  0.0         20.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0 &    64 &    0.1 &    5.0 &    1.0 &    0.1 &    0.0\n",
      "$26.62_{0.50}$\n",
      "26.62280797958374\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                    trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                               \n",
      "3_0         64            0.1 1.0 0.2          0.2       36.000000  0.263597   \n",
      "5_0         64            0.1 0.2 0.2          0.2       48.333333  0.263597   \n",
      "                              5.0 0.4          1.0       39.333333  0.263597   \n",
      "\n",
      "                                                    statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                           \n",
      "3_0         64            0.1 1.0 0.2          0.2      1.0          0.0   \n",
      "5_0         64            0.1 0.2 0.2          0.2      1.0          0.0   \n",
      "                              5.0 0.4          1.0      1.0          0.0   \n",
      "\n",
      "                                                    ds_make_undir  split  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                           \n",
      "3_0         64            0.1 1.0 0.2          0.2            1.0   43.0   \n",
      "5_0         64            0.1 0.2 0.2          0.2            1.0   43.0   \n",
      "                              5.0 0.4          1.0            1.0   43.0   \n",
      "\n",
      "                                                    w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr  p   prob_replace q                             \n",
      "3_0         64            0.1 1.0 0.2          0.2   0.0     0.0      20.0   \n",
      "5_0         64            0.1 0.2 0.2          0.2   0.0     0.0      20.0   \n",
      "                              5.0 0.4          1.0   0.0     0.0      20.0   \n",
      "\n",
      "                                                    walks_per_node  \n",
      "delay_alpha embedding_dim lr  p   prob_replace q                    \n",
      "3_0         64            0.1 1.0 0.2          0.2            10.0  \n",
      "5_0         64            0.1 0.2 0.2          0.2            10.0  \n",
      "                              5.0 0.4          1.0            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0 &    64 &    0.1 &    0.2 &    0.2 &    0.2\n",
      "$26.36_{0.58}$\n",
      "26.359650492668152\n",
      "\n",
      "\n",
      "Act 62\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    5.0 &    1.0\n",
      "$27.06_{0.74}$\n",
      "27.061402797698975\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.8 &    64 &    0.1 &    0.2 &    1.0\n",
      "$27.65_{1.42}$\n",
      "27.653509378433228\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.8 &    64 &    0.1 &    0.2 &    1.0 &    0.0 &    0.0\n",
      "$27.65_{1.42}$\n",
      "27.653509378433228\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "0_0.8 &    64 &    0.1 &    5.0 &    0.6 &    5.0\n",
      "$27.68_{1.03}$\n",
      "27.675437927246094\n",
      "\n",
      "\n",
      "Act 81\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    1.0 &    5.0\n",
      "$27.72_{0.95}$\n",
      "27.719298005104065\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "3_0 &    64 &    0.1 &    1.0 &    1.0\n",
      "$27.76_{0.53}$\n",
      "27.763158082962036\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "0_1 &    64 &    0.1 &    5.0 &    1.0 &    0.0 &    0.1\n",
      "$28.07_{1.28}$\n",
      "28.070175647735596\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "0_0.2 &    64 &    0.1 &    5.0 &    0.2 &    0.2\n",
      "$27.81_{0.59}$\n",
      "27.807018160820007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dss = [\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\", \"Ar\", \"Re\", \"Act\"]\n",
    "dss = [\"Cora\", \"Cite\", \"Pho\", \"Act\"]\n",
    "splits = [\"145\", \"24\", \"43\", \"62\", \"81\"]\n",
    "do(dss, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e1879b7-afe7-4de5-ba20-2255dbafbbdb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PM 145\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    0.2 &    0.2\n",
      "$58.45_{1.15}$\n",
      "58.45355987548828\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.2 &    256 &    0.1 &    0.2 &    1.0\n",
      "$66.85_{1.22}$\n",
      "66.85076355934143\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.2 &    256 &    0.1 &    0.2 &    0.2 &    10.0 &    0.1\n",
      "$67.55_{1.32}$\n",
      "67.55334734916687\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0.2 &    256 &    0.1 &    1.0 &    0.2 &    0.2\n",
      "$67.19_{1.04}$\n",
      "67.1889066696167\n",
      "\n",
      "\n",
      "PM 24\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    1.0\n",
      "$62.24_{1.37}$\n",
      "62.23743557929993\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.2 &    256 &    0.1 &    0.2 &    1.0\n",
      "$69.71_{0.73}$\n",
      "69.7138786315918\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.2 &    256 &    0.01 &    0.2 &    1.0 &    10.0 &    0.01\n",
      "$70.14_{0.62}$\n",
      "70.14496326446533\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0.2 &    256 &    0.1 &    0.2 &    0.2 &    5.0\n",
      "$69.59_{1.21}$\n",
      "69.58708763122559\n",
      "\n",
      "\n",
      "Com 145\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    5.0 &    1.0\n",
      "$79.88_{0.65}$\n",
      "79.87828254699707\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "3_0.6 &    256 &    0.1 &    0.2 &    0.2\n",
      "$85.44_{0.59}$\n",
      "85.44191718101501\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "3_0.6 &    256 &    0.1 &    1.0 &    0.2 &    1.0 &    0.01\n",
      "$85.65_{0.68}$\n",
      "85.64658164978027\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "1_0.4 &    256 &    0.1 &    1.0 &    0.6 &    1.0\n",
      "$85.50_{0.60}$\n",
      "85.49577593803406\n",
      "\n",
      "\n",
      "Com 24\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.01 &    5.0 &    0.2\n",
      "$82.62_{0.39}$\n",
      "82.62134194374084\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "1_0.4 &    256 &    0.1 &    0.2 &    5.0\n",
      "$86.45_{0.96}$\n",
      "86.45095229148865\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "0_0.2 &    256 &    0.1 &    5.0 &    1.0 &    10.0 &    0.01\n",
      "$86.78_{0.83}$\n",
      "86.77816390991211\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "0_0.4 &    256 &    0.1 &    5.0 &    0.2 &    0.2\n",
      "$86.50_{1.34}$\n",
      "86.49942278862\n",
      "\n",
      "\n",
      "Ar 145\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    0.2 &    5.0\n",
      "$37.20_{0.61}$\n",
      "37.19530403614044\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0 &    256 &    0.1 &    5.0 &    1.0\n",
      "$39.03_{0.64}$\n",
      "39.02800381183624\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0 &    256 &    0.1 &    1.0 &    5.0 &    1.0 &    0.001\n",
      "$39.13_{0.17}$\n",
      "39.12780284881592\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0 &    256 &    0.1 &    0.2 &    0.4 &    0.2\n",
      "$39.05_{0.56}$\n",
      "39.05220031738281\n",
      "\n",
      "\n",
      "Ar 24\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                            trained_epochs   val_acc  statrep  ds_add_self  \\\n",
      "embedding_dim lr   p   q                                                     \n",
      "256           0.01 1.0 0.2      122.666667  0.382158      1.0          0.0   \n",
      "                   5.0 5.0      145.000000  0.382158      1.0          0.0   \n",
      "\n",
      "                            ds_make_undir  prob_replace  split  w_ms  w_ndiv  \\\n",
      "embedding_dim lr   p   q                                                       \n",
      "256           0.01 1.0 0.2            1.0           0.0   24.0   0.0     0.0   \n",
      "                   5.0 5.0            1.0           0.0   24.0   0.0     0.0   \n",
      "\n",
      "                            walk_len  walks_per_node  \n",
      "embedding_dim lr   p   q                              \n",
      "256           0.01 1.0 0.2      20.0            10.0  \n",
      "                   5.0 5.0      20.0            10.0  \n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.01 &    5.0 &    5.0\n",
      "$38.22_{0.06}$\n",
      "38.21578025817871\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.2 &    256 &    0.001 &    5.0 &    0.2\n",
      "$40.04_{0.14}$\n",
      "40.03606736660004\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0 &    256 &    0.1 &    1.0 &    5.0 &    1.0 &    0.01\n",
      "$40.26_{0.21}$\n",
      "40.26402533054352\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "3_0 &    256 &    0.01 &    1.0 &    0.4 &    0.2\n",
      "$40.32_{0.65}$\n",
      "40.32186567783356\n",
      "\n",
      "\n",
      "Re 145\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    5.0 &    5.0\n",
      "$13.13_{0.39}$\n",
      "13.133293390274048\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "0_0 &    64 &    0.1 &    5.0 &    5.0\n",
      "$13.22_{0.30}$\n",
      "13.22481483221054\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "0_1 &    64 &    0.01 &    5.0 &    1.0 &    10.0 &    0.1\n",
      "$13.32_{0.36}$\n",
      "13.322873413562775\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "3_0 &    64 &    0.1 &    0.2 &    0.6 &    5.0\n",
      "$13.28_{0.47}$\n",
      "13.280381262302399\n",
      "\n",
      "\n",
      "Re 24\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    1.0 &    1.0\n",
      "$13.28_{0.47}$\n",
      "13.28185349702835\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0 &    64 &    0.001 &    0.2 &    5.0\n",
      "$13.33_{0.25}$\n",
      "13.329656422138214\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "1_0 &    64 &    0.001 &    0.2 &    1.0 &    10.0 &    0.01\n",
      "$13.55_{0.21}$\n",
      "13.553962111473083\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "0_1 &    64 &    0.1 &    1.0 &    0.6 &    1.0\n",
      "$13.40_{0.41}$\n",
      "13.399522006511688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dss = [\"PM\", \"Com\", \"Ar\", \"Re\"]\n",
    "splits = [\"145\", \"24\"]#, \"43\", \"62\", \"81\"]\n",
    "do(dss, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f8a7934-39fa-4371-8fbb-5ec68e1c1eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Com 62\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    1.0 &    1.0\n",
      "$87.06_{0.56}$\n",
      "87.05925345420837\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "1_0.6 &    256 &    0.001 &    5.0 &    1.0\n",
      "$88.95_{0.36}$\n",
      "88.94947171211243\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "1_0.2 &    256 &    0.1 &    5.0 &    1.0 &    10.0 &    0.001\n",
      "$89.77_{0.11}$\n",
      "89.77341651916504\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "0_0.2 &    256 &    0.01 &    0.2 &    0.8 &    5.0\n",
      "$89.23_{0.38}$\n",
      "89.22815918922424\n",
      "\n",
      "\n",
      "Com 81\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    0.2 &    5.0\n",
      "$88.00_{1.55}$\n",
      "87.99999356269836\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "0_0.4 &    256 &    0.001 &    0.2 &    5.0\n",
      "$89.87_{0.99}$\n",
      "89.86666798591614\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "0_0.2 &    256 &    0.1 &    0.2 &    0.2 &    10.0 &    0.001\n",
      "$90.47_{0.79}$\n",
      "90.47272801399231\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                                                     trained_epochs   val_acc  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                               \n",
      "0_0.2       256           0.01 0.2 0.8          5.0       94.666667  0.901333   \n",
      "                               5.0 0.8          0.2       80.666667  0.901333   \n",
      "\n",
      "                                                     statrep  ds_add_self  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "0_0.2       256           0.01 0.2 0.8          5.0      1.0          0.0   \n",
      "                               5.0 0.8          0.2      1.0          0.0   \n",
      "\n",
      "                                                     ds_make_undir  split  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                           \n",
      "0_0.2       256           0.01 0.2 0.8          5.0            1.0   81.0   \n",
      "                               5.0 0.8          0.2            1.0   81.0   \n",
      "\n",
      "                                                     w_ms  w_ndiv  walk_len  \\\n",
      "delay_alpha embedding_dim lr   p   prob_replace q                             \n",
      "0_0.2       256           0.01 0.2 0.8          5.0   0.0     0.0      20.0   \n",
      "                               5.0 0.8          0.2   0.0     0.0      20.0   \n",
      "\n",
      "                                                     walks_per_node  \n",
      "delay_alpha embedding_dim lr   p   prob_replace q                    \n",
      "0_0.2       256           0.01 0.2 0.8          5.0            10.0  \n",
      "                               5.0 0.8          0.2            10.0  \n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "0_0.2 &    256 &    0.01 &    0.2 &    0.8 &    5.0\n",
      "$90.13_{0.68}$\n",
      "90.13333320617676\n",
      "\n",
      "\n",
      "Re 62\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    0.2 &    5.0\n",
      "$13.66_{0.29}$\n",
      "13.66276890039444\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "0_0 &    64 &    0.1 &    1.0 &    5.0\n",
      "$13.65_{0.23}$\n",
      "13.648062944412231\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "0_1 &    64 &    0.1 &    1.0 &    0.2 &    10.0 &    0.1\n",
      "$14.13_{0.45}$\n",
      "14.126038551330566\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "0_1 &    64 &    0.1 &    1.0 &    0.6 &    0.2\n",
      "$14.07_{0.77}$\n",
      "14.074563980102539\n",
      "\n",
      "\n",
      "Re 81\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                            trained_epochs   val_acc  statrep  ds_add_self  \\\n",
      "embedding_dim lr   p   q                                                     \n",
      "64            0.01 0.2 5.0        5.666667  0.140335      1.0          0.0   \n",
      "              0.10 5.0 1.0       23.000000  0.140335      1.0          0.0   \n",
      "\n",
      "                            ds_make_undir  prob_replace  split  w_ms  w_ndiv  \\\n",
      "embedding_dim lr   p   q                                                       \n",
      "64            0.01 0.2 5.0            1.0           0.0   81.0   0.0     0.0   \n",
      "              0.10 5.0 1.0            1.0           0.0   81.0   0.0     0.0   \n",
      "\n",
      "                            walk_len  walks_per_node  \n",
      "embedding_dim lr   p   q                              \n",
      "64            0.01 0.2 5.0      20.0            10.0  \n",
      "              0.10 5.0 1.0      20.0            10.0  \n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.01 &    0.2 &    5.0\n",
      "$14.03_{0.32}$\n",
      "14.033539593219757\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "1_0.8 &    64 &    0.1 &    0.2 &    0.2\n",
      "$13.92_{0.23}$\n",
      "13.915857672691345\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "0_0 &    64 &    0.1 &    5.0 &    0.2 &    10.0 &    0.0\n",
      "$14.53_{0.11}$\n",
      "14.533686637878418\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "0_1 &    64 &    0.1 &    5.0 &    0.4 &    1.0\n",
      "$14.36_{0.60}$\n",
      "14.35716301202774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dss = [\"Com\", \"Re\"]\n",
    "splits = [\"62\", \"81\"]\n",
    "do(dss, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "920f3b39-e765-4731-b3ae-7c9e936c4144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ar 43\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    5.0\n",
      "$40.91_{0.23}$\n",
      "40.91465771198273\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0 &    256 &    0.01 &    5.0 &    5.0\n",
      "$42.31_{0.45}$\n",
      "42.30751693248749\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0 &    256 &    0.01 &    1.0 &    1.0 &    1.0 &    0.1\n",
      "$42.38_{0.45}$\n",
      "42.38464832305908\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0 &    256 &    0.01 &    5.0 &    0.6 &    0.2\n",
      "$42.35_{0.49}$\n",
      "42.352887988090515\n",
      "\n",
      "\n",
      "Re 43\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.01 &    0.2 &    1.0\n",
      "$13.46_{0.34}$\n",
      "13.459841907024384\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0 &    64 &    0.01 &    0.2 &    1.0\n",
      "$13.37_{0.38}$\n",
      "13.36667686700821\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "1_0 &    64 &    0.1 &    5.0 &    0.2 &    1.0 &    0.001\n",
      "$13.61_{0.11}$\n",
      "13.611847162246704\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "0_1 &    64 &    0.1 &    0.2 &    0.4 &    5.0\n",
      "$13.85_{0.16}$\n",
      "13.847209513187408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dss = [\"Ar\"]\n",
    "# splits = [\"62\", \"81\"]\n",
    "# do(dss, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb30bed-9f42-4bc7-888e-7930ff6ee831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delay_alpha</th>\n",
       "      <th>trained_epochs</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>statrep</th>\n",
       "      <th>datamode</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ds_add_self</th>\n",
       "      <th>ds_make_undir</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>lr</th>\n",
       "      <th>model</th>\n",
       "      <th>p</th>\n",
       "      <th>prob_replace</th>\n",
       "      <th>q</th>\n",
       "      <th>split</th>\n",
       "      <th>w_ms</th>\n",
       "      <th>w_ndiv</th>\n",
       "      <th>walk_len</th>\n",
       "      <th>walks_per_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.414455</td>\n",
       "      <td>1</td>\n",
       "      <td>gra</td>\n",
       "      <td>Amazon-ratings</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>N2V</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>81</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.412005</td>\n",
       "      <td>1</td>\n",
       "      <td>gra</td>\n",
       "      <td>Amazon-ratings</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>N2V</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>81</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.415272</td>\n",
       "      <td>1</td>\n",
       "      <td>gra</td>\n",
       "      <td>Amazon-ratings</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>N2V</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>81</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5_0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.412005</td>\n",
       "      <td>1</td>\n",
       "      <td>gra</td>\n",
       "      <td>Amazon-ratings</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>N2V</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>81</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.414047</td>\n",
       "      <td>1</td>\n",
       "      <td>gra</td>\n",
       "      <td>Amazon-ratings</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>N2V</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>81</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72592</th>\n",
       "      <td>0_0.8</td>\n",
       "      <td>227</td>\n",
       "      <td>0.442630</td>\n",
       "      <td>0</td>\n",
       "      <td>gra</td>\n",
       "      <td>Amazon-ratings</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>N2V</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72593</th>\n",
       "      <td>1_0.8</td>\n",
       "      <td>115</td>\n",
       "      <td>0.441405</td>\n",
       "      <td>0</td>\n",
       "      <td>gra</td>\n",
       "      <td>Amazon-ratings</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>N2V</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72594</th>\n",
       "      <td>3_0.8</td>\n",
       "      <td>105</td>\n",
       "      <td>0.443446</td>\n",
       "      <td>0</td>\n",
       "      <td>gra</td>\n",
       "      <td>Amazon-ratings</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>N2V</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72595</th>\n",
       "      <td>5_0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>0.439771</td>\n",
       "      <td>0</td>\n",
       "      <td>gra</td>\n",
       "      <td>Amazon-ratings</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>N2V</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72596</th>\n",
       "      <td>0_1</td>\n",
       "      <td>213</td>\n",
       "      <td>0.443446</td>\n",
       "      <td>0</td>\n",
       "      <td>gra</td>\n",
       "      <td>Amazon-ratings</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>N2V</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72597 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      delay_alpha  trained_epochs   val_acc  statrep datamode         dataset  \\\n",
       "0             0_0              56  0.414455        1      gra  Amazon-ratings   \n",
       "1             1_0              57  0.412005        1      gra  Amazon-ratings   \n",
       "2             3_0              15  0.415272        1      gra  Amazon-ratings   \n",
       "3             5_0              18  0.412005        1      gra  Amazon-ratings   \n",
       "4           0_0.2               8  0.414047        1      gra  Amazon-ratings   \n",
       "...           ...             ...       ...      ...      ...             ...   \n",
       "72592       0_0.8             227  0.442630        0      gra  Amazon-ratings   \n",
       "72593       1_0.8             115  0.441405        0      gra  Amazon-ratings   \n",
       "72594       3_0.8             105  0.443446        0      gra  Amazon-ratings   \n",
       "72595       5_0.8             106  0.439771        0      gra  Amazon-ratings   \n",
       "72596         0_1             213  0.443446        0      gra  Amazon-ratings   \n",
       "\n",
       "       ds_add_self  ds_make_undir  embedding_dim     lr model    p  \\\n",
       "0            False           True             64  0.010   N2V  0.2   \n",
       "1            False           True             64  0.010   N2V  0.2   \n",
       "2            False           True             64  0.010   N2V  0.2   \n",
       "3            False           True             64  0.010   N2V  0.2   \n",
       "4            False           True             64  0.010   N2V  0.2   \n",
       "...            ...            ...            ...    ...   ...  ...   \n",
       "72592        False           True            256  0.001   N2V  5.0   \n",
       "72593        False           True            256  0.001   N2V  5.0   \n",
       "72594        False           True            256  0.001   N2V  5.0   \n",
       "72595        False           True            256  0.001   N2V  5.0   \n",
       "72596        False           True            256  0.001   N2V  5.0   \n",
       "\n",
       "       prob_replace    q  split  w_ms  w_ndiv  walk_len  walks_per_node  \n",
       "0               0.0  0.2     81   0.1     0.0        20              10  \n",
       "1               0.0  0.2     81   0.1     0.0        20              10  \n",
       "2               0.0  0.2     81   0.1     0.0        20              10  \n",
       "3               0.0  0.2     81   0.1     0.0        20              10  \n",
       "4               0.0  0.2     81   0.1     0.0        20              10  \n",
       "...             ...  ...    ...   ...     ...       ...             ...  \n",
       "72592           0.0  5.0     81   0.0     0.1        20              10  \n",
       "72593           0.0  5.0     81   0.0     0.1        20              10  \n",
       "72594           0.0  5.0     81   0.0     0.1        20              10  \n",
       "72595           0.0  5.0     81   0.0     0.1        20              10  \n",
       "72596           0.0  5.0     81   0.0     0.1        20              10  \n",
       "\n",
       "[72597 rows x 19 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [\"\", \"r\", \"a\", \"a1\", \"a2\", \"b\", \"b1\", \"c\", \"c1\", \"c2\"]\n",
    "\n",
    "df = pd.concat([pd.read_pickle(\"../results_comb/Ar_81\"+split+\".pkl\") for split in tmp], ignore_index=True).drop([\n",
    "                \"val_loss\", \"loss_hist\", \"valtest_time\", \"train_time\", \"record_train\", \"save_models\", \"batch_size\", \"batch_size_test\", \"batch_size_val\", \"alpha\", \"delay\", \"save_embeds\",\n",
    "                \"context_size\", \"num_negative_samples\", \"max_iter\", \"patience\"], axis=1, errors=\"ignore\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09b898fa-beb6-49b1-8217-97cdf9dcb2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.01 &    5.0 &    0.2\n",
      "$43.74_{1.03}$\n",
      "43.738940358161926\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0 &    256 &    0.01 &    5.0 &    1.0\n",
      "$44.62_{0.57}$\n",
      "44.61685121059418\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "3_0 &    256 &    0.1 &    1.0 &    1.0 &    0.1 &    0.1\n",
      "$44.97_{1.12}$\n",
      "44.97073590755463\n",
      "\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0.8 &    256 &    0.1 &    0.2 &    0.2 &    1.0\n",
      "$44.86_{1.43}$\n",
      "44.86185014247894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_gen_save(df[df.w_ms.eq(0) & df.w_ndiv.eq(0) & df.prob_replace.eq(0) & df.delay_alpha.eq(\"0_1\")], \"base\")\n",
    "print_gen_save(df[df.w_ms.eq(0) & df.w_ndiv.eq(0) & df.prob_replace.eq(0) & df.delay_alpha.ne(\"0_1\")], \"post\")\n",
    "print_gen_save(df[df.prob_replace.eq(0)], \"loss\")\n",
    "print_gen_save(df[df.prob_replace.ne(0)], \"prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9e74b-4358-4953-92c0-966847cb3e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eaaf9104-299f-4b8a-a234-8ef3c8f4286e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PM &  baseline  & $58.45_{1.15}$ & $62.24_{1.37}$ \\\\\n",
      "  & best post-hoc & $66.85_{1.22}$ & $69.71_{0.73}$ \\\\\n",
      "  &     w losses  & $67.55_{1.32}$ & $70.14_{0.62}$ \\\\\n",
      "  &   w sampling  & $67.19_{1.04}$ & $69.59_{1.21}$ \\\\ \\midrule\n",
      "\n",
      "\n",
      "Com &  baseline  & $79.88_{0.65}$ & $82.62_{0.39}$ \\\\\n",
      "  & best post-hoc & $85.44_{0.59}$ & $86.45_{0.96}$ \\\\\n",
      "  &     w losses  & $85.65_{0.68}$ & $86.78_{0.83}$ \\\\\n",
      "  &   w sampling  & $85.50_{0.60}$ & $86.50_{1.34}$ \\\\ \\midrule\n",
      "\n",
      "\n",
      "Ar &  baseline  & $37.20_{0.61}$ & $38.22_{0.06}$ \\\\\n",
      "  & best post-hoc & $39.03_{0.64}$ & $40.04_{0.14}$ \\\\\n",
      "  &     w losses  & $39.13_{0.17}$ & $40.26_{0.21}$ \\\\\n",
      "  &   w sampling  & $39.05_{0.56}$ & $40.32_{0.65}$ \\\\ \\midrule\n",
      "\n",
      "\n",
      "Re &  baseline  & $13.13_{0.39}$ & $13.28_{0.47}$ \\\\\n",
      "  & best post-hoc & $13.22_{0.30}$ & $13.33_{0.25}$ \\\\\n",
      "  &     w losses  & $13.32_{0.36}$ & $13.55_{0.21}$ \\\\\n",
      "  &   w sampling  & $13.28_{0.47}$ & $13.40_{0.41}$ \\\\ \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_table([\"PM\", \"Com\", \"Ar\", \"Re\"], [\"145\", \"24\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07373440-258d-4a93-b485-24ec263cf40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "433ef526-14ec-41a5-8e43-b0c79c24fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_save_tr(dfi, split):\n",
    "    df = dfi[dfi.split_val.eq(split)]\n",
    "    params = []\n",
    "    for c in df.drop([\"val_acc\", \"statrep\", \"trained_epochs\"], axis=1).columns:\n",
    "        if len(df[c].unique())>1:\n",
    "            params.append(c)\n",
    "    tmp = df.groupby(params)\n",
    "    mean = tmp.mean(numeric_only = True)\n",
    "    std = tmp.std(numeric_only = True)\n",
    "    \n",
    "    ix = mean.val_acc.idxmax()\n",
    "    num_occ = mean.val_acc.value_counts()[mean.loc[ix].val_acc]\n",
    "    \n",
    "    #check wether max is unique, if not use lowest sd one\n",
    "    if num_occ > 1:\n",
    "        print()\n",
    "        print(\"more than 1 max acc:\")\n",
    "        max_df = mean[mean.val_acc.eq(mean.loc[ix].val_acc)]\n",
    "        print(max_df)\n",
    "        print()\n",
    "        for index, row in max_df.iterrows():\n",
    "            if std.loc[index].val_acc < std.loc[ix].val_acc:\n",
    "                ix = index\n",
    "    \n",
    "    print(params)\n",
    "    print(t2l(ix))\n",
    "    print(\"${:.2f}_{{{:.2f}}}$\".format(mean.loc[ix].val_acc*100, std.loc[ix].val_acc*100))\n",
    "    print(mean.loc[ix].val_acc*100)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    base_d = {\"batch_size\":[128], \"prob_replace\":[0], \"statrep\":[10], \"w_ms\": [0], \"w_ndiv\":[0], \"split\":[\"trans_\"+split], \"dataset\":[df[\"dataset\"].unique()[0]], \"save_embeds\":[True]}\n",
    "    #remove numpy datatypes (loaded by pandas) for saving\n",
    "    d = {}\n",
    "    for i in range(len(ix)):\n",
    "        try:\n",
    "            d[params[i]] = [ix[i].item()]\n",
    "        except:\n",
    "            d[params[i]] = [ix[i]]\n",
    "    base_d.update(d)\n",
    "        \n",
    "    yaml.dump(base_d, open(\"../Experiments/E_\"+base_d[\"dataset\"][0]+\"_\"+split+\"_tr.yml\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ca8260-759c-4b31-8807-9ef917d0276c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    0.2 &    0.2\n",
      "$78.93_{0.31}$\n",
      "78.93404364585876\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    0.2 &    0.2\n",
      "$80.25_{0.35}$\n",
      "80.24638295173645\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    1.0 &    1.0\n",
      "$80.88_{0.52}$\n",
      "80.87913990020752\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    1.0 &    0.2\n",
      "$80.87_{0.62}$\n",
      "80.86894154548645\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    1.0 &    1.0\n",
      "$81.60_{0.57}$\n",
      "81.59543871879578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds = \"WCS\"\n",
    "df = pd.read_pickle(\"../results_comb/\"+ds+\"_tr.pkl\").drop([\"batch_size\", \"save_embeds\", \"context_size\", \"num_negative_samples\", \"max_iter\", \"patience\"], axis=1)\n",
    "for split in [\"145\", \"24\", \"43\", \"62\", \"81\"]:\n",
    "    gen_save_tr(df, split)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a63435a8-0c22-4ded-812e-0ba011605fe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    1.0\n",
      "$55.56_{2.32}$\n",
      "55.55555820465088\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    1.0 &    1.0\n",
      "$59.53_{2.26}$\n",
      "59.5291793346405\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    5.0\n",
      "$63.83_{0.35}$\n",
      "63.82765173912048\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    0.2\n",
      "$65.02_{0.65}$\n",
      "65.01501202583313\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    1.0\n",
      "$65.56_{3.62}$\n",
      "65.56224822998047\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.001 &    0.2 &    0.2\n",
      "$80.68_{0.41}$\n",
      "80.6845486164093\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.001 &    1.0 &    1.0\n",
      "$81.18_{0.15}$\n",
      "81.18000030517578\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    0.2 &    0.2\n",
      "$81.95_{0.53}$\n",
      "81.94984793663025\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    1.0\n",
      "$82.70_{0.19}$\n",
      "82.69945979118347\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    1.0 &    1.0\n",
      "$82.94_{0.36}$\n",
      "82.93590545654297\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    1.0 &    1.0\n",
      "$87.69_{0.23}$\n",
      "87.68783211708069\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    1.0 &    1.0\n",
      "$88.59_{0.37}$\n",
      "88.5899543762207\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    1.0 &    0.2\n",
      "$89.72_{0.38}$\n",
      "89.72120881080627\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    1.0 &    1.0\n",
      "$90.34_{0.66}$\n",
      "90.34290313720703\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    1.0 &    1.0\n",
      "$90.74_{0.30}$\n",
      "90.73939323425293\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    1.0\n",
      "$91.32_{0.23}$\n",
      "91.31571650505066\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    1.0\n",
      "$92.22_{0.09}$\n",
      "92.22221970558167\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    0.2 &    1.0\n",
      "$92.62_{0.14}$\n",
      "92.62164235115051\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    0.2 &    1.0\n",
      "$93.07_{0.13}$\n",
      "93.07189583778381\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    1.0\n",
      "$93.86_{0.99}$\n",
      "93.85620951652527\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    5.0 &    0.2\n",
      "$24.60_{0.29}$\n",
      "24.60039108991623\n",
      "\n",
      "\n",
      "more than 1 max acc:\n",
      "                           trained_epochs   val_acc  statrep  ds_add_self  \\\n",
      "embedding_dim lr  p   q                                                     \n",
      "64            0.1 0.2 1.0       86.333333  0.248684      1.0          0.0   \n",
      "                      5.0       13.000000  0.248684      1.0          0.0   \n",
      "\n",
      "                           ds_make_undir  prob_replace  w_ms  w_ndiv  \\\n",
      "embedding_dim lr  p   q                                                \n",
      "64            0.1 0.2 1.0            1.0           0.0   0.0     0.0   \n",
      "                      5.0            1.0           0.0   0.0     0.0   \n",
      "\n",
      "                           walk_len  walks_per_node  \n",
      "embedding_dim lr  p   q                              \n",
      "64            0.1 0.2 1.0      20.0            10.0  \n",
      "                      5.0      20.0            10.0  \n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    0.2 &    1.0\n",
      "$24.87_{0.33}$\n",
      "24.868421256542206\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    5.0 &    5.0\n",
      "$26.01_{0.79}$\n",
      "26.00877285003662\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    0.2 &    0.2\n",
      "$27.06_{0.30}$\n",
      "27.061402797698975\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    5.0 &    0.2\n",
      "$27.41_{0.72}$\n",
      "27.412280440330505\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.001 &    5.0 &    0.2\n",
      "$39.88_{0.49}$\n",
      "39.87782001495361\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    1.0\n",
      "$41.31_{0.50}$\n",
      "41.30516052246094\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    1.0\n",
      "$42.83_{0.26}$\n",
      "42.829275131225586\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    0.2 &    0.2\n",
      "$43.19_{0.84}$\n",
      "43.19249093532562\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.001 &    5.0 &    5.0\n",
      "$43.64_{1.08}$\n",
      "43.63685846328735\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    1.0 &    1.0\n",
      "$12.15_{0.34}$\n",
      "12.146171927452087\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    5.0 &    0.2\n",
      "$13.19_{0.15}$\n",
      "13.186247646808624\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    0.2 &    0.2\n",
      "$13.56_{0.14}$\n",
      "13.557909429073334\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    5.0 &    1.0\n",
      "$13.77_{0.34}$\n",
      "13.773071765899658\n",
      "\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "64 &    0.1 &    1.0 &    1.0\n",
      "$14.18_{0.59}$\n",
      "14.180640876293182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ds in [\"Cite\", \"PM\", \"Com\", \"Pho\", \"Act\", \"Ar\", \"Re\"]: #Cora\n",
    "    df = pd.read_pickle(\"../results_comb/\"+ds+\"_tr.pkl\").drop([\"batch_size\", \"save_embeds\", \"context_size\", \"num_negative_samples\", \"max_iter\", \"patience\"], axis=1)\n",
    "    for split in [\"145\", \"24\", \"43\", \"62\", \"81\"]:\n",
    "        gen_save_tr(df, split)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "435cc6b9-8409-453e-9899-f9f6c26eba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_save_exfeats(dfi, ds, split, name):\n",
    "    print(ds, split)\n",
    "    if name == \"base\":\n",
    "        df = dfi[dfi.split.eq(split) & dfi.dataset.eq(ds) & dfi.alpha.eq(\"1\")]\n",
    "    elif name == \"fp\":\n",
    "        df = dfi[dfi.split.eq(split) & dfi.dataset.eq(ds) & dfi.alpha.eq(\"fp\")]\n",
    "    elif name == \"ph\":\n",
    "        df = dfi[dfi.split.eq(split) & dfi.dataset.eq(ds) & dfi.alpha.ne(\"fp\") & dfi.alpha.ne(\"1\")]\n",
    "    df = df.drop([\"delay\", \"alpha\"], axis=1)\n",
    "    params = [\"delay_alpha\"]\n",
    "    tmp = df.groupby(params)\n",
    "    mean = tmp.mean(numeric_only = True)\n",
    "    std = tmp.std(numeric_only = True)\n",
    "\n",
    "   \n",
    "    ix = mean.val_acc.idxmax()\n",
    "    num_occ = mean.val_acc.value_counts()[mean.loc[ix].val_acc]\n",
    "    \n",
    "    #check wether max is unique, if not use lowest sd one\n",
    "    if num_occ > 1:\n",
    "        print()\n",
    "        print(\"more than 1 max acc:\")\n",
    "        max_df = mean[mean.val_acc.eq(mean.loc[ix].val_acc)]\n",
    "        print(max_df)\n",
    "        print()\n",
    "        for index, row in max_df.iterrows():\n",
    "            if std.loc[index].val_acc < std.loc[ix].val_acc:\n",
    "                ix = index\n",
    "    \n",
    "    print(params)\n",
    "    print(ix)\n",
    "    print(\"${:.2f}_{{{:.2f}}}$\".format(mean.loc[ix].val_acc*100, std.loc[ix].val_acc*100))\n",
    "    print(mean.loc[ix].val_acc*100)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    base_d = {\"statrep\":[10], \"split\":[split], \"dataset\":[df[\"dataset\"].unique()[0]], \"save_embeds\":[True], \"model\":[\"feats\"]}\n",
    "    #remove numpy datatypes (loaded by pandas) for saving\n",
    "    \n",
    "    tmp = ix.split(\"_\")\n",
    "    if tmp[1] == \"fp\":\n",
    "        base_d[\"fp\"] = [[int(tmp[0])]]\n",
    "        base_d.pop(\"delay\", None)\n",
    "        base_d.pop(\"alpha\", None)\n",
    "    else:\n",
    "        base_d[\"delay\"] = [[int(tmp[0])]]\n",
    "        base_d[\"alpha\"] = [[float(tmp[1])]]\n",
    "        \n",
    "    yaml.dump(base_d, open(\"../Experiments/E_\"+base_d[\"dataset\"][0]+\"_\"+str(split)+\"_exf_\"+name+\".yml\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "787c3ca1-0254-4f00-a752-25a16c00271b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delay_alpha</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>statrep</th>\n",
       "      <th>datamode</th>\n",
       "      <th>alpha</th>\n",
       "      <th>dataset</th>\n",
       "      <th>delay</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0.899020</td>\n",
       "      <td>0</td>\n",
       "      <td>gra</td>\n",
       "      <td>0</td>\n",
       "      <td>Photo</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_0</td>\n",
       "      <td>0.892157</td>\n",
       "      <td>0</td>\n",
       "      <td>gra</td>\n",
       "      <td>0</td>\n",
       "      <td>Photo</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_0</td>\n",
       "      <td>0.882680</td>\n",
       "      <td>0</td>\n",
       "      <td>gra</td>\n",
       "      <td>0</td>\n",
       "      <td>Photo</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5_0</td>\n",
       "      <td>0.865359</td>\n",
       "      <td>0</td>\n",
       "      <td>gra</td>\n",
       "      <td>0</td>\n",
       "      <td>Photo</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0.2</td>\n",
       "      <td>0.900980</td>\n",
       "      <td>0</td>\n",
       "      <td>gra</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Photo</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11245</th>\n",
       "      <td>0_1</td>\n",
       "      <td>0.111591</td>\n",
       "      <td>9</td>\n",
       "      <td>gra</td>\n",
       "      <td>1</td>\n",
       "      <td>Roman-empire</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246</th>\n",
       "      <td>10_fp</td>\n",
       "      <td>0.115317</td>\n",
       "      <td>9</td>\n",
       "      <td>gra</td>\n",
       "      <td>fp</td>\n",
       "      <td>Roman-empire</td>\n",
       "      <td>10</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11247</th>\n",
       "      <td>20_fp</td>\n",
       "      <td>0.113650</td>\n",
       "      <td>9</td>\n",
       "      <td>gra</td>\n",
       "      <td>fp</td>\n",
       "      <td>Roman-empire</td>\n",
       "      <td>20</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11248</th>\n",
       "      <td>40_fp</td>\n",
       "      <td>0.113061</td>\n",
       "      <td>9</td>\n",
       "      <td>gra</td>\n",
       "      <td>fp</td>\n",
       "      <td>Roman-empire</td>\n",
       "      <td>40</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11249</th>\n",
       "      <td>60_fp</td>\n",
       "      <td>0.112375</td>\n",
       "      <td>9</td>\n",
       "      <td>gra</td>\n",
       "      <td>fp</td>\n",
       "      <td>Roman-empire</td>\n",
       "      <td>60</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11250 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      delay_alpha   val_acc  statrep datamode alpha       dataset delay  split\n",
       "0             0_0  0.899020        0      gra     0         Photo     0     24\n",
       "1             1_0  0.892157        0      gra     0         Photo     1     24\n",
       "2             3_0  0.882680        0      gra     0         Photo     3     24\n",
       "3             5_0  0.865359        0      gra     0         Photo     5     24\n",
       "4           0_0.2  0.900980        0      gra   0.2         Photo     0     24\n",
       "...           ...       ...      ...      ...   ...           ...   ...    ...\n",
       "11245         0_1  0.111591        9      gra     1  Roman-empire     0    145\n",
       "11246       10_fp  0.115317        9      gra    fp  Roman-empire    10    145\n",
       "11247       20_fp  0.113650        9      gra    fp  Roman-empire    20    145\n",
       "11248       40_fp  0.113061        9      gra    fp  Roman-empire    40    145\n",
       "11249       60_fp  0.112375        9      gra    fp  Roman-empire    60    145\n",
       "\n",
       "[11250 rows x 8 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropls = [\"batch_size\", \"save_embeds\", \"context_size\", \"num_negative_samples\", \"max_iter\", \"patience\", \"ds_make_undir\", \"ds_add_self\", \"model\", \"model\", \"prob_replace\", \"walk_len\", \"walks_per_node\", \"fp\", \"name\", \"device\"]\n",
    "df = pd.read_pickle(\"../results_comb/all_extend_original.pkl\").drop(dropls, axis=1)\n",
    "df[[\"delay\", \"alpha\"]] = df.delay_alpha.str.split(\"_\", expand=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2a475dca-4f49-4a9a-9d19-6173bfd0531c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photo 145\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$84.80_{0.59}$\n",
      "84.79814529418945\n",
      "\n",
      "Photo 145\n",
      "['delay_alpha']\n",
      "60_fp\n",
      "$81.43_{1.43}$\n",
      "81.43479228019714\n",
      "\n",
      "Photo 145\n",
      "['delay_alpha']\n",
      "1_0.4\n",
      "$87.89_{0.68}$\n",
      "87.89137005805969\n",
      "\n",
      "Photo 24\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$87.27_{0.60}$\n",
      "87.2745156288147\n",
      "\n",
      "Photo 24\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "40_fp        0.851961      4.5   24.0\n",
      "60_fp        0.851961      4.5   24.0\n",
      "\n",
      "['delay_alpha']\n",
      "40_fp\n",
      "$85.20_{1.03}$\n",
      "85.19607782363892\n",
      "\n",
      "Photo 24\n",
      "['delay_alpha']\n",
      "1_0.4\n",
      "$89.52_{0.56}$\n",
      "89.51960802078247\n",
      "\n",
      "Photo 43\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$89.29_{0.54}$\n",
      "89.28976058959961\n",
      "\n",
      "Photo 43\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "20_fp        0.885272      4.5   43.0\n",
      "40_fp        0.885272      4.5   43.0\n",
      "60_fp        0.885272      4.5   43.0\n",
      "\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$88.53_{0.72}$\n",
      "88.52723240852356\n",
      "\n",
      "Photo 43\n",
      "['delay_alpha']\n",
      "0_0.2\n",
      "$91.16_{0.35}$\n",
      "91.15903973579407\n",
      "\n",
      "Photo 62\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$90.56_{0.72}$\n",
      "90.56209325790405\n",
      "\n",
      "Photo 62\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "10_fp        0.899216      4.5   62.0\n",
      "20_fp        0.899216      4.5   62.0\n",
      "40_fp        0.899216      4.5   62.0\n",
      "60_fp        0.899216      4.5   62.0\n",
      "\n",
      "['delay_alpha']\n",
      "10_fp\n",
      "$89.92_{0.58}$\n",
      "89.92156982421875\n",
      "\n",
      "Photo 62\n",
      "['delay_alpha']\n",
      "0_0.2\n",
      "$92.32_{0.66}$\n",
      "92.3202633857727\n",
      "\n",
      "Photo 81\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$91.20_{0.85}$\n",
      "91.20261073112488\n",
      "\n",
      "Photo 81\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "10_fp        0.910065      4.5   81.0\n",
      "20_fp        0.910065      4.5   81.0\n",
      "40_fp        0.910065      4.5   81.0\n",
      "60_fp        0.910065      4.5   81.0\n",
      "\n",
      "['delay_alpha']\n",
      "10_fp\n",
      "$91.01_{0.75}$\n",
      "91.00653529167175\n",
      "\n",
      "Photo 81\n",
      "['delay_alpha']\n",
      "0_0\n",
      "$93.02_{0.54}$\n",
      "93.01961064338684\n",
      "\n",
      "Cora 145\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$65.33_{3.49}$\n",
      "65.32840728759766\n",
      "\n",
      "Cora 145\n",
      "['delay_alpha']\n",
      "60_fp\n",
      "$64.74_{2.69}$\n",
      "64.73727226257324\n",
      "\n",
      "Cora 145\n",
      "['delay_alpha']\n",
      "5_0.4\n",
      "$67.72_{1.56}$\n",
      "67.71757006645203\n",
      "\n",
      "Cora 24\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$72.45_{1.74}$\n",
      "72.44690656661987\n",
      "\n",
      "Cora 24\n",
      "['delay_alpha']\n",
      "60_fp\n",
      "$71.54_{2.70}$\n",
      "71.5420126914978\n",
      "\n",
      "Cora 24\n",
      "['delay_alpha']\n",
      "3_0.4\n",
      "$73.67_{1.09}$\n",
      "73.6657440662384\n",
      "\n",
      "Cora 43\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$77.92_{1.62}$\n",
      "77.92128324508667\n",
      "\n",
      "Cora 43\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "20_fp        0.766913      4.5   43.0\n",
      "40_fp        0.766913      4.5   43.0\n",
      "60_fp        0.766913      4.5   43.0\n",
      "\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$76.69_{1.30}$\n",
      "76.69126391410828\n",
      "\n",
      "Cora 43\n",
      "['delay_alpha']\n",
      "5_0.6\n",
      "$79.99_{1.50}$\n",
      "79.98770475387573\n",
      "\n",
      "Cora 62\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$81.92_{1.84}$\n",
      "81.9223701953888\n",
      "\n",
      "Cora 62\n",
      "\n",
      "more than 1 max acc:\n",
      "             val_acc  statrep  split\n",
      "delay_alpha                         \n",
      "20_fp         0.8061      4.5   62.0\n",
      "40_fp         0.8061      4.5   62.0\n",
      "60_fp         0.8061      4.5   62.0\n",
      "\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$80.61_{1.72}$\n",
      "80.60997724533081\n",
      "\n",
      "Cora 62\n",
      "['delay_alpha']\n",
      "5_0.6\n",
      "$83.60_{2.53}$\n",
      "83.60443115234375\n",
      "\n",
      "Cora 81\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$85.20_{2.07}$\n",
      "85.20295023918152\n",
      "\n",
      "Cora 81\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "20_fp        0.841328      4.5   81.0\n",
      "40_fp        0.841328      4.5   81.0\n",
      "60_fp        0.841328      4.5   81.0\n",
      "\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$84.13_{2.42}$\n",
      "84.13284420967102\n",
      "\n",
      "Cora 81\n",
      "['delay_alpha']\n",
      "1_0.4\n",
      "$86.97_{2.02}$\n",
      "86.97417378425598\n",
      "\n",
      "Computers 145\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$81.49_{0.48}$\n",
      "81.49458765983582\n",
      "\n",
      "Computers 145\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "40_fp        0.723849      4.5  145.0\n",
      "60_fp        0.723849      4.5  145.0\n",
      "\n",
      "['delay_alpha']\n",
      "40_fp\n",
      "$72.38_{1.10}$\n",
      "72.38487601280212\n",
      "\n",
      "Computers 145\n",
      "['delay_alpha']\n",
      "0_0.4\n",
      "$85.74_{0.53}$\n",
      "85.74244379997253\n",
      "\n",
      "Computers 24\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$83.82_{0.72}$\n",
      "83.82293581962585\n",
      "\n",
      "Computers 24\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "20_fp        0.776477      4.5   24.0\n",
      "40_fp        0.776477      4.5   24.0\n",
      "\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$77.65_{0.94}$\n",
      "77.64769792556763\n",
      "\n",
      "Computers 24\n",
      "['delay_alpha']\n",
      "0_0.4\n",
      "$87.58_{0.65}$\n",
      "87.58044242858887\n",
      "\n",
      "Computers 43\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$85.94_{0.41}$\n",
      "85.93696355819702\n",
      "\n",
      "Computers 43\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "20_fp        0.817042      4.5   43.0\n",
      "40_fp        0.817042      4.5   43.0\n",
      "60_fp        0.817042      4.5   43.0\n",
      "\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$81.70_{0.71}$\n",
      "81.70424699783325\n",
      "\n",
      "Computers 43\n",
      "['delay_alpha']\n",
      "0_0.2\n",
      "$89.19_{0.59}$\n",
      "89.18545842170715\n",
      "\n",
      "Computers 62\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$86.76_{0.56}$\n",
      "86.76117658615112\n",
      "\n",
      "Computers 62\n",
      "['delay_alpha']\n",
      "10_fp\n",
      "$83.08_{0.72}$\n",
      "83.07524919509888\n",
      "\n",
      "Computers 62\n",
      "['delay_alpha']\n",
      "0_0.2\n",
      "$90.05_{0.47}$\n",
      "90.04725217819214\n",
      "\n",
      "Computers 81\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$86.74_{0.88}$\n",
      "86.74181699752808\n",
      "\n",
      "Computers 81\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "10_fp        0.832364      4.5   81.0\n",
      "20_fp        0.832364      4.5   81.0\n",
      "40_fp        0.832364      4.5   81.0\n",
      "60_fp        0.832364      4.5   81.0\n",
      "\n",
      "['delay_alpha']\n",
      "10_fp\n",
      "$83.24_{1.23}$\n",
      "83.23636054992676\n",
      "\n",
      "Computers 81\n",
      "['delay_alpha']\n",
      "1_0.2\n",
      "$90.28_{0.63}$\n",
      "90.27636647224426\n",
      "\n",
      "Roman-empire 145\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$10.43_{0.95}$\n",
      "10.434398800134659\n",
      "\n",
      "Roman-empire 145\n",
      "['delay_alpha']\n",
      "10_fp\n",
      "$10.79_{0.96}$\n",
      "10.785448551177979\n",
      "\n",
      "Roman-empire 145\n",
      "['delay_alpha']\n",
      "0_0\n",
      "$10.73_{0.91}$\n",
      "10.73249727487564\n",
      "\n",
      "Roman-empire 24\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$8.52_{0.77}$\n",
      "8.519580960273743\n",
      "\n",
      "Roman-empire 24\n",
      "['delay_alpha']\n",
      "10_fp\n",
      "$8.92_{0.80}$\n",
      "8.918918669223785\n",
      "\n",
      "Roman-empire 24\n",
      "['delay_alpha']\n",
      "5_0\n",
      "$9.91_{0.35}$\n",
      "9.912851452827454\n",
      "\n",
      "Roman-empire 43\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$7.14_{0.33}$\n",
      "7.138864696025848\n",
      "\n",
      "Roman-empire 43\n",
      "['delay_alpha']\n",
      "10_fp\n",
      "$7.31_{0.39}$\n",
      "7.306560128927231\n",
      "\n",
      "Roman-empire 43\n",
      "['delay_alpha']\n",
      "1_0\n",
      "$10.51_{1.46}$\n",
      "10.506031662225723\n",
      "\n",
      "Roman-empire 62\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$7.03_{0.37}$\n",
      "7.032869756221771\n",
      "\n",
      "Roman-empire 62\n",
      "['delay_alpha']\n",
      "10_fp\n",
      "$7.17_{0.34}$\n",
      "7.16964453458786\n",
      "\n",
      "Roman-empire 62\n",
      "['delay_alpha']\n",
      "1_0\n",
      "$15.07_{5.50}$\n",
      "15.073902904987335\n",
      "\n",
      "Roman-empire 81\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$7.64_{0.51}$\n",
      "7.643423974514008\n",
      "\n",
      "Roman-empire 81\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "20_fp        0.075728      4.5   81.0\n",
      "40_fp        0.075728      4.5   81.0\n",
      "60_fp        0.075728      4.5   81.0\n",
      "\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$7.57_{0.35}$\n",
      "7.57281556725502\n",
      "\n",
      "Roman-empire 81\n",
      "['delay_alpha']\n",
      "0_0\n",
      "$20.70_{10.05}$\n",
      "20.69726437330246\n",
      "\n",
      "WikiCS 145\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$65.94_{2.05}$\n",
      "65.9399926662445\n",
      "\n",
      "WikiCS 145\n",
      "['delay_alpha']\n",
      "40_fp\n",
      "$47.61_{2.82}$\n",
      "47.61108756065369\n",
      "\n",
      "WikiCS 145\n",
      "['delay_alpha']\n",
      "0_0.6\n",
      "$68.55_{1.20}$\n",
      "68.5472846031189\n",
      "\n",
      "WikiCS 24\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$68.87_{1.47}$\n",
      "68.87203454971313\n",
      "\n",
      "WikiCS 24\n",
      "['delay_alpha']\n",
      "60_fp\n",
      "$56.98_{3.07}$\n",
      "56.9771409034729\n",
      "\n",
      "WikiCS 24\n",
      "['delay_alpha']\n",
      "0_0.4\n",
      "$71.11_{0.82}$\n",
      "71.11087441444397\n",
      "\n",
      "WikiCS 43\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$72.66_{1.38}$\n",
      "72.66021370887756\n",
      "\n",
      "WikiCS 43\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "40_fp        0.623127      4.5   43.0\n",
      "60_fp        0.623127      4.5   43.0\n",
      "\n",
      "['delay_alpha']\n",
      "40_fp\n",
      "$62.31_{2.59}$\n",
      "62.31273412704468\n",
      "\n",
      "WikiCS 43\n",
      "['delay_alpha']\n",
      "0_0.4\n",
      "$74.57_{0.73}$\n",
      "74.57419633865356\n",
      "\n",
      "WikiCS 62\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$75.03_{0.89}$\n",
      "75.03418922424316\n",
      "\n",
      "WikiCS 62\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "10_fp        0.637009      4.5   62.0\n",
      "20_fp        0.637009      4.5   62.0\n",
      "40_fp        0.637009      4.5   62.0\n",
      "60_fp        0.637009      4.5   62.0\n",
      "\n",
      "['delay_alpha']\n",
      "10_fp\n",
      "$63.70_{1.93}$\n",
      "63.700854778289795\n",
      "\n",
      "WikiCS 62\n",
      "['delay_alpha']\n",
      "0_0.4\n",
      "$76.71_{0.70}$\n",
      "76.70513391494751\n",
      "\n",
      "WikiCS 81\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$76.53_{1.23}$\n",
      "76.5299141407013\n",
      "\n",
      "WikiCS 81\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "10_fp        0.630256      4.5   81.0\n",
      "20_fp        0.630256      4.5   81.0\n",
      "40_fp        0.630256      4.5   81.0\n",
      "60_fp        0.630256      4.5   81.0\n",
      "\n",
      "['delay_alpha']\n",
      "10_fp\n",
      "$63.03_{1.57}$\n",
      "63.025641441345215\n",
      "\n",
      "WikiCS 81\n",
      "['delay_alpha']\n",
      "0_0.4\n",
      "$77.93_{1.07}$\n",
      "77.9316246509552\n",
      "\n",
      "Pubmed 145\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$66.69_{0.86}$\n",
      "66.68733358383179\n",
      "\n",
      "Pubmed 145\n",
      "['delay_alpha']\n",
      "60_fp\n",
      "$65.12_{1.14}$\n",
      "65.12398719787598\n",
      "\n",
      "Pubmed 145\n",
      "['delay_alpha']\n",
      "0_0.6\n",
      "$67.51_{0.76}$\n",
      "67.50563383102417\n",
      "\n",
      "Pubmed 24\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$69.31_{0.83}$\n",
      "69.31279301643372\n",
      "\n",
      "Pubmed 24\n",
      "['delay_alpha']\n",
      "60_fp\n",
      "$67.78_{1.10}$\n",
      "67.78242588043213\n",
      "\n",
      "Pubmed 24\n",
      "['delay_alpha']\n",
      "0_0.4\n",
      "$70.42_{0.90}$\n",
      "70.41841149330139\n",
      "\n",
      "Pubmed 43\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$72.90_{0.99}$\n",
      "72.90109395980835\n",
      "\n",
      "Pubmed 43\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$70.11_{0.83}$\n",
      "70.1149582862854\n",
      "\n",
      "Pubmed 43\n",
      "['delay_alpha']\n",
      "1_0.4\n",
      "$74.33_{0.97}$\n",
      "74.33474063873291\n",
      "\n",
      "Pubmed 62\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$75.53_{0.93}$\n",
      "75.52992105484009\n",
      "\n",
      "Pubmed 62\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "20_fp        0.717089      4.5   62.0\n",
      "40_fp        0.717089      4.5   62.0\n",
      "60_fp        0.717089      4.5   62.0\n",
      "\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$71.71_{0.68}$\n",
      "71.7089295387268\n",
      "\n",
      "Pubmed 62\n",
      "['delay_alpha']\n",
      "0_0.4\n",
      "$77.23_{0.76}$\n",
      "77.22870111465454\n",
      "\n",
      "Pubmed 81\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$78.24_{1.30}$\n",
      "78.24454307556152\n",
      "\n",
      "Pubmed 81\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "10_fp        0.732268      4.5   81.0\n",
      "20_fp        0.732268      4.5   81.0\n",
      "40_fp        0.732268      4.5   81.0\n",
      "60_fp        0.732268      4.5   81.0\n",
      "\n",
      "['delay_alpha']\n",
      "10_fp\n",
      "$73.23_{1.25}$\n",
      "73.22679162025452\n",
      "\n",
      "Pubmed 81\n",
      "['delay_alpha']\n",
      "3_0.4\n",
      "$80.42_{1.27}$\n",
      "80.41602969169617\n",
      "\n",
      "Citeseer 145\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$41.52_{3.87}$\n",
      "41.516366600990295\n",
      "\n",
      "Citeseer 145\n",
      "['delay_alpha']\n",
      "60_fp\n",
      "$41.98_{3.72}$\n",
      "41.97728633880615\n",
      "\n",
      "Citeseer 145\n",
      "['delay_alpha']\n",
      "5_0\n",
      "$42.28_{4.42}$\n",
      "42.27789044380188\n",
      "\n",
      "Citeseer 24\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$47.64_{0.84}$\n",
      "47.64087200164795\n",
      "\n",
      "Citeseer 24\n",
      "['delay_alpha']\n",
      "60_fp\n",
      "$48.14_{1.05}$\n",
      "48.144251108169556\n",
      "\n",
      "Citeseer 24\n",
      "['delay_alpha']\n",
      "5_0.2\n",
      "$49.55_{2.58}$\n",
      "49.54921305179596\n",
      "\n",
      "Citeseer 43\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$57.69_{1.67}$\n",
      "57.68536925315857\n",
      "\n",
      "Citeseer 43\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "40_fp        0.571142      4.5   43.0\n",
      "60_fp        0.571142      4.5   43.0\n",
      "\n",
      "['delay_alpha']\n",
      "40_fp\n",
      "$57.11_{1.90}$\n",
      "57.1142315864563\n",
      "\n",
      "Citeseer 43\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "3_0.2        0.590581      4.5   43.0\n",
      "5_0.4        0.590581      4.5   43.0\n",
      "\n",
      "['delay_alpha']\n",
      "3_0.2\n",
      "$59.06_{2.24}$\n",
      "59.05811786651611\n",
      "\n",
      "Citeseer 62\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$64.23_{2.10}$\n",
      "64.23423290252686\n",
      "\n",
      "Citeseer 62\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "20_fp        0.628829      4.5   62.0\n",
      "40_fp        0.628829      4.5   62.0\n",
      "60_fp        0.628829      4.5   62.0\n",
      "\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$62.88_{1.92}$\n",
      "62.88288235664368\n",
      "\n",
      "Citeseer 62\n",
      "['delay_alpha']\n",
      "5_0.6\n",
      "$65.09_{2.21}$\n",
      "65.09009003639221\n",
      "\n",
      "Citeseer 81\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$69.49_{2.70}$\n",
      "69.48795318603516\n",
      "\n",
      "Citeseer 81\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "10_fp        0.681024      4.5   81.0\n",
      "20_fp        0.681024      4.5   81.0\n",
      "40_fp        0.681024      4.5   81.0\n",
      "60_fp        0.681024      4.5   81.0\n",
      "\n",
      "['delay_alpha']\n",
      "10_fp\n",
      "$68.10_{2.43}$\n",
      "68.10240745544434\n",
      "\n",
      "Citeseer 81\n",
      "['delay_alpha']\n",
      "5_0.4\n",
      "$70.99_{1.87}$\n",
      "70.99397778511047\n",
      "\n",
      "Amazon-ratings 145\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$37.39_{0.57}$\n",
      "37.393397092819214\n",
      "\n",
      "Amazon-ratings 145\n",
      "['delay_alpha']\n",
      "60_fp\n",
      "$37.61_{0.49}$\n",
      "37.6084178686142\n",
      "\n",
      "Amazon-ratings 145\n",
      "['delay_alpha']\n",
      "1_0\n",
      "$38.76_{0.54}$\n",
      "38.75884413719177\n",
      "\n",
      "Amazon-ratings 24\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$38.05_{0.33}$\n",
      "38.05450797080994\n",
      "\n",
      "Amazon-ratings 24\n",
      "['delay_alpha']\n",
      "60_fp\n",
      "$38.29_{0.39}$\n",
      "38.28927278518677\n",
      "\n",
      "Amazon-ratings 24\n",
      "['delay_alpha']\n",
      "3_0\n",
      "$40.01_{0.41}$\n",
      "40.01429080963135\n",
      "\n",
      "Amazon-ratings 43\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$39.09_{0.61}$\n",
      "39.08670246601105\n",
      "\n",
      "Amazon-ratings 43\n",
      "['delay_alpha']\n",
      "40_fp\n",
      "$39.06_{0.57}$\n",
      "39.05676007270813\n",
      "\n",
      "Amazon-ratings 43\n",
      "['delay_alpha']\n",
      "5_0\n",
      "$41.41_{0.55}$\n",
      "41.407376527786255\n",
      "\n",
      "Amazon-ratings 62\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$39.46_{0.70}$\n",
      "39.45703208446503\n",
      "\n",
      "Amazon-ratings 62\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$38.82_{0.72}$\n",
      "38.82425129413605\n",
      "\n",
      "Amazon-ratings 62\n",
      "['delay_alpha']\n",
      "5_0\n",
      "$41.89_{0.52}$\n",
      "41.88610017299652\n",
      "\n",
      "Amazon-ratings 81\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$39.20_{1.25}$\n",
      "39.2037570476532\n",
      "\n",
      "Amazon-ratings 81\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "20_fp        0.386525      4.5   81.0\n",
      "40_fp        0.386525      4.5   81.0\n",
      "60_fp        0.386525      4.5   81.0\n",
      "\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$38.65_{0.92}$\n",
      "38.652509450912476\n",
      "\n",
      "Amazon-ratings 81\n",
      "['delay_alpha']\n",
      "5_0\n",
      "$42.07_{0.79}$\n",
      "42.07431674003601\n",
      "\n",
      "Actor 145\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$21.63_{1.38}$\n",
      "21.62865400314331\n",
      "\n",
      "Actor 145\n",
      "['delay_alpha']\n",
      "60_fp\n",
      "$20.50_{1.82}$\n",
      "20.502924919128418\n",
      "\n",
      "Actor 145\n",
      "['delay_alpha']\n",
      "3_0.2\n",
      "$23.36_{1.09}$\n",
      "23.35672676563263\n",
      "\n",
      "Actor 24\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$21.40_{1.50}$\n",
      "21.401314437389374\n",
      "\n",
      "Actor 24\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$20.56_{1.56}$\n",
      "20.56250125169754\n",
      "\n",
      "Actor 24\n",
      "['delay_alpha']\n",
      "5_0\n",
      "$24.12_{1.00}$\n",
      "24.121710658073425\n",
      "\n",
      "Actor 43\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$21.37_{1.21}$\n",
      "21.368420124053955\n",
      "\n",
      "Actor 43\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "20_fp        0.202632      4.5   43.0\n",
      "40_fp        0.202632      4.5   43.0\n",
      "60_fp        0.202632      4.5   43.0\n",
      "\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$20.26_{0.94}$\n",
      "20.263156294822693\n",
      "\n",
      "Actor 43\n",
      "['delay_alpha']\n",
      "5_0.2\n",
      "$24.56_{1.01}$\n",
      "24.561402201652527\n",
      "\n",
      "Actor 62\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$22.23_{0.55}$\n",
      "22.23026305437088\n",
      "\n",
      "Actor 62\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "40_fp        0.200658      4.5   62.0\n",
      "60_fp        0.200658      4.5   62.0\n",
      "\n",
      "['delay_alpha']\n",
      "40_fp\n",
      "$20.07_{1.37}$\n",
      "20.06578892469406\n",
      "\n",
      "Actor 62\n",
      "['delay_alpha']\n",
      "5_0\n",
      "$25.27_{1.21}$\n",
      "25.26973783969879\n",
      "\n",
      "Actor 81\n",
      "['delay_alpha']\n",
      "0_1\n",
      "$23.05_{0.95}$\n",
      "23.052632808685303\n",
      "\n",
      "Actor 81\n",
      "\n",
      "more than 1 max acc:\n",
      "              val_acc  statrep  split\n",
      "delay_alpha                          \n",
      "20_fp        0.200789      4.5   81.0\n",
      "40_fp        0.200789      4.5   81.0\n",
      "60_fp        0.200789      4.5   81.0\n",
      "\n",
      "['delay_alpha']\n",
      "20_fp\n",
      "$20.08_{1.39}$\n",
      "20.078948140144348\n",
      "\n",
      "Actor 81\n",
      "['delay_alpha']\n",
      "5_0.2\n",
      "$25.30_{1.16}$\n",
      "25.30263066291809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ds in df.dataset.unique():\n",
    "    for split in [145, 24, 43, 62, 81]:\n",
    "        gen_save_exfeats(df, ds, split, \"base\")\n",
    "        gen_save_exfeats(df, ds, split, \"fp\")\n",
    "        gen_save_exfeats(df, ds, split, \"ph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc0a3c-4340-4270-87b9-b91408189207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a2f51f4-eac1-4081-b091-9e783b74f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print2do():\n",
    "    p = Path(\"../Experiments\")\n",
    "    ls = []\n",
    "    for p in list(p.glob(\"*\")):\n",
    "        if str(p)[-3:] == \"yml\":\n",
    "            settings = yaml.safe_load(p.open())\n",
    "            if not settings.get(\"alldone\", False):\n",
    "                ls.append(str(p))\n",
    "    ls.sort()\n",
    "    print(\"\\n\".join(ls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2499397a-c0ef-4b90-a68e-86de39ed7fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def best_res(df, v = \"val_acc\"):\n",
    "    for split in df.split.unique():\n",
    "        print(split)\n",
    "        helper(split, df,v)\n",
    "\n",
    "def baseline(df, v = \"val_acc\"):\n",
    "    for split in df.split.unique():\n",
    "        print(split)\n",
    "        df = df[df.w_ms.eq(0) & df.w_ndiv.eq(0) & df.prob_replace.eq(0) & df.delay_alpha.eq(\"0_1\")]\n",
    "        helper(split, df,v)\n",
    "\n",
    "def baseline_post(df, v = \"val_acc\"):\n",
    "    for split in df.split.unique():\n",
    "        print(split)\n",
    "        df = df[df.w_ms.eq(0) & df.w_ndiv.eq(0) & df.prob_replace.eq(0)]\n",
    "        helper(split, df,v)\n",
    "\n",
    "def all_res(df, v = \"val_acc\"):\n",
    "    for split in df.split.unique():\n",
    "        print(split)\n",
    "        print(\"BASELINE\")\n",
    "        df_b = df[df.w_ms.eq(0) & df.w_ndiv.eq(0) & df.prob_replace.eq(0) & df.delay_alpha.eq(\"0_1\")]\n",
    "        helper(split, df_b,v)\n",
    "        print(\"POSTHOC\")\n",
    "        df_p = df[df.w_ms.eq(0) & df.w_ndiv.eq(0) & df.prob_replace.eq(0)]\n",
    "        helper(split, df_p,v)\n",
    "        print(\"ALL\")\n",
    "        helper(split, df,v)\n",
    "\n",
    "def helper(split, df, v):\n",
    "        df_ = df[df.split.eq(split)].drop([\"val_loss\", \"loss_hist\", \"valtest_time\", \"train_time\", \"record_train\", \"save_models\", \"batch_size_test\", \"batch_size_val\", \"early_stopping_patience\"], axis=1, errors=\"ignore\")\n",
    "\n",
    "        params = []\n",
    "        for c in df_.drop([\"val_acc\", \"statrep\", \"trained_epochs\"], axis=1).columns:\n",
    "            if len(df_[c].unique())>1:\n",
    "                params.append(c)\n",
    "        tmp = df_.groupby(params)\n",
    "        mean = tmp.mean(numeric_only = True)\n",
    "        std = tmp.std(numeric_only = True)\n",
    "        \n",
    "        ix = mean[v].idxmax()\n",
    "        num_occ = mean.val_acc.value_counts()[mean.loc[ix].val_acc]\n",
    "        \n",
    "        print(params)\n",
    "        if num_occ != 1:\n",
    "            max_df = mean[mean.val_acc.eq(mean.loc[ix].val_acc)]\n",
    "            for index, row in max_df.iterrows():\n",
    "                print(t2l(index))\n",
    "                print(\"${:.2f}_{{{:.2f}}}$\".format(mean.loc[index].val_acc*100, std.loc[index].val_acc*100))\n",
    "            \n",
    "        else:\n",
    "            print(t2l(ix))\n",
    "            print(\"${:.2f}_{{{:.2f}}}$\".format(mean.loc[ix].val_acc*100, std.loc[ix].val_acc*100))\n",
    "            print(mean.loc[ix].val_acc*100)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e4fbf6-29ed-4622-a88d-7f773c2361fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "BASELINE\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    0.2 &    5.0\n",
      "$67.49_{1.86}$\n",
      "67.4876868724823\n",
      "\n",
      "POSTHOC\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0 &    256 &    0.1 &    0.2 &    5.0\n",
      "$68.34_{2.46}$\n",
      "68.3360755443573\n",
      "\n",
      "ALL\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.2 &    256 &    0.1 &    0.2 &    5.0 &    10.0 &    0.01\n",
      "$68.42_{1.74}$\n",
      "68.41816902160645\n",
      "\n",
      "24\n",
      "BASELINE\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    0.2 &    0.2\n",
      "$72.24_{1.35}$\n",
      "72.23761081695557\n",
      "\n",
      "POSTHOC\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "1_0.6 &    256 &    0.1 &    0.2 &    1.0\n",
      "$73.28_{1.35}$\n",
      "73.28408360481262\n",
      "\n",
      "ALL\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "3_0.6 &    256 &    0.1 &    1.0 &    0.2 &    0.0 &    0.1\n",
      "$73.44_{1.76}$\n",
      "73.4379768371582\n",
      "\n",
      "43\n",
      "BASELINE\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    1.0 &    0.2\n",
      "$76.63_{1.42}$\n",
      "256 &    0.1 &    5.0 &    5.0\n",
      "$76.63_{1.23}$\n",
      "\n",
      "POSTHOC\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "3_0.2 &    256 &    0.01 &    5.0 &    5.0\n",
      "$79.70_{1.25}$\n",
      "79.70479130744934\n",
      "\n",
      "ALL\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "3_0.2 &    256 &    0.01 &    0.2 &    0.2 &    0.1 &    0.001\n",
      "$79.83_{1.30}$\n",
      "79.82780337333679\n",
      "\n",
      "62\n",
      "BASELINE\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    1.0 &    1.0\n",
      "$79.61_{2.72}$\n",
      "79.60567474365234\n",
      "\n",
      "POSTHOC\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.8 &    256 &    0.1 &    5.0 &    0.2\n",
      "$82.81_{3.60}$\n",
      "82.80961513519287\n",
      "\n",
      "ALL\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "0_0.2 &    256 &    0.1 &    5.0 &    1.0 &    10.0 &    0.0\n",
      "$83.30_{2.83}$\n",
      "1_0.4 &    256 &    0.1 &    5.0 &    0.2 &    10.0 &    0.001\n",
      "$83.30_{3.35}$\n",
      "3_0.6 &    256 &    0.1 &    5.0 &    0.2 &    10.0 &    0.001\n",
      "$83.30_{3.35}$\n",
      "5_0.6 &    256 &    0.1 &    5.0 &    1.0 &    10.0 &    0.0\n",
      "$83.30_{3.21}$\n",
      "\n",
      "81\n",
      "BASELINE\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.01 &    0.2 &    0.2\n",
      "$86.72_{0.37}$\n",
      "86.71586513519287\n",
      "\n",
      "POSTHOC\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "3_0.4 &    256 &    0.1 &    0.2 &    1.0\n",
      "$89.30_{1.11}$\n",
      "3_0.4 &    256 &    0.1 &    0.2 &    5.0\n",
      "$89.30_{1.33}$\n",
      "\n",
      "ALL\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "1_0.4 &    256 &    0.1 &    0.2 &    0.2 &    1.0 &    0.01\n",
      "$89.54_{0.77}$\n",
      "1_0.4 &    256 &    0.1 &    5.0 &    0.2 &    0.0 &    0.001\n",
      "$89.54_{0.93}$\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl = []\n",
    "pl.append(Path(\"../results_comb/Cora_145.pkl\"))\n",
    "pl.append(Path(\"../results_comb/Cora_24.pkl\"))\n",
    "pl.append(Path(\"../results_comb/Cora_43.pkl\"))\n",
    "pl.append(Path(\"../results_comb/Cora_62.pkl\"))\n",
    "pl.append(Path(\"../results_comb/Cora_81.pkl\"))\n",
    "df = pd.concat([pd.read_pickle(str(p)) for p in pl], ignore_index=True)\n",
    "\n",
    "all_res(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2f560a-7716-4986-8166-12751acf2e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'prob_replace', 'q']\n",
      "5_0 &    256 &    0.1 &    5.0 &    0.8 &    0.2\n",
      "$68.66_{2.22}$\n",
      "68.66447925567627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl = []\n",
    "pl.append(Path(\"../results_comb/Cora_145r.pkl\"))\n",
    "#pl.append(Path(\"../results_comb/Cora_24.pkl\"))\n",
    "#pl.append(Path(\"../results_comb/Cora_43.pkl\"))\n",
    "#pl.append(Path(\"../results_comb/Cora_62.pkl\"))\n",
    "#pl.append(Path(\"../results_comb/Cora_81.pkl\"))\n",
    "df = pd.concat([pd.read_pickle(str(p)) for p in pl], ignore_index=True)\n",
    "\n",
    "best_res(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b43511ee-3583-4a0e-8459-03a3ccd643ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "BASELINE\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    0.2 &    5.0\n",
      "$44.91_{3.16}$\n",
      "44.9120432138443\n",
      "\n",
      "POSTHOC\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "3_0.2 &    256 &    0.1 &    1.0 &    0.2\n",
      "$47.12_{1.99}$\n",
      "47.11645543575287\n",
      "\n",
      "ALL\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "3_0.2 &    256 &    0.1 &    0.2 &    5.0 &    0.1 &    0.0\n",
      "$47.21_{1.72}$\n",
      "5_0.2 &    256 &    0.1 &    1.0 &    1.0 &    10.0 &    0.0\n",
      "$47.21_{1.72}$\n",
      "\n",
      "24\n",
      "BASELINE\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    1.0 &    5.0\n",
      "$51.97_{0.58}$\n",
      "51.96594595909119\n",
      "\n",
      "POSTHOC\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.2 &    256 &    0.1 &    0.2 &    1.0\n",
      "$53.62_{0.68}$\n",
      "53.61883044242859\n",
      "\n",
      "ALL\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.2 &    256 &    0.1 &    0.2 &    5.0 &    0.1 &    0.0\n",
      "$53.69_{0.93}$\n",
      "53.69396209716797\n",
      "\n",
      "43\n",
      "BASELINE\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.1 &    5.0 &    5.0\n",
      "$54.18_{1.86}$\n",
      "54.175013303756714\n",
      "\n",
      "POSTHOC\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.2 &    256 &    0.001 &    1.0 &    1.0\n",
      "$61.69_{0.95}$\n",
      "61.69005036354065\n",
      "\n",
      "ALL\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.2 &    256 &    0.01 &    1.0 &    1.0 &    1.0 &    0.0\n",
      "$61.79_{0.76}$\n",
      "5_0.2 &    256 &    0.01 &    1.0 &    1.0 &    1.0 &    0.001\n",
      "$61.79_{0.76}$\n",
      "\n",
      "62\n",
      "BASELINE\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.01 &    1.0 &    1.0\n",
      "$58.36_{1.13}$\n",
      "58.35835933685303\n",
      "\n",
      "POSTHOC\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "3_0.2 &    256 &    0.1 &    1.0 &    1.0\n",
      "$63.01_{0.88}$\n",
      "5_0.2 &    256 &    0.1 &    0.2 &    0.2\n",
      "$63.01_{1.52}$\n",
      "5_0.2 &    256 &    0.1 &    0.2 &    5.0\n",
      "$63.01_{0.74}$\n",
      "\n",
      "ALL\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.2 &    256 &    0.1 &    5.0 &    0.2 &    0.0 &    0.001\n",
      "$63.91_{1.50}$\n",
      "63.91391158103943\n",
      "\n",
      "81\n",
      "BASELINE\n",
      "['embedding_dim', 'lr', 'p', 'q']\n",
      "256 &    0.01 &    5.0 &    0.2\n",
      "$63.96_{1.52}$\n",
      "63.95582556724548\n",
      "\n",
      "POSTHOC\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q']\n",
      "5_0.2 &    256 &    0.001 &    1.0 &    0.2\n",
      "$68.57_{2.43}$\n",
      "5_0.2 &    256 &    0.001 &    1.0 &    1.0\n",
      "$68.57_{2.70}$\n",
      "5_0.2 &    256 &    0.001 &    5.0 &    0.2\n",
      "$68.57_{2.43}$\n",
      "5_0.2 &    256 &    0.001 &    5.0 &    1.0\n",
      "$68.57_{2.43}$\n",
      "5_0.2 &    256 &    0.1 &    5.0 &    0.2\n",
      "$68.57_{1.82}$\n",
      "\n",
      "ALL\n",
      "['delay_alpha', 'embedding_dim', 'lr', 'p', 'q', 'w_ms', 'w_ndiv']\n",
      "5_0.2 &    256 &    0.1 &    1.0 &    0.2 &    10.0 &    0.01\n",
      "$69.48_{1.22}$\n",
      "69.4779098033905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl = []\n",
    "pl.append(Path(\"../results_comb/Cite_145.pkl\"))\n",
    "pl.append(Path(\"../results_comb/Cite_24.pkl\"))\n",
    "pl.append(Path(\"../results_comb/Cite_43.pkl\"))\n",
    "pl.append(Path(\"../results_comb/Cite_62.pkl\"))\n",
    "pl.append(Path(\"../results_comb/Cite_81.pkl\"))\n",
    "df = pd.concat([pd.read_pickle(str(p)) for p in pl], ignore_index=True)\n",
    "\n",
    "all_res(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71a246a8-f524-41d6-8b32-d7ca11740ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fp_exp(ds, split, typ = False, dim = 64):\n",
    "    ds_l = {\"Cora\":\"Cora\", \"Cite\":\"Citeseer\", \"PM\":\"Pubmed\", \"Com\":\"Computers\", \"Pho\":\"Photo\", \"Act\":\"Actor\", \"Ar\":\"Amazon-ratings\", \"Re\":\"Roman-empire\", \"WCS\":\"WikiCS\"}[ds]\n",
    "    \n",
    "    d = {\"batch_size\":[128],\n",
    "         \"dataset\":[ds_l],\n",
    "         \"embedding_dim\": [dim],\n",
    "         \"fp\": [[10,20,40,60]],\n",
    "         #\"alpha\": [[0, 0.2, 0.4, 0.6, 0.8, 1]],\n",
    "         #\"delay\": [[0, 1, 3, 5]],         \n",
    "         \"lr\": [0.1, 0.01, 0.001],\n",
    "         \"split\": [split],\n",
    "         \"statrep\": [3],\n",
    "         \"p\": [0.2, 1, 5],\n",
    "         \"prob_replace\": [0],\n",
    "         \"q\": [0.2, 1, 5],\n",
    "         \"w_ndiv\": [0],\n",
    "         \"w_ms\":[0],}\n",
    "    if typ == \"loss\":\n",
    "        d[\"w_ndiv\"] = [0, 0.001, 0.01, 0.1]\n",
    "        d[\"w_ms\"] = [0, 0.1, 1, 10]\n",
    "    elif typ == \"prob\":\n",
    "        d[\"prob_replace\"] = [0.2, 0.4, 0.6, 0.8]\n",
    "    else:\n",
    "        typ = \"\"\n",
    "\n",
    "    #p = \"../Experiments/\"+ds+\"_\"+str(split)+\"_\"+typ+\"_\"+str(dim)+\".yml\"\n",
    "    p = \"../Experiments/\"+ds+\"_\"+str(split)+\"_fp_\"+typ+\"_\"+str(dim)+\".yml\"\n",
    "    #print(p)\n",
    "    #print(d)\n",
    "    yaml.dump(d, open(p, \"w\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f383963-f93c-4cce-9d57-81b26e4613d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hom -> 256\n",
    "#act, ar, re both\n",
    "for dim in [64]:\n",
    "    for ds in [\"Cora\", \"Cite\", \"PM\", \"Com\", \"Pho\"]:\n",
    "        for split in [81, 62, 43, 24, 145]:\n",
    "            for typ in [\"loss\", \"prob\"]:\n",
    "                #print_fp_exp(ds, split, typ=typ, dim=dim)\n",
    "                pass #print()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf46060-a615-4f90-a552-9e4f6dba0c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
